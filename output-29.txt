Solutions like these are great because they are easy to follow. The solutions with loops, stacks, etc. are nice but harder to inspect than this one.All this needs is a line or two to trim it down to a fixed alphabet (just [a-zA-Z] characters?). Joel, thanks for clarifying my choice!Regarding comments: yes, I think it'd be nice if the first few on each answer were expanded by default. Or at least highlighted a little more. I've run into these before as custom jobs. I think it's tough because you need so much context (US vs. UK, volume vs. mass vs. liquid vs. density etc. to do conversions properly. Why do the passwords need to be completely unique? This is what we had started to do but I thought I might as well ask SO to see if something exists already.Thanks for the link, though! Is this a homework question? Take CSE566 at Ohio State and you'll learn all about this and other counting things. One of my favorite classes. Check the permissions by right-clicking on it and hitting the security or permissions tab. Is the Excel file closed when you connect to it? you can write &amp; in place of the ampersand instead of escaping the code in your example This would instantiate a new object on every single request--I think Bob's trying to get a single object *per server*. Aww snap! Good answer. I always forget about the globalization stuff. Forget this--use the globalization class http://stackoverflow.com/questions/72831/how-do-i-capitalize-first-letter-of-first-name-and-last-name-in-c#72871 Just to clarify--if you have a long query from a DB--I'd use Load there, too. At my company, the conventions document is often customized for each project to incorporate whatever style and DSL the customer brings to the table. I just added the code review approach. The conventions document is maintained throughout the life of a project--it's a living document. For example, if, during a code review you came across something that wasn't well defined in the document, you'd either update the doc at that time or tell the developer to do it and approve the change. Yes. I guess I hadn't really given it so much thought before. Code reviews are the mechanism by which you maintain your standards and enforce them. What is your current function? See my updated answer--untested I'm afraid. No problem, thanks for correcting my initial answer! Of course in most languages, you wouldn't need the "==true" part of that ternary either. I thought I was a huge fan until I saw that example. That would take some getting used to. I use them for one-liners, not blocks. Jeffrey: awesome. Make sure you add a check for the empty string. isNaN('') returns false but you probably want it to return true in this case. Props on a cool regex but that is just plain ridiculous. I do not think regex is the way to go--this is extremely difficult to verify with the eye and any test you write to verify it works is likely to be worse than just implementing it a clearer way in the first place. Thanks for clarifying the specific generics, Jon. A few have asked why I am leaving Vault. It's not about abandoning vault or favoring SVN--my company uses both. It'd just be helpful in some situations to be able to move from one to the other. This is disabled in most browsers now. Yes! This is the best reason to be explicit--covering indexes. What are your project references? Reference: http://www.xml.com/pub/a/2001/08/01/gettingloopy.html Good call, Robert. It is so unlikely to occur that you are far, far better off spending your time elsewhere. Your server is more likely to catch on fire than generate the same GUID twice. Thank you for adding the ref lines. It's also common to use a random salt for each user and store it alongside the hashed password. Just a note on convention: I rarely (if ever) see RIGHT joins--usually they are LEFT joins. So in this case, I'd start with users_usr, then left join to credit_acc. I think it reads better, too. Can you post your c# code? Why this works: if @var is null, then the whole line is true, regardless of the rest of the line (thus ignored and unfiltered). If it's not null, than the line is false *unless* ColVar=@var, thus applying the filter. I was confused the first time I read this filter style but use it everywhere now. mancmanomyst.myopenid.com: that's what this does. I suggest making a truth table--it's not intuitive at first. Does this break the optimizer or is it smart enough to do this well? I get nervous when I see fall-through comparisons like that. Good mention, though. I use those functions a lot. Another lesser known function is NULLIF(a,b) which returns null if a and b are equal. Thanks, lassevk. This worked for me! I implemented .Equals according to the guidelines here: http://msdn.microsoft.com/en-us/library/336aedhh(VS.80).aspx Unfortunately this approach is not practical for my projects (hundreds of tables, procedures, gigs of data). This is too high-friction to justify on an existing project. I wish that were true. I really do. Plus, I don't want to have to write lots and lots of fixture code just to get the db into a "ready to go" state. tvanfosson: yes, I agree. Good point, Pax. You get your randomness by simply randomly allocating pastors to pastor-0 through pastor-12. It doesn't feel random because all 12 months are determined by one initial shuffle. It is random though--this is similar to how card games work. You don't typically shuffle between draws. That's a good idea, but I'd like something a little more guided before we get there. Plus, the VBA won't be used in Office all that much. finally a reason to unblock Youtube at the office! +1 for the VB6 backup plan No. The time required to build the datatable will be tiny compared to the time you're spending now. Indeed. I revised out the contradiction. Thanks! Are you able to use an asp:listitem inside your item template (instead of an li)? I think it would work if it will let you add it. It might not allow it without being nested within an asp collection control, though. You can also join to the table-function with this approach. In my case, the missing file was MSVCP71.DLL, which was installed on the dev box by VS.NET. This assumes you want to insert after the first character (but doesn't assume it's an "H"). If it IS always an "H", and the only "H" in the cell, then @Tony Andrews's answer is good. What's an example input that fails with your first method? Ah, I get it now. Math.Pow(10,18)+1 will be true with mine... Here's a blocking queue: http://www.eggheadcafe.com/articles/20060414.asp Duplicate: http://stackoverflow.com/questions/349398/aspnet-session-state-service-information Duplicate http://stackoverflow.com/questions/349503/aspnet-session-state-service-information +1 for partitioning I don't think you can update the virtual tables directly. Instead, I think you need to join to the actual tables and update those. Where did you hear this? Another drawback to sessions is that they are stored on the server. Viewstate is stored in the page itself. Just use the subquery and remove the parans. A single order by after a bunch of unions will order the entire set. Also, use "UNION ALL" here. Yeah, it's valid. I doubt myself with simple things from time to time and occasionally find a good reason to change my ways... I do not recommend this approach unless you add code to handle collisions. The service could be running before you login. How long did you wait? What about permissions? Does the service have access to the resources it needs without a user being logged in? Holy crap--I didn't know CAST would truncate like this. I always assumed that the returning varchar would be sized to fit what CAST was stuffing into it. I have some code to check up on...bbl can you insert a duplicate *after* the primary key is applied? Great, glad it's "working" now. Too bad you had to do all that rework. I don't think this is ASP... Is this ASP or winforms? C# could mean ASP.NET or Winforms... the difference is important I've made this error myself... +1, thanks! TT beat you to this answer so I accepted that one. I'd keep an eye on partitioning, too. It's not ready yet, though. http://dev.mysql.com/doc/refman/5.1/en/partitioning.html OK, since Chrome failed, we can ignore all the browser stuff, like cache, permissions, etc. What about the OS and network stuff? I assume you did a reboot, too...? (Note that Chrome has to work on a good machine to be a valid test on the bad machine) This has the same limitation that it counts multiple occurrences on one line only once. I am guessing that this behavior is OK in this case, though. Yes, using existing, well established software. I think it's definitely the F/OSS part of it-- not the GPL specifically. I think it's definitely the F/OSS part of it-- not the GPL specifically. I've clarified above, thanks Good point, I'll make sure. I agree with your first line. And yet here I am... ;) Yes to the enum for playing around with the numeric representation. To display the text to the user, though, I'd be looking up the strings from a resource file or the database. I clarified the question: IT is opposed to F/OSS in general, not just with providing credentials to it. I agree--and I should have clarified earlier. I wasn't actually asking IT for any passwords. I just wanted permission to authenticate against the active directory, which doesn't require any admin credentials. After discussing this issue with the IT manager in person, your list seems to cover their hesitation. Thanks, Jon--I always forget the "@" on this site. I turned it into a function. this should make your validation code simpler Agreed--having a column in there that maintains this state is clearer. On the other hand, if you're doing this to generate a total or some calculated statistic, the other answers can help. Or, if you are using temp tables, then this answer works well, too I like this approach, too. Yuliy covers why your version is failing quite nicely. I also agree that copying elements may be easier and clearer. Plus one for finding the reference and suggesting a good alternative. I know what you mean. The more I use C#, the less I like using VB. Now that you mention it, that makes a lot of sense. I'll force the app down to one thread and see if the problem goes away. +1 clever. I tend to avoid triggers when possible but this is a nice, (hopefully) light-weight use for them Don't be--sql is wonky. @Tom: I agree with you. In some cases like this, the SQL Server optimizer will convert this to a more efficient left join with group by. As you say, though, you've got to check the query plans to make sure they're performing well. +1 for aspnet_regiis -i -- which usually fixes this issue for me. One other point: make sure your app is actually supposed to be using v1.1 of the framework. If not, go into IIS and switch it to 2.0. Just to be explicit: =IIf(Fields!STATUS.value = "Completed" AND Fields!DONOTINVOICE.value = True, Fields!ORDERCOST.Value, 0) Make sure you add formatting in your presentation layer to round that down to 1 or 2 decimal places. Otherwise, you're likely to run into things like 33.33333... After using this approach for a couple weeks, I'm very happy with it, thanks again! Google's powered by sites like this so easy questions like this are fine by me. I'd much prefer these to all the silly poll questions. True--I can't argue with you there. Can you edit your answer or question with the benchmark specifics? I'd have to see some very, very compelling evidence to give this performance tweak a second thought. Do you have a measurable performance problem related to this? Wow, I use NULLs a lot. Strings are really the only place where they don't fit nicely, in my opinion. OP might be using a date column in the DB--we can't see that part. I agree that you should use parameterized queries, though. Thankfully it doesn't look like you are inserting any text so strictly speaking you're probably safe on this one (though performance could be better). I'd try the query without it. Are the records actually being inserted? I guess I was just surprised by the "never, ever" part My answer includes the scope_identity version for Mysql, as per the tags. No problem--i miss them often enough myself. 1. Can you post the final CommandText that gets executed? 2. Are the records actually being inserted? OK, how about "SELECT last_insert_id();" at the end? OK, how about "SELECT last_insert_id();" at the end? Does this mean that I could work seamlessly with other devs on a 2.0/2005 project, while running VS2008? I really don't have to upgrade the project file? And VS won't encourage me to use language features not available in 2.0sp1? Am I understanding this correctly? It'd be an easy sell if we could upgrade one at a time vs. 25-50 people all at once. Alas. Poster is working in javascript--it looks to me that you're mixing C# and javascript. Yes, it's unpleasant to figure this out in practice. System.Threading.Thread.Sleep(10000) This is a duplicate of http://stackoverflow.com/questions/321180/how-do-i-test-database-related-code-with-nunit (a question I asked, too!) Ah, I see. I thought you could still download the doc in its original format, though (pdf). That may not work I guess if you need the actual acrobat experience inline. In that case, I think the iFrame is probably best. I'm with LeJeune on (2) being OK--I've used that intentionally to swallow up nulls as "" I think you need to be more specific. What's the available point-space? Integers? Reals? There are infinite points unless you constrain the problem otherwise. I agree with you, I'm just trying to be fair to all possibly guilty parties. This should be easy to confirm with a simple Html page, maybe with a little JS, if necessary. /32 probably allows anything in the server's D block to access your system. That is, given an IP in the form a.b.c.d, what server1address/32 means is that anyone with the same a.b.c address of the server but a different 'd' number can connect. What about the GAE? The code goes into the dll so it doens't need to be included when you publish this way. As others have mentioned, yes, it can be partially pulled out if the dll. VB initializes integers to zero automatically in most cases, including this one. in that specific case, I agree that it'd be nice to have. How is the stack not accurate in release mode?! if this is a web project, you can leave off the ToString() as the Value property is a string already. ah, it looks like the "listbox" should have clued me in that it's not an aspnet project. Sorry added in my version with 'Nothing', and +1 Yes. Yes it does. @Zubair: this is pretty much what @tvanosson suggested. I suggest you upvote and accept his answer. 39 seconds quicker I think the wrap around effect would be less desirable, IMO. Hopefully this encourages you to go with whatever is clearest--not fastest. They're all fast. http://www.google.com/search?q=paging+techniques+sql Unfortunately I don't, sorry. That's a great point @Joel. Can I assume that the actual address is absent quotes? I prefer this method (punch in and punch out on one row). It makes duration calculations much easier. Plus, I think the time to resolve time clock anomalies is at the clock, not in a report later on. Hopefully, but I wouldn't be surprised if it's as simple as "it works." They seem to be practical people. if it's actually connections that you want to preserve, you're probably using connection pooling. They DID hire a designer. I assumed that the SP method was covered by option 2. I updated the table with the Mac info I think that part is fine. I think the argument is between catching a general exception and factoring our the handling code. If the log code is less than 3 lines, I'd go with the version I presented. If it's more than that, your dev's version is reasonable. Got me by 1 second. Yeah, examples of this one are really hard to find. I think amazon's links have actually improved quite a bit in recent years. Now they often include a description of the item which is nice. Copy/paste is actually the reason I think people don't care. This is nice and easy if you have a small list of static addresses to block or allow. If you need something programmatic, try @Mitch Wheat's answer. +1 Mitch - good idea I'd make a mention of this behavior in the documentation. @Keltia, I don't think this is a backup issue--this is what source control is designed for. Although, I agree that OP should have backups, just not for this. You want to search all columns/rows for a particular number? Can you restrict it to numeric columns? Integer columns? Identity columns? If the initial string has only a username and the optional string " joined", with nothing else, this will work great! Also provided no one has " joined" as part of their username :/ Nice find, @Gortok. I voted to close. I think the idea is that the user running the app isn't the one you are trying to keep it from. If that's the case, then you'd have to encrypt it. Jared: if you went with samba, you'd have to tunnel it through SSH anyway--so it'd be equally safe as ssh. If you really want an easy drag-drop method, then WinSCP is nice, as suggested by others. This isn't SQL injection if the users are actually writing SQL. It seems the phrase has properly communicated what you meant, though! @TheTXI good catch. As written, that SQL is mighty dangerous. I'd agree if the problem was more clearly defined. I did a lot of guessing. If you can straighten out some of my assumptions (below), I can update my answer with code. You should put the entire check in the lock. Though to be sure, you need to clarify what you want. Can you download multiple files at once? If they change their mind before the download is complete, do you abandon the first download and start another one? If you truly can only download one file at a time, I'd unhook the async event handler while it's running, and rehook it when it's finished. I added some comments to your question--I need just a bit more Right on. Take a whitelist approach--not a black list approach. Ah, you're right. This works in 2005, but not 2000. http://wardyit.com/blog/blog/archive/2006/02/15/84.aspx I fixed it -- it just needed to be indented four spaces to show up. You are right for *EXCESSIVE* indexing. Normal indexing tends to help with selects AND updates/deletes (the record must be found before it can be updated/deleted). I've yet to find a case where I had a reasonable set of indexes on a table and they were found to be hurting performance. Can you post the actual table definitions (including indexes)? You will get a much, much better answer. +1-- looking at the query plan is extremely helpful I'll grant you that--a write-heavy/read-light system does often require a very different db strategy. @jishi: yes, but well coordinated indexes on both tables can make a big difference. You have to actually drill into it. Then it IS flash, and awesome. http://finance.google.com/finance?q=INDEXDJX:.DJI,INDEXSP:.INX,INDEXNASDAQ:.IXIC Add more references Plus, I'd say performing 1 billion runs in under 30 seconds is pretty good, so what's the fuss? http://www.themathpage.com/aprecalc/permutations-combinations.htm Good call. Merging in my answer: if you put each of those onto one line (not inside {}), you'll get a more useful stack trace. Or the debugger method, works nicely, too. Are you getting script errors in the browser? nice work, thanks for posting the final answer Most browsers won't allow you to open popups programatically without the user triggering them. If these popups are not the direct result of a user click, I think you're out of luck. Please post your table schema! The 2005 version of that doc says the same thing (http://technet.microsoft.com/en-us/library/ms190273(SQL.90).aspx). I don't mean to be pedantic, but does that mean I can add/drop columns? That's the challenge of any design where scalability is a high-priority issue. Based on "Edit 2", it looks like I was on the right track. It'd still help if you posted the db tables--then someone will give you a nice answer. I like this idea +1 I don't think that's what Ash was looking for but I found it interesting. Good question--I'd love to see a comparison like we often see between browser versions. Run any query without manually started a transaction and it will run itself, within an implicit transaction. Yes--it's all browser/server specific. Yes: IE has a 4GB limit I updated the answer with IE6 info, thanks for reminding me I'm on windows so I don't think that will work for me. Thanks, though. According to the passenger site windows is not supported. If it is, please provide a link saying so and I'll check it out! You can pull out the parts you need. Roger turned it into .net 2.0 for you. This really isn't heavy solution--it's the right way to do it because it's clear, easy, and light. +1 Good point Joel. I updated it with an order by on the temp table select and added in the window criteria. @Electrons_Ahoy: if you really only need a subset of the records, checkout the paging links I included--there are lots of ways to do this more efficiently without temp tables. Dude-- don't talk to John Lam like that. It's John Lam. What then is the syntax for a group?Is it possible to put his info in the authz file so I don't have to restart apache after every change? Test it and let us know! Does it have to go through asp.net? I had to add a trailing / to my Location () to make this work. Thanks! http://www.svnforum.org/2017/viewtopic.php?p=21502&sid=888ad3d666f135fb6251766f39a9dd2c Some of the top results are other ZoneAlarm users with the same complaint. I wouldn't worry about it. It's not likely *your* app that's doing it, anyway. Zone Alarm tends to be overly aggressive with its alerts, IMO. I'm with sam on this one. I assumed that items ought to be centered with whatever the img height turned out to be. I think we could all stand to cool down a bit though. True--SQL is rarely pretty. I updated my answer wth more info and more questions. Clever--I like that idea nice - i like it. @Pax: me too. I edited the title. Dupe (sort of): http://stackoverflow.com/questions/6301/why-is-array-length-an-int-and-not-an-uint I like your idea, though, about forcing non-negative numbers by use of uint. Take a look at spec# (experimental)--neat stuff for contract programming. http://research.microsoft.com/en-us/projects/specsharp/ Either way requires an explicit cast. You're narrowing either direction in a sense because the window is shifted. Ack! I just deleted someone's comment accidentally. Sorry! Any tips on how to implement the Vault side of that? This is the best help so far but it's really not what I was hoping for. That's exactly the same thing as adding TOP 1. It's just a different flavor of sql (Mysql, etc.) This approach doesn't require a reboot. Hopefully SSCM doesn't either--update us if you determine that either way! Good luck Quotes! (Single quotes) I hope you have a where clause in, too. Otherwise, you'll be updating EVERY record in that table. Yes, this is a smell that indicates something very wrong. 24h time isn't the solution, though. Storing time as a proper datetime is the solution. That said, poster already knows this so the horror isn't warranted. +1: do not roll your own crypto If you're thinking about things like account numbers, I typically sanitize them (remove dashes, whitespace, etc.) and pass around the number. When presented to the user, it can be reformatted. Welcome to stack overflow. Thanks for wording your question clearly, providing code, and showing what works and what doesn't. If you have useful information in your apache logs, please post that, too. Sometimes the redirect issues become more obvious when you see the logs. You just want anecdotes? Maybe shoppingcart has a row for each item in a customer's cart. Welcome to SO. You should update your question with these followup notes. This isn't a discussion board--use the comments or question for question-related info, and answers for answers. I'm glad you figured it out. This particular issue has bitten me before. I really think you should consider going with Marc--his answer is the right way to do this. I hope you have considered the usability implications of disabling that feature. It's there for a reason. That said, I'm curious, too, how you'd do that. I'd create these indexes: Posts{id, tag_id}; Tags{post_id, tag}. Then, run your query with 'explain plan' to see if it's performing well. +1: regex is extremely hard to read, but this is a tooling issue, not a language issue I encourage you to follow Martin's advice and go with the predefined codes, which are culture aware. You might not need it now but in the future it could make things easier. The key here is that Integer is a reference type and int (or the numeral 5) is a value type/primitive. One of the issues is that while Svn has a repo-wide version number, that changes on each commit, vault doesn't. Each folder/file is versioned individually, making the concept of a changeset a little harder to determine +1 for the downsides and alternative Don't forget to sanitize any user input! escapeshellarg, escapeshellcmd, etc. +1 good, classic example Look into obfusacators. Although you'd have to find one that was configurable--to strip comments only. +1 beat me to it. This is nice because you can reference other repos on other servers if necessary--it's quite powerful OK, OK, micro-opimizations are not good--but what's the answer to the question? Can you try out different behavior with compilation flags or method attributes, etc.? +1 for the question, and the comments thus far. I doubt this is something he'd be happy to have. Yes: I updated the answer with an example. Joshua, I appreciate your help here. Your suggestions are good, but they don't really answer my question. What I've done is what @Brettski suggested--I'm going to have to go with him. Does that apply to variable names? Or just data? Thanks for following up! If this query will be used regularly make sure you evaluate its performance. I guess I assumed that SQL CE wasn't an option. If so, then this is great! I agree with that. I don't think that's true--can you provide references? But does it work on Windows? No, that moves my working folder, which is great, but doesn't update any properties. These are absolute urls to the old server. I was hoping for something easier than that, thanks for the suggestion, though. Another reason to use linq is that, however bloated the query may be, the SQL engine authors might have a smaller set of query patterns to tune internally which would be nice. +1 -- leverage existing credentials whenever possible. It looks like this is what I'll have to do. Thanks for the nudge. How do you write XML files with WIX? Is there a way to do this that isn't a hack? Nice explanation. This is a good example of why you should use UTC datetimes for your date arithmetic. @Whatsit: in this case yes, but if wee add DST into the mix, UTC is the only reasonable way This is the biggest draw for me It does go away when running a single thread. Now I just have to figure out why... Unfortunately I ruled out format issues because this doesn't occur consistently. No, each thread has its own connection. In fact, I changed it so that each thread would create and open/close the connection each time it's needed. This didn't help. Unfortunately I ruled out format issues because this doesn't occur consistently. That is, it works and fails with the same data. @Igal Serban: unforunately this has not solved the problem. I think you're on the right track, though--it seems to occur in spurts, perhaps during high load times. As requested, my version of librfc32.dll is 6403.3.78.4732. +1: Good points about the optimizer and design I agree that reducing the number of connection cycles by persisting a long-lived connection would probably help, it'd be nice, though, to know what the real problem is. @thiru: welcome to stackoverflow. Unfortunately, I don't follow your question. Can you please take some time to reword it so it is clearer? Once you do, it's likely the question will be reopened. That debug is a good idea in general, though, I'll try it. Of course you could use a trusted third party like Paypal, Google, etc. @Kyralessa: Good point. Can you link the source? Unless you're quoting yourself... +1 when used properly, these can offer amazing improvements in performance Yeah, they are great, just be careful with large tables as they can become quite enormous and do more harm than good if used improperly. Like all things performance, you need to test a representative workload before and after. I would assume that the alternative would be connection pooling, though I admit that is a lot to assume in some cases. I agree on the var keyword--it is useful when the object's type is extremely obvious (e.g. var NewList = List), but not in many of your cases. Good to know, thanks THanks Maurice, I updated my answer. I can't delete my answer as it's been accepted. I encourage Joe to go with @Esko's answer! I get no errors at the moment in IE8, but your page is bombing with script and php errors so those probably need fixed first... Sorry, @Michael Meadows--I didn't mean to step on your edit +1 That's so awesomely simple, clear, and fast. Nice mind reading! This is a nice rosetta stone for an extremely simple example but really doesn't do much to contrast the two. This shows syntax but doesn't explain why you would (or must) use one or the other. This might be useful: http://www.ruby-forum.com/topic/57923#47559 How do I specify the number of decimals as a variable? I suppose I could do (1.2M).ToString("D" + x) but that seems a little hacky OK, so generating the format string ("F"+x.ToString()) is the trick, then? I assumed I was just missing a library. Thanks, Joel! It's growing on me, thanks for the extension method, too. It's growing on me Was that the System.Diagnostics.Process class? e.g. http://blogs.msdn.com/csharpfaq/archive/2004/06/01/146375.aspx added reference to a similar question If you are going to use the  syntax, you could put the conditional logic for your CSS include in the same place Please note: the difference between "F" and "N": "N" will insert a thousands separator while "F" will not. What's the primary key on the table? Posting the table DML and actual error message would help, too. Remove the "End" keyword at the end. (or add the word 'begin' after 'as') please post create scripts for your tables Note that if you replace ThreadRating with Inserted, it will only use what you insert, excluding what is already in the table. If that's what you want, great! I'm very curious about this, too. Benchmarks or credible sources would be much appreciated. Is there a significant difference between hash joins and nested loop joins? It's not clear if you're suggesting that the distinction justifies one or the other. Are you saying then that there's not a general answer (it depends heavily on the query)? Is there no easy answer to this?: if the index *could* be unique, should I make it unique or not? If i'm using a secure smtp server, how far will I get here? Where would I supply a password or start an SSL/TLS connection? @devinb: thanks for the tips. This is for internal use only, and for a quick sanity check, won't actually send anything. There's a step for that later on in the process. Thanks! thanks Eoin, that extra link is very useful I'm willing to use dirty tricks! It can't be *that* crazy if VB happily accepts it...well ok, it can be, but I'd like to see... Declare what as virtual? The methods aren't present in the base classes. Right. This is what I started with but without control over the classes, I can't do it. That's a nice idea but the whole point is to eliminate big switch blocks like this. Thanks, though. So I'd need to subclass each of the three classes (base, a, b) and add in an interface each time, e.g. MissingBaseMethods{ Add(); CreateNewItem();}; add a little NotImplemented code for the base, ignore A and B and then instantiate these new classes? If I got that mostly right then it might not be too bad. It'll avoid reflection and keep the method calls nice and tidy. I'll have to think about it. Thanks for the help! In general I couldn't say, but in this case it's because I'm not using VS2008. Thanks again. @Kevin, thanks for the help but what I was trying to show is that I can't touch that code--I don't control it. the //no present lines are actually NOT in the code file--if they were there I'd be golden. @Kevin: the methods aren't in the base class. I commented further on your answer. MStodd, thanks for the suggestion but unfortunately I don't have control over the classes. Additionally, those method calls aren't actually present in the base class, abstract or concrete. Ah, yes of course. Thanks Lucero! Is the issue that clicking multiple rows causes multiple rows to highlight, rather than just the last row clicked? That covers it. Don't forget that you *do* need proper indexes for good insert/update/delete performance, too. Like all things, it's a balance. You need to provide a lot more information. What are you trying to run? Are you executing through Visual Studio? Some other ide? @dance2die's got you there, Mark I'm not using this for paging but I just realized the parallel application. If you find any good duplicates that apply here please let me know and I'll close the question. I like that idea, thanks @Jacob: thanks for the suggestion. I made this return tables and implement IEnumerable with the yield keyword. I also turned it into an extension method as you suggested. Works great! Mike- I think you could mostly remedy that by including the global.css always--for everyone, and only selectively including the admin.css for admins. Unfortunately, I just learned that these don't work for Express edition. This might help: http://www.cpptalk.net/confused-about-the-meaning-of-the-semicolon-vt11965.html For SQL Server, you may want to make that a UNION ALL since UNION removes duplicates which can be a performance hit...unless a person can have multiple seats at a table, in which case UNION is appropriate. I'm not sure if Mysql has the same semantics. Sure it could, but it doesn't. I agree with you, Adam. I would guess he's doing it this way so that the object reference is nullified so that if DisposeObject is called again with the same reference, it'll exit early. thanks for the feedback. i've updated my code ref to match @Jon B. I'd delete my answer as it's now worthless, but the comments are nice so I'll leave it. This might help: http://social.msdn.microsoft.com/Forums/en-US/linqprojectgeneral/thread/5edb3dd0-c778-47e2-b89d-a9c90a0bd1bc Yes, my mistake. Thanks for the explanation--a private class wouldn't make a lot of sense This is nice because nothing is hard-coded in strings, but it requires a round trip to the database to load the status. Is there any way to get around that? @Simon: (@@ROWCOUNT) > 0) returns the number of affected rows from the previous query. In this case, your query will only return the updated timestamp if a row was actually updated (otherwise, @ROWCOUNT would equal 0). This way, if you don't get the timestamp back in your app, you know that the update failed. Linq-to-Sql != Linq-to-Entities This is a simplified example. Also, if I can easily avoid retrieving a record from the database just to update it, I will--I don't think that's premature. *sigh*...that's lame @Graham: Can you add column headers on your sample tables? @Graham: I've updated my answer to hopefully capture your changes. Note on @@Identity or Scope_Identity(): it retrieves a value that has *most recently* been inserted in the desired scope--not the *next* value. That's why in my answer I generate the number myself inside a transaction. If you actually want the identity value, then replace the last error check with this: "SELECT @ERR = @@ERROR, @ID = SCOPE_IDENTITY()". If you want the new or existing RefID as you said, don't do anything as it's already captured with the "SELECT @RefID..." It's not much better than a case statement but you could use the dreaded dynamic sql It seems to be 6 as the array is zero indexed I would guess that starvation is unlikely but not guaranteed. Just a guess, though. @devinb: I completely agree with you--a failure in the test procedure was a big part of the "unfortunate chain of events". Perhaps my tone was a bit harsh on the new guys--perhaps not--they've actually been around too long to be called newbies. Again, though, I do agree--I want to fix the system, not treat the symptoms and isolate people. I like this idea. It seems much less adversarial--much more team oriented, which is good. You're absolutely right--I might be attacking this from the wrong angle. We DO need more rigid code reviews but that's not the failsafe that should have saved us--the testing process broke down in a way that was unexpected but CAN be fixed. All good ideas, thanks! I don't like seeing assignments after the '?' in ternary expressions either Based on the answers to this question, I'm strongly leaning against the system I proposed. I like the idea of more mentoring and more code reviews to improve code quality while plugging the hole in the test procedure to prevent additional hiccups. It's not the trunk I should protect as much as the actual releases. @rmeador: agreed--I'm very thankful to the community. Also, it's easy for me to change my mind when I'm obviously and publicly wrong :) In this case I don't think a DVCS would have helped us, though, I'm a fan, personally. I'm pretty sure that approach won't work for Alters and creates related to stored procedures I completely agree for open source projects with faceless committers Does it work in other browsers? Your title implies that it does but it's not explicit. Interesting approach. Are there any performance considerations to catching the full page output like that? Or possible issues with changes to the naming convention in the future? Which version of C# are you using? VS2008/C#3? Did you get it working? If not, can you update your question with the errors and your code? That's an interesting idea, too, but I don't think it'll work for me as it has some serious limitations with post backs and I'm trying to limit the changes I'd need to make to the existing code base. Thanks! That second link is broken. This might be similar: http://digitalbush.com/projects/watermark-input-plugin/ I recently had an auto update fail. The log file @qat mentions indicated that the .war file was corrupt. Once I reinstalled that file manually, everything worked fine. This has happened to me several times and is quite annoying. Open the DB in SQL Server Management Studio if you can and look for 'dbo' or 'youruser' before the stored procedure. If it doesn't have 'dbo.', drop the existing procedure and recreate it with that as a prefix for the procedure name. +1: comprehensive and safer solution +1: Use debug for almost everything so that when you move to production you can tone it down easily to a tiny amount of infos, and any warnings and errors that your app generates. @Marc: that's true. In my case, though, I have Skeet's book at hand, not the spec. I added a link to a more accessible blog on MSDN which might be more appropriate. One subtle point about your two functions: *both* initialize an object, but only the first actually impacts the caller. You said this all correctly, I just wanted to make it more explicit for future readers. +1: it makes extension methods much clearer to think of them this way I'll give that a try, thanks for following up +1--small tables threw me for a long time because they refused to use indexes in many circumstances (for good reason, I guess) The problem is that these aren't small dialogs--they are rich interfaces that need tested. I'll try something else, I guess. Thanks! Apparently I'm the only one... good assumptions--I'll check it out, thanks If you post a tiny, but complete html example, we can try to reproduce the issue... I'll give it a try. It seems crazy to me that there's not a jquery built-in to get a querystring parameter value without using plugins or complicated code. Yeah, I'm beginning to learn that--it's by design. @JaredPar's right--most trivial software has bugs. All non-trivial software has bugs. It is simply not possible to write interesting, bug-free software with today's tools; and we seem to be cool with that for the most part. Software really does an amazing job considering how complex it gets. Even notorious office always seems to recover my unsaved documents should I cross it :). We've come a long way this decade in *handling* the inevitable bugs better. s are good for paragraphs but really don't serve any purpose for layout beyond adding some space between paragraphs or indenting lines, etc. That is, a typical layout would likely use s for the major blocks, including the block wherein the s are placed I would call that a 'literal', not a cast--you're not casting anything Yes, that is technically true. It would go against how those tags were intended to be used, though (or at least how everyone else uses them). No, but I did talk to some folks at OSI through our paid support. Poster mentions that this isn't available. If you are looking for user security (to handle logins), then yes there are many. But that's not what I think you're asking for. How is user data different from say...invoice data or customer data or location data, etc.? Nice find--that's a good reference What platform? Windows? What browser? That sounds like a good plan A recent check of the source code shows that SO actually does use DIVs instead of tables in a lot of places--this might be new since this question was asked. Awesome link, thanks! If you must work with arrays, manipulators like this would be helpful. If you have coworkers who might use it wrong you could give it a name more indicative of its shortcomings like 'PrependSlow' or 'PrependAndCopy'. I like it +1 You're getting vague answers because you asked a vague question... You might be able to get by with 2008 SSMS Express, too...which is free. Hire a coop with CS101 knowledge of databases as your DBA and your database will automagically become denormalized (test your backup strategy first...) Those are great for the symbols but how about the bar? Good point, I like that better, too. Just to be clear, you want the two calls in your example to have different eventIDs? Obviously the names should be changed to represent what's actually being described, too. I strongly encourage you not use the code in your edit. Aside from a weird break from convention, this could have slight performance and severe localization issues. I always love me some ZedGraph Agreed. 300 rows is nothing. With connection pooling, and a light query, it'd be no big deal to hit the database one at a time for 300 times. Vincent--the asterisks were showing up, I hope you don't mind that I edited them in with a backslash Will there be more rows in the table that should be replicated appropriately or is it always just the one row? As long as it's a text-area, this effect can be helpful. I don't like it on what appeared to be single line text inputs, though. I have a couple instances of that and hitting enter to submit the form just adds a carriage return. I'll take a reasonable upper limit like 16 chars over an accidental no limit that works for some parts of an app but not others. Please don't do that. It's awkward to use. Instead, preselect whatever list you're populating to the desired "default" country There's a bit more to it than that...http://code.google.com/apis/ajax/documentation/ With regard to websites, I would be a sizable fortune that you are in the minority. The average password length for a regular website is probably less than 8 (assuming the minimum is less than 8). Does the timestamp change when you do that? That could be a little clearer. Is it saying that if you can `touch` files with either w-perms *or* ownership? Could the user touch readonly files that are owned by someone else if said user has execute permissions on the directory? You might try something more friendly first in less you actually can follow up on your threat. Something like "hi, I noticed you're using my program. It'd be really great if you bought a copy so I could feed my family. Here's a coupon! Thanks!" Exactly. It can change, too, as the database evolves (dml changes, more data, indexes, stats, etc.) It's actually worse than that--deltas of 3.999 seconds could be included while deltas of 2.999 could be excluded. Datediff counts boundary crossings so 0 to 2.999 would be 2s or 2999ms while 0 to 3.999 would be 3s or 3999ms. The updated version is better. Can you add in some examples with === for a more comprehensive demonstration? The preliminary consensus seems to be that what I want can't be done. Thanks for looking, though! I hoped there might be some creative solution based (perhaps using views) or some performance tricks I should consider... The switch statement is certainly a viable alternative to actually creating a dozen procedures. It's less than ideal but a step up. Thanks! Assuming this is homework, please take a stab at a solution and we'll help you out. I agree. If regex experience is a requirement for the job (in that they must have it from day 1 and can't read up on it for day 2), I guess this would be good. However, I don't think a question as detailed or arbitrary as this makes sense--you don't learn much about the candidate regardless of their answer. If they get it right, kudos...but what have they really proven? If they get it wrong, well maybe the question was too narrow/etc. Agreed. I know where you're coming from with the desire for exclusive checkouts but once you get going with svn you won't need it or miss it. (and you can use locks until your comfortable). I'd say it's much more like those ropes ushers use to reserve seats. You *can* bypass them easily, but you're not supposed to out of ethical/social pressure What is the value of ElapsedMilliseconds when negative? I am asking more for the magnitude. Is it usually around -10ms? or is it usually -4000000000ms? +1 I cannot imagine how a regular expression could beat indexOf. If you don't need regex-power, don't use regex. According to this article (http://blogs.lessthandot.com/index.php/DataMgmt/DataDesign/changing-exec-to-sp_executesql-doesn-t-p), using sp_executesql properly can improve dynamic queries by parameterizing them. Note--the weird comment format is to fake-out the syntax highlighter My only suggestion might be to make this an assertion so that it can be disabled when you release for performance reasons (or leave it on all the time if that's what you want!) Not as straight forward as I'd like but a way out--thanks! Do you want box1 content to overflow into box2 like in a newspaper? Apple provides developers with apps in the app store with a regular dump of sales statistics. I was editing my answer to add this example but you've already got it so +1 to you! You'll definitely want to make a backup before doing *anything*...but you should be safe. Please post your code. You can't type directly into a div (did you mean input area? Or is the div being populated through some script?) Your first point is contradicted by many sources in @breitak67's answer (http://stackoverflow.com/questions/1034634/what-is-the-difference-between-select-and-set-in-t-sql/1034756#1034756) @vpsingh88: Note that table normalization != better performance (at least not automatically). There are plenty of cases where a side effect of normalization is a better design that leads to better performance, but too much normalization or poor normalization can hurt performance, too. And an example from those docs: http://msdn.microsoft.com/en-us/library/6h2ws3ft.aspx They already use RSS, too That's awesome, thanks! Thanks for the suggestion. Filed: http://dev.jqueryui.com/ticket/4644 I've never had c-c/c-v work in the console...instead I've always used Select/mark If you're displaying a mesh, you might want to use a graphics library instead....grids are slow. I can't imagine how bad a grid with 65k+ columns would be. +1 for guids. They're awesome +1: covering indexes are essential. With careful indexes and careful queries, 6mm rows is no big deal. You'll want `time`, too +1 Nice work around. I'd probably leave out the $='foo' part in the signature since the null check handles the default now. That's nearly there--you need to index into the select to get the selected option's value. I agree that if you weren't using jquery, this problem wouldn't be a good reason to start. BUT if you already have jquery on the project, go ahead and use it! I'm not sure why we can assume the problem is with IE-specific code in jquery... This is a browser flaw that jquery will need to work around but currently doesn't. I'm not sure why we can assume the problem is with IE-specific code in jquery... This is a browser flaw that jquery will need to work around but currently doesn't. I think you misunderstood me. You said it's most likely a problem with jquery's *IE-specific* code. I'm saying that we have no reason to assume that. I bet instead that it's actually IE's crummy garbage collector choking on code that works fine with most other browsers Beware, Russ, as this will overwrite any and all data in the column you update all at once. For large tables, this operation will consume lots of resources, too (disk/memory/log/etc.). I once did this to a table on a machine with low disk space...and there was not fun to be had. I'm talking about huge tables, though...100k-1m+ rows That's a neat trick. Is there a list of other =func()s available in word? Here's some more info on rand()/lorem() for the curious (as I was) http://support.microsoft.com/kb/212251 I'm sorry gradbot, bit this doesn't really help me. Running my test page without binding the datepicker **does not leak**. Memory usage goes up a little but levels off. Once I add the .datepicker() line, it leaks like crazy. I will try that Sorry, it still leaks. It might be slightly slower, but it still leaks 500-1000kb per refresh. Thanks for the suggestion, though. @nemo: Yes, it is definitely an IE6 bug--but since I can't get all my users to upgrade to IE6sp3+, jquery's gotta change. Many, many corporate users have no choice what IT pushes out and in my case, I have hundreds of old machines accessing the site with the old, unsupported version of IE. @Keith: unfortunately, this is for a custom app written by my company. With 25% of my users running <IE6sp3, I do not have a choice as to what I support--trust me, I'd love to just force everyone to upgrade. I also understand that is sucks jquery has to work around IE's bug, but that's why I love jquery: it lets me stop worrying about browser problems and versions, etc. Or so I thought. If I can't fix the leak, I have to rip out jquery or at least whatever part of it leaks and do something else. @Keith: the company that hired me to create this site cannot/will not accept a solution like that. We had a datepicker system in place with an annoying old-school popup calendar which worked. I replaced it with the simpler, flashier datepicker hoping that it would *improve* things. For 75% of users, it has improved things, but I can't just ignore the other 25%. I like the idea of degrading for those 25%, though, I'll think about that. @Keith, thanks for the follow up--this is interesting information. I wish all signs weren't pointing to: "you're screwed", though. I think CI would be a nice safety net, too, to make sure I have all my code in a VCS, that all tests are routinely run, etc. Those are things that can easily slide if no one else has to build your code. It would be far less painful if I could add work-around IE's bug with some server-side code. If such a fix is impossible, I guess my only options are (1) avoid JS like that used by jquery/jqui *or* (2) upgrade hundreds of machines on 3 continents. Fun. @Gabriel: I think the obvious answer to that is: upgrading requires resources (effort, time, money, etc.). I think the organization has a best-practice upgrade policy in effect for most users, but the 27% of users stuck with IE6sp1 are probably just forgotten. I guess it's not that they CANNOT upgrade, it's that me getting all of them to upgrade is not really an option because of volume, geography, language, etc. Right, I think this is what most people meant by degrading gracefully. Be careful with this syntax as it won't work if Table2 has an identity column and it will break in the future if Table1 ever changes without Table2 changing in sync (burned me before). This solution might be perfect for your case, just be aware of these considerations. @ScottStonehouse: if you collect all the other answers into this answer like you have done but with code (making it comprehensive), you'd definitely become the best answer. Ah I see. Presumably this is for a disconnected app, then, where the server time is unhelpful? emphasis on *or* Nice--I didn't know you could do that. +1 Please, please use a numeric, discrete type (eg int/bigint) for your table. Or a guid with newsequentialid that's another debate... @marc_s that's what newsequentialid is for (where available) I'd also add that you should use *signed* ints--not unsigned. Unsigned types give you double the range but I don't think they're worth the hassle of coercing your data layer, tools, etc. every step of the way. Plus, hardly anyone does this @marc_s--good points Using LINQ/extension methods, yes. What version of VB/.NET are you using? Post your html, please This is a little smelly--I encourage you to post more of you html/js--there might be a better way. You mean the order of your CSS definitions? Is it possible some resource files are not downloading reliably (other scripts, images, css, etc.)? In that example, yes, but in practical sql it would never be written that way. You'd have a table alias so it'd be more like `SELECT C.Name, C.Address FROM Customers WHERE Customers.Name > 'def'` http://www.joelonsoftware.com/articles/fog0000000043.html #5 It's not that crappy code is the goal...it's just often what comes out. True. "Cheap" too often ends up being more expensive in the long run...buggy, confusing, @tvanfosson: ah I see, I completely agree. I can't imagine working somewhere where quality wasn't at least a goal, either. This question might have a better chance of survival if you add: how well are these characters supported on different platforms? I disagree--if this belongs anywhere, it's here. In VB: CInt() rounds. Fix() truncates. Burned me once (http://blog.wassupy.com/2006/01/i-can-believe-it-not-truncating.html) @aib: I would guess because /**/ are C style comments and the question is tagged for C how large is the file? http://en.wikipedia.org/wiki/Modulo_operator @Bjarke Ebert: thanks for the correction: I've updated the answer That makes sense, thanks for the follow up I think sniffing the network would help. Or at least additional logging within your SMTP server If you are sending one message with 10k BCCs, the limitation is almost certainly out of your control (disk, bandwidth, SMTP, etc.) unless you redesign how you send messages or change your infrastructure (e.g. different SMTP, beefier hardware, etc.) Nice ideas, thanks! Tamara, thanks for following up. I'll correct my answer. That's an interesting idea. It's definitely not script related (I just posted an update) but your technique might help me here. +1; this might be confusing in vb, though @Joel: So instead of letting users run queries *directly* against the database, I could let them use this thin wrapper? I like it, thanks! And yes, you nailed my next question. +1 Thanks for this, it looks promising. It would benefit from an example, though. Please post more of your code--the *full* line from above and the markup it is referencing. Very useful, thanks! Apparently the keywords I was missing in my search were "show/hide". Possible dupe: http://stackoverflow.com/questions/455958/hide-show-column-in-an-html-table +1: love it, thanks! +1: this is why $.support lists *features*, not versions The value matches (LEFT/LEN) won't work like that in practice--I just used As and Bs as an example. This is perfect, thanks! Solved per @Brian's answer. Thanks to everyone for your help. If my vague question led you in a wrong direction, I apologize! Thanks again. @EricLaw -MSFT-: thanks for helping out--fiddler2 is an essential tool in my box. Thanks for showing me another great feature of it. @Joel, thanks for the input and confirming what I recommended to my customer (transactional replication or something similar)! I'm looking at this to use in the mean time. Dirty reads are acceptable. +1, thanks! Accepted (I was holding out to see if other answers would come in...) @Raj: hover over the relative timestamps to get actual timestamps with seconds you should accept answers to your questions and vote more! Are you asking how to fill the select lists or how to query your database given certain selected values? What database engine are you using (e.g. Mysql, Sql Server, Oracle, etc.)? web or desktop? also, the keywords I think you are looking for are "master detail"--that may aid your search ok desktop--cool--what version of .net? Winforms...wpf...? I've dabbled with using a WIKI for all technical project documentation--this made it very easy for *all* devs to maintain it. I wrote 95% of it initially but after that, it lived on as a well-maintained, accurate document, without becoming a burden to one person (i.e. me!). Do you know if this applies to *transactional* replication, too? I'll test it tomorrow to see... are you asking technically how could it be handled, or practically how might it be handled? Agreed. This will be tricky the first time since you haven't done it before; it will be worth it though as an event-based solution like @Michael Petrotta provided is the right way to do this and once you figure it out, it's quite elegant. Perhaps one could monitor the power draw? I don't know if modern USB circuits provide that information... (retagged to java) I like this--we can surely come up with a better name, though. "liveAnotherDay()" or something... Here are a bunch of examples http://dotnetperls.com/7-zip-examples Please add some more info--maybe I'm missing it, but I don't understand either what you're trying to do or what the problem then would be. You can call it multiple times. I think you're hunch that this approach is wrong is right, though, I don't know much about this area--sorry! Does phpinfo() agree that gd is enabled? I'm sure it looks nice and I'm interested in the solution to this problem, but as a matter of personal preference I don't like animated scrolling @Brandon Wang, fair enough Maybe some other addin messed up the settings...or maybe it was one of these http://www.encyclopediadramatica.com/index.php/Computer_Gremlins @x2: I would say yes, that is commercial use. It would help if it wasn't installed on your work machine I think that's what we want here--an actual backslash with an actual dollar sign to be passed as a regex Please put a little more effort into your question. Are you developing an application or did you just notice this error in there while poking around? +1 Hints are good If this is homework--which is ok--please tag it that way so we can help you with hints and guidance instead of answers Best quote ever: "I asked the internet and didn't come up with anything useful." I suggest you take your best shot and we'll go from there (post what you have so far!) are you talking about this thing? http://www.theexceladdict.com/images/zoom_controls_excel_2007_2003.jpg FYI: this looks fine in IE8; but yes, it's wrong in IE7 @tsubasa: I said *if this is homework*--I didn't say it was or retag Agreed--it works fine for me, too The only other thing I can think of would be accidental damage to a database. I'd consider this low risk, but considering that many people don't properly version their databases, it's a risk. Though the risk isn't much smaller with RTM software... +1--didn't know about the .Value property Do you want the union *or* the intersection? In your example, does "not defined" mean you don't care what happens or you want it to actually say "not defined"? Is either/both list sorted? +1 -- all very good points Thanks, Joel, appreciated How many terms does a typical resource have? Dupe: http://stackoverflow.com/questions/844567/any-way-to-prevent-master-pages-from-changing-element-ids More specifically http://jqueryui.com/demos/datepicker/#min-max I know I'm just talking to myself here but... @Sakthivel, it would be courteous of you to accept answers to more of your questions and/or contribute to others' questions hide...what? A div? The entire page? Do you want notified so you can hide yourself in a closet...? missing the `]`? Maybe OP is thinking of _BeginRequest? Your request is a little vague. You give a signature that tests a single number but then ask for a data structure of (1,N]. Do you want an algorithm that generates a dictionary or just a one-shot function that checks if a single number is prime? What's your source for google/ms password requirements? +1 -- this is the proper way to handle your requirements What's the custom validation layer? Please post your code +1--more complete (and correct) than my answer was This is an interesting idea--references to benchmarks would be great If you use this approach (which I like), I suggest using a `data-` prefix on your custom attributes. That makes it future compatible with HTML5 http://ejohn.org/blog/html-5-data-attributes/ This is a common and valid approach. I suggest that if you are anticipating a lot of data that you go with something else, though. I've found that SQL Server can run into performance problems with this model. This may be different with filtered indexes in SQL Server 2008, though... I think your read performance will be comparable to a regular shared directory. However, your insert/update performance may vary dramatically depending on your workload b/c SQL Server maintains transactional integrity with files. I'd definitely add insert/update/delete to your test list If you're learning and you like it, go for it. If it were part of a professional/work project, I'd look into existing solutions first; for hobby/educational work, this is great How about posting the code you have which creates the bitmap. Add a comment for 'magic goes here' so we know where to help. Also, are you using c# or vb? Agreed. Something that better represents a `game` or a win/lose log (e.g. 1 row per team per game) would make this easier @Paul: got it, thanks! How many games are we talking about (100 1000 10000...)? In a sense, this is analagous to double entry book keeping--for one team to win, another must lose. You could record all these as transactions with a ledger style DB If you normalize it a bit to have a FK reference for each team instead of copying the team name string each time, and add a "winner" column as @pixeline suggested (possibly computed/calculated/formula--whatever mysql calls them), I think you can keep much the same structure with the same number of rows, but a much smaller (byte-wise) table. please post your markup/css What kind of JS objects? Post some more code. If they can be wrapped with a $(), then you can do this: `$(obj1).add(obj2).jqueryfunction` or if that doesn't work, then this should: `$(obj1).add($(obj2)).jqueryfunction` What version of FF/IE? Also, can you post a repro to jsbin.com? And GetHashCode()... Please post your entire `` block +1--you're probably right about the issue OP's reporting What is your question? Finding empty divs is certainly possible...though not likely very performant...an not likely the Right Solution Any attempt to store data on a client machine from the web will be difficult. You are likely to have much more success with either maintaining state in the querystring (assuming there isn't much to keep) or letting users export/import actual files. If you're suggesting that the google links "auto upgrade", that's not true. Google lets you control this behavior by being as precise as desired (e.g. 1.3.x vs. 1.3.1) I guess this is a valid consideration if you target such audiences--I hadn't considered this +1 If you're doing all that work *just* for jQuery, then I'd say it is overkill. However, if you already have some of those components in place for other pieces of your app (e.g. if you already load scripts from a DB) then it looks pretty nice. I'd like this, too; I submitted a ticket http://dev.jqueryui.com/ticket/5081 Please share some info regarding what kind of data you'll be working with. Specifically, what kind of volume and churn are you expecting in each direction (between a user and the server)? My ticket was marked Wont-Fix with a comment indicating the the buttn support may be dropped entirely in the future... I guess you're on your own :/ @unknown-- this is a good question. If you don't get anyone to bite here, you might try moving it to serverfault.com. I also encourage you to accept answers to more of your questions and possibly even answer some questions along the way, too... yay! that's nice @reallyJim I believe they do, though, in my case I needed raw data I suggest changing `TagRenderMode.Normal` to `TagRenderMode.SelfClosing` for the img; otherwise it renders as `` instead of `` I applaud your line count but...that is a crazy application of sophisticated tech for this simple problem @David Brunelle: This one looks pretty nice: http://stackoverflow.com/questions/2240488/2240514#2240514 @itowlson: maybe I came across a bit harsh--sorry. It just seemed a little too dense for an otherwise simple problem. Don't get me wrong--your approach is elegant in its own way. At a glance, though, it's not at all obvious what this thing does. @discorax ?? what code did you add? Please update your question with what you went with--your comment makes me very curious @Frank, @Dave it's not the regex--it's the significantly large chain of operations. Now that it's been reformatted, it is much better. Again, I appreciate the elegance--I love stuff like this--I'm just saying that the iterative approach is more obvious and easier to understand Of course if the regex does grow as is inevitable in a public forum like this...it does become part of the problem @Sergio--that depends on a lot of factors (DB, load, recovery model, etc.). In general, a SQL Server DB in "Simple" mode will wrap around its log file if it can. It will typically grow when it must and then only shrink if autoshrink is enabled (bad) or you manually shrink it with a command or SQL job. This isn't quite working for me...do I need to restart IIS or clear a cache somewhere? I created a project from scratch and this does indeed work, thanks! I just need to figure out why it's not working in my existing, IIS-hosted project... I see what you did there With the initializer method, though, this doesn't allow you to pass in the size of the array That's a clever approach Did not know about that...neat! This is by far the easiest+safest solution, especially if you won't be doing this often...or, actually, especially if you'll be doing it often. Unless you need something more fluid like partitioning (which will require a fair bit of education to execute properly), this is a great option. It looks like a pretty helpful error, actually. It's saying that the whatever your doing makes Excel look frozen. To make this error go away, your app should periodically talk to Excel so it knows you're still running. How are you generating the tokens? So in conclusion, they are *not* very random. That is, consecutive guids from the same server will have a lot in common. No--the [] setter will add or overwrite as needed. Not to be nitpicky--just want to clarify something--the web server is definitely not creating a new thread to service each request. In some ways it feels like it, but in many others it doesn't (because that's not what happens) Your recommendation to create a new datacontext for each request is good, though--dataContext is pretty lightweight. @Darin Any reason to use one over the other? Excellent--this is my understanding, too That makes sense. thanks! @George-- agreed All good answers (all upvoted), thanks! this looks like Counting sort, which for numbers of known (and reasonable) range, is O(n). But it doesn't have many practical applications I hear you--and on the server that's what I might end up doing. However, it's just so easy to plug a regex into the ASP.NET MVC model validation engine that I'd like to stick with it for now Wouldn't this match a single tag of 60, 90, 120... characters, though? Wouldn't this match a single tag of 60, 90, 120... characters, though? I like this--thanks--unfortunately, I cannot preprocess the input in anyway, e.g. adding a space I added an example--it's basically the same as SO tags That's a neat site--thanks for the reference @Steve: I appreciate your extra efforts--unfortunately the latest regex doesn't cap out at 30 chars/each--i.e. it matches a 40char tag With the code you have posted--and nothing in prerender, init, etc. except a call to DataBind(), you get multiple rows with cell 2 filled with "random text"? And if you comment out that line, it's filled with data? I always add YUIReset/Base/Fonts (http://developer.yahoo.com/yui/reset/) as the first lines of CSS in my apps. It helps with so many issues like this by (hopefully) providing a baseline foundation across all browsers so that CSS changes *you* make are applied consistently. They will serve it for you, but it's really just a couple of lines that you could add to the top of your existing styles page. What have you tried so far...? You'll probably want to create a page that loads the image from the database and serves it ala http://bit.ly/c40sON *Do not* send images to the browser like this. There are lots of reasons why this is a terrible idea. The link, however, does explain how to do this properly (through a handler) JS is single threaded so that really shouldn't be happening...can you post a repro on jsbin.com? Yes. They are pretty much hard-wired so it's safe to code against them. No problem. Here's another SQL Server gotcha you may run into, this time with `varchar` columns: if you don't spec a length, they default to 30. http://stackoverflow.com/questions/359257/why-is-the-default-length-for-varchar-30-when-using-cast Yes, put it in the view. I would only suggest moving it into the model (which might be view specific, and thus require controller manipulation) if you were going to do this in a lot of different places **and** either there was potential for unsafe conditions (e.g. security) or it was overly complex or confusing. But this seems like a clear case of a simple display issue so yes, do it in the view. beat me to it--here's a live example http://jsbin.com/unogu3/ (I offset the images to show they overlap--obviously yours would be a little different) There are also compatibility plugins for jquery to ease the transition of any breaking changes e.g. http://github.com/jquery/jquery-compat-1.3 @ScG--if you need to access both A and B, I'd suggest just going with what you have--it's really very clear. My solution, when adding in an anonymous type to KeyValuePair to keep track of A&B would make it difficult to read and no faster Add the element's ID attribute to your log message to see what's going on What did you use to make that image? Why can't you use GUIDs? They are awesome for this. Or at least they were until very recently... http://weblogs.asp.net/leftslipper/archive/2010/04/01/last-guid-used-up-new-scottguid-unique-id-to-replace-it.aspx If an LI's display is set to inline, it will still have a bullet unless the list-style is busted. If poster is trying to throw  tags anywhere, not just within a UL or OL...that's an entirely different question... What culture is your dev system running as? there is no try there is only do What do you have so far? Try to create a simple repro and post that code this is really easy to check...and you should with your actual files; or don't worry about it and just gzip do you have any JS frameworks on the page already? If so, you can make this easy (very, very wrong, but easy and pretty) Grab the generated SQL script and run it interactively in Management Studio to see what's really going on I'm going to disagree with you here. I think that a regular delete is pretty well understood to "succeed" even if no records are affected in set-based operation land. Plus, if you're going to check first, you introduce all kinds of transactional issues you'll have to worry about. And of course the performance hit... moving up to wpf with 2008 or 2010 would be a good start look at fiddler--it lets you inspect and replay requests If you have to ask, the answer is probably (and in this case, definitely) "no" Plus it often has other benefits, too, like query plan caching, readability, etc. Can you describe the issue a little more clearly? I use VS2010RC a lot and have no idea what you're talking about... Plus, jquery really is pretty tiny which served up with gzip...not worth worrying about Also, this doesn't need to be iterated: this should work `$(something).find(somethingelse).fadeOut(1000)` -- do it all at once (no `each` required) In that case, you want to run animations *sequentially*. refer to this http://stackoverflow.com/questions/1218152/how-can-i-animate-multiple-elements-sequentially-using-jquery Yeah, you might be looking at making a new plugin for something like this (or searching for one) Note that IE9 doesn't even have a release date yet...I'd guess not until sometime in 2011... Did you `Rebuild Solution` after changing it? You could also try toggling `Copy to Output Directory`...that one sounds very promising ;) Your link doesn't work (forbidden) Yes, more or less. The thing here is that the files are sent down with extra data (headers) that say "never ask for this file again--it never changes". Since they do that, the site is faster (one less request each load). BUT when the file *does* change, they communicate that by changing its name. Try to ignore that the version number is a querystring parameter--think of the whole thing--path, name, query string-- as part of the file name. When any of it change, it's treated as a completely unique "file" or resource. what is your platform? (IIS, Apache, etc....)? What type of file is it referring to? Lookups were added 3.5 which might help a little here http://msdn.microsoft.com/en-us/library/bb460184.aspx I'm not sure what the bug is but you could clean things up a lot and hopefully fix it or discover it. e.g. the [current tab index](http://jqueryui.com/demos/tabs/#...retrieve_the_index_of_the_currently_selected_tab) can be found with `var selected = $tabs.tabs('option', 'selected');`. Additionally, you can clean up a lot of `.parent().parent()...` code with [`.closest()`](http://api.jquery.com/closest/) and [`.find()`](http://api.jquery.com/find/). It's clearer, and more robust. Actually, all that class manipulation to show/hide content is really unnecessary--that's what the plugin is for :). 2/3 of those lines (the jQuery ones) are unnecessary Are you saying the XML files are 50-100mb each? What XML parser are you using? Post your code I try really hard to make sure my applications [*don't* become self aware](http://xkcd.com/534/) Please post *all* your code--not just one line :) Building a library, which contains your queries is good, that's not what you're doing here. Please, please look into SQL injection attacks--that's the first thing you should do. Go and convert your queries to be parameterized. They might be a little faster (though probably not noticeably) and more importantly, they will be a lot safer But what's the right thing to do? What will clients understand most easily? because.........? I meant why a document response instead of headers...I think that's what the original poster is asking, too Please post your code for ISOCountry; specifically, what does the property `isoCountryCode` look like? Active Directory/LDAP This should be a pretty straightforward adaptation of the existing algorithms you linked. Can you post what you have and we can help you along with hints? He's asking for the power of two that's *closest to a given value* (and less than, not greater than the given value) Novice users might benefit from your example if you add a version with everything broken up. e.g. `$div = $("div"); $div.html(".."); $("body").append($div);` what you present is what we use (+1), but it'd be confusing to someone new to jquery Based on the answers so far, it looks like your case is not extreme enough to warrant *any* action. That is, the cure looks worse than the disease...unless you pushed *huge* files into the repo... +1 for hints and reasoning instead of code [I totally flip out](http://www.realultimatepower.net/index4.htm) What does your table look like? Care to post some code...or a question? We need a little more than just a question mark For added clarification, the view is typically very simple. In this case, `getHTML()` could be simply this: `return "...$user, $email...";`. The controller is where most of your php code will probably go. Your html/css/js will go into views. Your models will be simple data containers (usually). I'm not big into crypto so I can't put words to my discomfort with this idea...but it makes me uncomfortable. You've reduced the possibilities by going with base16 instead of, e.g., base-26+26+10; plus (guessing here) you compromise the integrity of a hash when you truncate it. I admit, though, the requirement of a unique password is a bit strange, too... Why do your passwords have to be unique? You might also look at XML+XSLT to see if that fits your need better. That allows you to transform (the xslt part) one XML document (yours) into another (html) Please post the error messages Actually, I think ajax and MVC go together quite well. For example, with SO, if you have a Question controller, with an Upvote action, it can be quite simple to call that Upvote action from the client, which will execute the upvote and return a status code. I'm running a 3yo medium grade Dell laptop and it does just fine...; it's not as quick as notepad, but it's doing a helluva lot more than notepad Definitely go with the shuffle approach--think of it more like a deck of cards. It's not exactly how lotteries typically work, but mathematically, the outcome should be exactly the same. post the HTML, please! @pax-- I know... I just mean that with ping pong balls, you take one, then shuffle the rest, then take another, and so on. It's procedural. With this, you just shuffle once (more would be ok, but unnecessary) and you have all the numbers at once parseInt() is a built in which turns a string into an int; added comments for you What does your program output? I believe jQuery aims to include as little browser-specific code as possible. It's true they have many IE workarounds, but they try to keep them to a minimum you're requirements are...missing. Are we supposed to break down the number into smaller parts? By what rules? +1 nice and clean, and handles city names better; might consider using [`LastIndexOf`](http://msdn.microsoft.com/en-us/library/0w96zd3d.aspx) to make it even more robust Shouldn't you escape the outside parens so the capture group has just "PR" in it, not "(PR)"? To be a fair comparison to @dtb's excellent solution, this should be coded up. Its brevity is compelling now but I'm curious if that'll hold up What's the question? If it works it works. and '.' concatenates in php these things, at google scale, are among the industry's greatest achievements. I suggest you start with something a little narrower That's too bad :/ I don't consider this a feature... This might be improved by leveraging a state variable instead of checking the button text; but if you don't have i18n to worry about, this is definitely clear and concise This is an HTML thing--disabled form fields don't get sent to the server by the browser; use read-only instead. I see what you did there That last [URL](https://furniture.retailcatalog.us.s3.amazonaws.com/products/2061/6262u9665.jpg) works for me, although it comes with a certificate error which is likely a problem for you Yes, this is what I'm doing. `TempData` for redirects, `ViewData` otherwise. No, no ajax involved (good question, thanks!) It happens when served via IIS on both my dev machine (IIS7.5, not Cassini) and beta (IIS6) I'm familiar with the read-once rule--I think I observe it. Are you saying that tempdata shouldn't be used from views or master pages? Can I get a source for that? Thanks for the help! Is there a standard pattern for doing what I'm trying to achieve here-- sending messages to the master page view from many different controller actions? The rep has vanished. Sorry folks. If I get a sweet answer, I'll start another bounty and award it to you Can you give an example? +1 nice alias names is `o` expected to be a double or is it an object which can be converted to a double (e.g. a string or something else) We're assuming that the pattern is all lower case for #2, right? Otherwise, they're not equivalent or what @Remus said--that's much simpler nice and simple +1 Shouldn't a running proc be terminated (and any open trans. be rolled back) if the connection is dropped? That *would* be pretty handy I don't suppose you'd be willing to use a command-line svn client? That might lend itself to a nifty powershell script or something... So you want to merge two arrays without any duplicates? You want a list of one row per thread, with the correlated top posting user? If you have money, but not a technical team, you should really hire out the whole thing--not to a developer, but to a company that sends email as a business. If you don't have money or a technical team, you probably shouldn't be sending so much email... Your highlighted statement is pretty much right. I'd say it's loaded into the HTTPContext when the app starts and it starts b/c of a request, though the routes are loaded without knowledge of the specific request; the actual routing of your specific request happens later Just to spare the next one the momentary confusion I had, we're talking about actualy `` tags here, not `` tags; and yes, as far as I know this is the standard way +1 You've tried this with permissions wide open and/or running the app as an admin? (just to help narrow things down; not advocating for this!) If your app doesn't run acceptably well on it, why would you want to list it as supported? Can't you exclude that as not supported? I don't have the time to test this right now but it's exactly what I was looking for when I started. Thanks!Can you by chance add a note about where the ebook is typically located? Sigh...another 150 points wasted... What is tbl7 and does it have ViewState enabled? Anything in your Page_Load event? You don't actually have a question in there, so I'll just take a guess at it plus what floatless said... I'd suggest investing in a good browser debugger. It will save you hours of headache. If you use Chrome, hit `ctrl-shift-i`; if you use Firefox, get the firebug extension; if you use IE8, hit `F12` Same thing for `(user_name)` You also need to clear the error message if the user enters something good; and maybe make those else-ifs to prevent later errors from overwriting earlier errors. Overall, I'd suggest a little refactoring to clean things up a bit and possibly help you restructure things to be simpler. Edit note: when I sank to the low, low level of employing LOLCats, this question had 3 views after 2hr45min... cut me some slack Worked great, thank you so much! Vote to close as "Not possible" Suppose for instance that you have a generic structure called a "List" holding your data. Suppose that this list is implemented under the covers with one data structure up to a certain record count, and then another structure above that count. An example of this is .NET's HybridDictionary. Each of these structures could handle undefined sorts differently and produce different results (I'm not saying HybridDictionary does this--that's just an example) @Jian, in the case of possible duplicates, it's not uncommon to sort by many, many fields to remove ambiguity. In my case, I usually sort by the field or two that matter, then by the primary key or log date to make it well defined. A case where this can bite you from the DB is when indexing or volume of data changes. When no sort is requested, the db will return it in whatever method is fastest. When indexes or volumes change, "what's fastest" may change, too, to a new index. The new index could have the data in a different order and thus you get different results. Most of them use computers I think that Twitter reference is old... +1 for migrating the format string #mindreading I don't think I'm doing the web-garden thing (I'll double check), thanks! This might be helpful reading: http://weblogs.sqlteam.com/jeffs/archive/2007/08/23/composite_primary_keys.aspx If you're using Tortoise, you can configure it to use _svn instead of .svn, which might help this is a good approach, too +1 What *exactly* is the output? Do a view-source in your browser and paste it here what's wrong with short tags? Thanks for the link @Josh - I haven't used php for a long, long time so I appreciate the info what is `BillingRates.BillingRate` (int, string, double, etc.)? Surely the IDE has these features, too... Yes, until a dozen people come in to clarify all the edge cases where this isn't 100% true... ;) @user279521 I think the default configuration in IIS will start the app domain when a user hits the site. Then it will stop the app domain if nothing hits it for a while (15 minutes?). I often change these limits so a less frequently used app stays up longer to avoid a huge delay for that poor first user @user279521, yes, if it's inproc session http://aspalliance.com/226 Can't you add a parameter to the link you give to google? i.e. instead of yoursite.com/landing, do yoursite.com/landing?campaign=12 Since the economic downtown, a significant slice of methods has left its usual tables for something less glamorous, virtual vtables Can you highlight how that is really any different? +1 for `\s` character class; I'd probably use the work "global" instead of "general" @Tim There are dozens of whitespace characters that could be pasted in that aren't a simple "space" @Tim Good to know, thanks! None of that code after `return false` will do anything...because the function will have returned already. It should be outdented a level, and the `$(function...` part in the middle isn't needed because you're already inside a `ready` event @Alex, true--though I think that's a feature. I generally don't want my tight dependencies to change from user to user automatically or accidentally I might suggest telling your superior that this isn't possible. It's nice when the compiler gives us helpful errors :) After computing tax or discounts, `>2` decimals are quite common... What's the 500 error all about (check the logs) *serialize*? Interesting idea. I'm not sure how it would hold up in terms of performance, though possible duplicate of [Server.UrlEncode vs. HttpUtility.UrlEncode](http://stackoverflow.com/questions/602642/server-urlencode-vs-httputility-urlencode) (answers include references to `UrlPathEncode`) +1; just about to write that... @Jannis - if you aren't actually interested in `data()` and just want attributes, use `.attr()` @Olivier I only have it running under a different port (3000) because apache is running on port 80. If you host multiple rails apps with the same webserver, you'd use the same port for all If age is calculated why do you need a constraint? +1: in this case, if you insisted on a constraint, I'd put it on `DateOfBirth` since it's the only component in the calculation and doesn't change by itself like `Age` LINQ is not magic. Just to address inevitable confusion with `.delay()`: it adds a delay to the animation queue. It *does not* "pause" execution of the code right there. It's *not* a `Thread.Sleep(6000)`. The rest of that line and subsequent lines will not be delayed--just the animation effects they may trigger will be delayed. Can we just get all the way down to butterflies now and get this over with? @breezer it was on one line--I edited it for our benefit This is definitely related to your input type. If you change "search" to "text" here `` it works easily. I'm not sure what to do to fix this for the html5 type `search` but at least now we know where to look... Am I missing something here? 1000urls/second * 60sec/min * 60min/hr = 3600k URLs needed per hour. 200k per hour or every 12hrs isn't even close to fast enough for you. You let the smoke out I see. I thought you were trying to maintain 200k/hr--I guess that was just an example of current performance being too slow. I struggled with this, too, and ultimately added a "BaseUrl" appsetting to my web.config file for this purpose (feeds in my case, not email...but same problem). I'm interested to see what people come up with. It's a tricky problem because the server and app may not really know--at least not reliably--what URL's being used to query them I might suggest running some more complex examples, too. It may make things look more even or less, but it'd at least be more realistic @sirmak, I'm suggesting you *add* to this by having a complex example, too. The view engines may not scale as you'd expect Try `colSpan` (note case); dupe: http://stackoverflow.com/questions/1294850/set-colspan-dynamically-with-jquery no problem, I hope you get it working +1 for point of about 2 states; I'd also suggest using `closest` with `find` (instead of `parent`), or not using `find`. I recommend applying recursion consistently (i.e. everywhere or no where) in cases like this good point, thanks, Shane I'd suggest using `addClass`/`removeClass` instead of `attr`. The code is simpler and handles other cases (e.g. multiple classes unrelated to the problem at hand) And yet, you can usually write `var X = SomeMethod()` inside the constructor... I think nearly all the explanations below are garbage, except for the fleeting references to [Lippert's post](http://blogs.msdn.com/b/ericlippert/archive/2009/01/26/why-no-var-on-fields.aspx). The answer: because it's a lot of work given the way the compiler is built today. It's an internal problem. All: I realize a constructor is a method; I was suggesting that the example in this answer could be more clear by emphasizing the fact that the compiler doesn't yet know information because of the way the compiler's been built. Without understanding this, the point doesn't make any sense because the same argument could be applied to use within a method where it *does* work If I'm not mistaken, this could be shortened a tiny bit by using `.once('click', ...` and removing the `unbind` line @Michael, how about ``, which does the same thing as what @Domenic suggested, but has been around longer? Yes, we tried that What? Huh? Congratulations, I'm now as confused as you must be. there's nothing inherently wrong with objects wrt performance. I think it's generally safe to assume that an Array will have a performance profile of N(1) access, which is what you need for binary searching `toSource` isn't universal across browsers http://stackoverflow.com/questions/1101584/javascript-tosource-method-not-working You may have a problem with your JS, but I doubt it's a JS caching problem. Go get Fiddler2 on your client machine. It can shed a lot of light on weird problems like this as you browse your site That would be pretty strange behavior. What happens if the user changes their mind and wants to pick one of the newly disabled options? This isn't what OP wants Yes, this! The first decent explanation When I run into issues like this I usually use one of the [other overloads](http://api.jquery.com/bind) so I can inspect more of the event details. The problem is then often obvious. Try this as your first statement: `set nocount on` Post the code for your action, your route, and what URL you're using to hit the action via said route Can you create this on jsbin or jsfiddle? Right...can you share it so I don't have to create it myself? This doesn't work, unfortunately. I'll try it word by word... This works! Thanks! @Oded PI is a time-series database/historian. The tag search dialog is commonly invoked from WPF/WinForms applications. I updated the tags to help clarify I bet addng `var` to `var theBox...` would fix this, too. As is, the scoping is incorrect @roviuser, it's just the ultimate lfgtfy! You should do this in server code when your paging URLs are generated--doing this in JS is inappropriate (unless the whole search operation is client-based) `img` or `canvas` is probably easier, but if you want to keep trying things, you might do that quarter round thing plus a partially rotated `div` over top the curved edge. Then you'll have hack upon hack but no image or canvas Note: it's not valid to have multiple elements with the same id (`checkbox_4`) What's the use-case for these data once they're in the database? i.e. what will your `selects` look like? Related: http://stackoverflow.com/questions/126271/key-value-pairs-in-relational-database btw, the behavior you are seeing is often referred to as a [flash of unstyled content](http://en.wikipedia.org/wiki/Flash_of_unstyled_content) -- "fouc" might help your googling If you are handy with server-image stuff, why not make a single image overlay that is itself a composite of all your fake tiles? That would make the site screaming fast because it'd really be just two (or even one) images, instead of thousands of ``s (that's a sweet effect, btw) Uhh...what are the advantages to switching? Why are you interested in switching? (these are not self evident) So the problem is that clicking one registration's checkbox changes all registrations? @patrck, that's pretty easy with the [`.siblings`](http://api.jquery.com/siblings) traverser/selector. You might use something like this inside my function, where `this` is the clicked checkbox: `$(this).filter(':checked').siblings('input:checked').attr('checked', false);`. Final note: if they should only have one selected, use radio buttons instead! Is it possible the primary server has long-running transactions that are tied to the "missing" records? Are you running x64 OS? This is pretty standard for a jquery one-liner so I wouldn't worry too much about reusing it all that much. You'd normally do that with [`unbind`](http://api.jquery.com/unbind) **but** why I'd simply *not* apply it again when things are dragged around. Or, if you really only want the events applied after dragging has occurred, don't append the event initially or use something like [`live`](http://api.jquery.com/live) instead of `.dblclick` Possibly related: http://stackoverflow.com/questions/412300/formsauthentication-signout-does-not-log-the-user-out What have you tried so far? ([hint](http://msdn.microsoft.com/en-us/library/ch45axte.aspx)) This open source app does much of what you want so I'd crack it open to see how. http://www.gnu.org/software/units/ Can you post your code where you use the PDF library? Can you post this to jsfiddle and share the link? @Steven I don't recall that--I thought he suggested using InternalsVisibleToAttribute for this, or if necessary, make something public in *debug builds*. He seemed to take a pragmatic approach throughout, though, so I may be remembering this point incorrectly. @Steven: sounds good, thanks for sharing. Applied in moderation, I think that advice is very reasonable another possible test: `$j.closest('body').size()>0` Relevant code, please! Sure, I updated my answer +1 for noting the weaknesses of the first two selectors I think the only way to really improve this is to detect mouse movement. I suspect digging into it would not payoff, though. `delay` is for the effects queue and won't work for this This is kind of insane A wild guess that this topic might aid your googling http://en.wikipedia.org/wiki/PID_controller#PID_controller_theory I made a fiddle for it to post as an answer but I'll just add it here since you got it already http://jsfiddle.net/mharen/XFCwJ/ @jd audi what are you expecting the buttons to do? In my fiddle, I just make them do an alert. You don't have any elements in your markup that are classed '.swShowPage.active' so either that's wrong or you're not providing all the code No worries--his solution is better (+1) Try my edit--it might help Which version of SQL Server? this doesn't address issues with the toggle function--as written it will toggle every div, not the clicked div Also, since `.appendTo` isn't passed a set of objects, it will only append the given collapse element to the last one that runs (it will remove/append each time) `IsApproved` and `NotApproved` are supposed to be collections of the corresponding items? +1: I suggest adding a fallback for nothing in the search box, e.g. `if(searchTerms.length==0){ $('li').show(); return; }` Stop everything and read this now: http://en.wikipedia.org/wiki/SQL_injection#Parameterized_statements @RightSaidFred in this case, isn't this overkill? We *know* that `this` in an array with a `length` property that returns whole, positive numbers...right? @jamietre @rightsaidfred I'm happy to rely on Mozilla's implementation, it'd just be nice to know *why* they do it that way. Are you getting script errors in your browser? What does this look like if you do a view-source? How is `finishPrompt_Action` invoked? Are you using the browser dev tools (F12 in IE, c-s-I in Chrome, Firebug in Firefox)? They're awesome for things like this @user: fyi: you can edit your question by clicking `edit` below the tag list Your code, `$('#set1').find('ul').eq(i)`, implies you have lots of separate lists (ULs). If you have only one, you shouldn't be using `.eq(i)` here. or `$('input:not([type=image],[type=button],[type=submit])` (moved this comment into an answer) Don't be scared! *just that* won't be enough but it's an interesting starting point OP says `y` is a value... it might help a little to remove the `WITH(...)`, `ON [...]`, `dbo.` and `GO` pieces You're first sentence is misleading. It has nothing to do with the column name and everything to do with the relationship which you correctly note later in your answer If all the big plugins don't work for you, what is so unique about your situation? It'll be a bit trickier to do client-side caching if you're returning content instead of data, no? Are you setting the attribute in a script, in c#, or in the aspx page? that's not possible. Attribute values are not transmitted on post-back. If you need to persist something you can use hidden inputs User isn't looking for `InnerText`, user is looking for an attribute on the `` element. Does this do that? Paste your whole block, or add `console.log(temp)` to see what temp is What have you tried so far? I suggest looking online for some tutorials. Scott Hanselman has some great videos of this kind of thing Check your HTML with Firebug or Devtools to see what HTML/script is being loaded. @JonSkeet Are computers *in* rooms commonplace where you are? I've never seen that before in the US Post your routes, please Look into `word boundaries` The idea is that you'd put some JS to launch a popup in the page you redirect to which opens the popup.BUT that won't work because browsers (with default settings) won't let pages open popups without a user's click. What you need to do instead is launch the popup from the first page, as a result of clicking the button, like @BalaR's answer.Or don't use popups at all. @tjcrowder cool, thanks! How about returning the total number of records via a parameter? Then you can calculate how many pages you have, too Surely you're hashing those passwords and you've just simplified it for our benefit, right? Right!? +1. Including `price` to make it a covering index could be beneficial, though And ***Gulp!***, catch eats another exception! :( @SecureFish are you looking for the **mode**? What is the path being rendered in the browser? @Killroy do what @TimSchmelter suggested or run Fiddler to watch the img request on the wire. You're probably getting a 404 or 500 error. You'll be able to inspect that error in Fiddler, or if you go to the image url directly as Tim suggested What SQL engine are you using? (This is important because concatenation aggregation is actually pretty tricky and the answer may depend on the engine and version you have.) @Tarun showing some effort is a nice gesture, sure, but...it's *not* a Q&A website?! Of course it is! possible duplicate of [Simulating group_concat MySQL function in MS SQL Server 2005?](http://stackoverflow.com/questions/451415/simulating-group-concat-mysql-function-in-ms-sql-server-2005) possible duplicate of [Detect IE8 Compatibility Mode](http://stackoverflow.com/questions/1328963/detect-ie8-compatibility-mode) +1 that's a more elegant way @Phill What? Surely you jest Why do you have two records in the `payments` table for a given offer? I could understand storing history, but you also seem to have `redeemedDate` which is weird if `NEW` records will never use it. I'd probably just change the `payments` record to `USED` when it's used instead of inserting a second record how is a payment mapped to a transaction? You need to specify that in your join condition--it's probably more than just offerid Your definition of `deadlock` is not correct. Normally SQL Server **does** let other requests wait. When it kills a query because it detects a deadlock condition it's because the given set of queries cannot complete (ever) and someone has to lose. I think if you do a little reading on what deadlocks are, you'll be in a much better position to get value out of a better question (+1) Imagine two cars headed towards each other on a single-lane road. They both need the road to continue on but obviously they both can't have it unless one car backs up or disappears (i.e. `rollback`). No amount of waiting, memory, disk, etc. can help @tsilb you may find this [`aba_lockinfo`](http://www.sommarskog.se/sqlutil/aba_lockinfo.html) utility to be very helpful I suggest going with a standard format for this so you don't have to write your own everything (json, xml, yaml, ini, etc.) Change that to `union all`, otherwise you'll get incorrect results when both tables have the same number of records Yes, you can do this. The actual implementation depends on a lot of information you haven't included. For example, how are you generating the images? What are you using them for? +1 If you understand this--I mean *really* get it--I think you'll be a notch above most programmers. @Henk thanks for the clarifying edit! @Henk I think the comment is accurate but it could be misunderstood since it doesn't specifically call out passing an object vs. an object-reference GUIDs are just a bunch of bits. We turn represent them as hexadecimal for our benefit (just like ASCII letters and numbers are really just bits, too). not really. Sure, the digits are printed in a fancy format but really you can do this on an envelope. Use this site to convert the letters into groups of 4 bits, or reverse http://www.electronics-tutorials.ws/binary/bin_3.html I don't know, but I would bet the sorting is simply by the binary representation (e.g. 00 < 01 < 10 < 11 ...). Unless you have uncommon culture settings, this would equate to a simple alphabetical sort. @gbn thanks for answering! You need to keep track of how often you call that function. A cookie could work well for this, or keep track on your server if you already track other user-specific stuff In case it's not obvious to the original poster, this 4-hour timer will reset every time the page is reloaded. @4thSpace `BEGIN TRAN` moves out one level and `COMMIT` moves back one level. `ROLLBACK` moves back *all* levels. So if you nest your three transactions within 1 super-transaction, nothing is *really committed* until super-tran is committed but everything is rolled back if anything rolls back. In case anyone's curious about the `*` like I was, it's a hack to make that property work only in IE6/7 ([ref](http://www.javascriptkit.com/dhtmltutors/csshacks3.shtml)) @Rocky if you have status that are out of date--i.e. were last computed when you had few rows but now have many rows--this can happen. You can set stats to automatically recompute (though I'm not sure how that works in practice), or you can create a maintenance plan that recomputes them on a schedule (what I normally do). +1. Your excellent advice to not worry about things unless they become problems is essential. If you add some details on proper stats maintenance (I personally want to know more), this would be a perfect answer Yes, I had that in there but removed it for brevity. Thanks for pointing it out though That makes sense, thanks! If I copy them to the SD card, what then is the recommended call to launch them (i.e. the full `startactivity` call)? What's the typical way an app loads resources into its `.cache` folder? Does this need to be coded up or do I put my files in a special location and they get dropped there on install? Thanks, @sam, I appreciate it! possible duplicate of [Creating a DateTime in a specific Time Zone in c# fx 3.5](http://stackoverflow.com/questions/246498/creating-a-datetime-in-a-specific-time-zone-in-c-fx-3-5) not a duplicate perhaps but I figured it'd be helpful I suggest following Wii Fit's example by making the password *optional*. @robhardgood, @Andre's JS code should just go in a `` block. The code takes care of finding the submit button (line 2), and adding an `onclick` function to it. It's totally separate from your HTML and should stay that way thanks for the tips! Unfortunately, both of those options actually **delete** the files from the destination, since they aren't included in the deployment. that option doesn't exist for me. It looks like I ought to switch to doing a regular msdeploy (with a config file for it) instead of passing in my options... It might be useful to start with a nice css reset file, and a cacheless reload How about a fiddle? @AshleyDavies no problem. Fresh eyes is all it takes sometimes... Mobile support is another story... This isn't comprehensive but it can be a good start if you need something very light. http://jsfiddle.net/mharen/sbtVd/1/ That's pretty cool This suffers from the tab problem @OP mentioned possible duplicate of [Render partial from different folder (not shared)](http://stackoverflow.com/questions/208421/render-partial-from-different-folder-not-shared) I think this is one of the extremely rare cases on SO where including code in a question confused the hell out of everyone @jQuerybeast I added some more info which might be useful to you @Awea Haha yeah, I just added that :) @Awea that looks like a [bug in jsfiddle](http://stackoverflow.com/questions/7689070/is-jquery-1-6-4-broken-or-did-something-change). If you change the fiddle to load the script during the `onDomReady` event, it works ([fiddle](http://jsfiddle.net/mharen/MkYMF/3/)) Can you post some sample html that this would be working on (in a fiddle)? You are probably running into an issue with the [same origin policy](http://en.wikipedia.org/wiki/Same_origin_policy) of the browser since the protocols don't match. I don't have time for an answer but that might help your searching @JohnSaunders Application Test on a backup of your database. Run it in a transaction, too, so you can roll it back. Upvoted because you got the right URL :) No...that'd still need to be encoded. What error did you get? Shouldn't that first query read `ID IN ()`, not `ID NOT IN ()`? @JamWaffles whoa. No. @user1088165 yes, you don't need to wrap it again. It won't actually re-search the dom, it's just unnecessary FYI: searching for "toast" will help you find some neat stuff that can help Thank you, sir. More evidence that I'm not crazy. @Guy - btw, I removed an extra `` tag when updating the formatting. It was probably just a copy-paste issue, but I wanted to let you know in case it matters elsewhere. I haven't used mysql for a looong time, but should those variables really be quoted? I'm assuming they are integers... And you're using parameterized queries, right? Right?! I had no idea that existed. Thanks! If anyone is wondering why there exists both `AddHeader` and `AppendHeader`, [wonder no more...](http://msdn.microsoft.com/en-us/library/system.web.httpresponse.addheader.aspx) The [new Migrations](http://blogs.msdn.com/b/adonet/archive/2012/01/12/ef-4-3-beta-1-automatic-migrations-walkthrough.aspx?CommentPosted=true#commentmessage) (beta) stuff looks very promising. It allows you to step up/down with automatic or custom changes and generate change scripts for hands-on production deployments (awesome!). Thanks, this is very helpful! More to the issue, if you see this while debugging, just hit F5 and your program will keep going (it won't crash...at least not b/c of this). Do you work at Sony? Can you also make a route directly to a static file? good to know, thanks This is beautiful. @dchris I fixed your closing tags. Surely you meant ``, not ``... This also fails in WebKit browsers (eg. Safari and Chrome) This doesn't fallback-load the CSS, though... Great, thank you For reference: http://api.jquery.com/eq/ Not sure if you're suggesting that the script should sniff the URL. Don't do that. Instead, handle the emptying of the table in the `success` function of your callback, or do it server side if that's where things are rendered. FYI (for people coming to this now), migrations support **now exists** (and it's pretty great, actually) @danludwig thanks for the comment, which prompted me to fix `Url.ActionLink` +1 I like the T4MVC stuff, too. I'm a little surprised it isn't built into MVC (yet?) @Smarty - this type of issue can be tough to figure out. You might find that the browser dev tools are very helpful to see what's going on (F12) @SmartyTwiti if you're having a different issue, I suggest opening a new question. You'll get better help that way @YvesR I don't think that's the same product as `Web Forms`. Also, I don't see any programmable API in there, either. If I missed it, please let me know! Thanks Also, the tiny custom shortcut area above/below the ribbon is pretty much perfect for your use-case What is `#pesqui`? I don't see that in your markup... What does it do for `txtUsername = "'; DROP TABLE users--"`? Seriously--please use parameterized queries. Stop now and add that, then come back to this issue. @MuhammadKashifNadeem your answer is incomplete and incorrect Great read! Specifically for OP's Q: "All comparisons between DateTimes ignore the Kind [i.e. UTC vs. local] property." See [this related question](http://stackoverflow.com/questions/18082/validate-numbers-in-javascript-isnumeric), which I asked some time ago. Jason: I definitely recommend the second approach (blocking queue/producer-consumer)--it's much easier IMO. For more on Semaphores, though, read this: http://msdn.microsoft.com/en-us/library/system.threading.semaphore.aspx This will work, but the other answer would perform a lot better Does making the `*.sln|*.csproj` files writable help? (OP is using TFS in case it matters...) @trung - note that parameters to JS functions aren't typed-- remove the `String ` What produces the initial string? What is consuming it? Have you worked with JSON before? Good call on the dom ready part. @Purmou I'm not entirely sure what you mean about the semicolon. It wasn't intentionally left out in this case. Are you saying it should work either way (it should)? @Purmou ah, ok. I'll add a note. Thanks! Yes, you can do something like that. If you get more specific, so will others @yumamd the problem is that your question isn't clear. Can you explain what's *not* working and what errors you're getting? In case it's related, there's a bug in Safari/iOS which prevents that format from working... http://stackoverflow.com/a/4310986/29 @yumamd we're all confused because the answer to *that* question is "yes"...so we're assuming you're having another problem. +1 it doesn't get much simpler than this @yumamd are you trying to put it in the `where` clause? I would also suggest using UTC (via `GETUTCDATE()`) wherever possible. It's a tiny bit faster, and helps you avoid a lot of time-related issues. Hi @jilius, why do you want this? Haack's post is about binding list of objects, not listboxes... I'm not entirely sure what you're going for so I"ll just throw this out there: look at `pivot`. If you want to do things dynamically, though, you might have to use some dynamic sql ([ref](http://stackoverflow.com/questions/2170058/can-sql-server-pivot-without-knowing-the-resulting-column-names)) Which URL do you want users to see? Should they be redirected to the Url with the QS? Do you have any script errors in the browser? Another way to set the interval is by passing in a timespan object. I think it's a little bit cleaner: [`Timespan.FromMinutes(5)`](http://msdn.microsoft.com/en-us/library/system.timespan.fromminutes.aspx) No. Definitely not a YSOD if you do it correctly. Let the unhandled error bubble up to your global error handler. This presents a friendly face on the error, and Elmah still gets a piece of the action. +1. Log4Net is awesome. (Don't avoid it because of its low activity in recent years.) @Dragan yep, that's a common way to do it @JeffAtwood what did you end up doing in your case? As of [2.2](http://docs.mongodb.org/manual/reference/method/db.collection.insert/), insert can take an array of docs, so you could do `var docs = ...find(...).toArray(); db.coll.insert(docs)`. I haven't found performance to be very good in either case, though @KevinB what browser/OS? I can repro it with the fiddle with Win7 (x64) + IE9.0.8112 (x86) possible duplicate of [What does sp\_reset\_connection do?](http://stackoverflow.com/questions/596365/what-does-sp-reset-connection-do) This probably worked by purging an oauth-related DLL that was already in your bin/obj folders. Removing the reference and rebuilding wouldn't remove the offending files, but blowing away the directories would. Thanks, awesomely helpful. I adapted this slightly to include the build configuration: `%system.teamcity.build.workingDir%\\**\bin\%env.BUILD_CONFIG%\\**\*Tests.dll` Unrelated to your question: `.Where(x=>...).First()` can usually be replaced with `.First(x=>...)`. If there must be only one, then `.Single(x=>...)` would be even better. If there must be 0 or 1, then I'd use `SingleOrDefault(x=>...)` and check for null. It might be weird at first, but I don't think it's a hack. You can use this approach for deletes, too, I think. Perfect! This is exactly what I needed. Note: this answer is correct for errors from MSBuild (prefixed with "MSB"), as OP asked. If Google brought you here and you want to suppress compiler errors (e.g. "CS2008"), you can do what OP did: `/p:nowarn=2008` (strip the "CS" off the number) Note: if you echo `n` instead you will get more consistent behavior. You will still continue with the connection, but the key won't be cached. It will ask you for it every time. Yes, I have--the 48mb download. It doesn't seem to be enough. Hmmm. Maybe this particular issue is actually only giving me build _warnings_, not errors. Not as big of a deal, but I'm still curious if there's a way... I gave up and just installed [Visual Studio 2012 Express](http://www.microsoft.com/visualstudio/eng/downloads#d-2012-express) (for web). That fixed it. @Mark0978 I read it to mean: "it's already composed, i.e. "iOS styled" (by you), so iOS won't mess with it (except to round the corners)" @BrentDaCodeMonkey sure, but I would have expected to still have access to the original request via a header, variable, etc. Surely there must be _some way_ to get to it? @viperguynaz MVC, though I doubt that matters...? (It *does* work locally, but not from Azure, which is likely behind some load balancer/proxy) @mehow, it [seems](http://msdn.microsoft.com/en-us/library/aa224033(v=sql.80).aspx) that way, but I don't have a reference indicating such explicitly. Related q: http://stackoverflow.com/questions/9917196/meaning-of-square-brackets-in-ms-sql-table-designer This url muck business means I can do things like http://url-tests.azurewebsites.net/////home////index////, which clearly shouldn't work, but does in Azure. @viperguynaz interesting! did you check the server variables, too (i.e. not just `Request.RawUrl`)? @astaykov I'll spin up a Server 2012 box and check, good idea. Something like a subscription? If you can't find it, searching for "subscription" plugins might help The service I'm calling requires it, unfortunately :/ HO LY CRAP. That's awesome. I would suggest using optimistic concurrency in that case. E.g. when you send your transaction, include some value that indicates the state of the data as _you_ know it. The server can check this "last updated" value when it does its atomic operation. If they match: continue. If not: error. When the client get this concurrency error it can refresh everything and see that the transaction already happened. Note that this problem is not exclusive to REST-- regular RDBMSs have it, too. Related: http://en.wikipedia.org/wiki/Two_Generals'_Problem Well...if you're going to ask a bunch of new questions not already asked, you've got to give us a chance to answer them. I updated my answer with an unsatisfying conjecture. I haven't tried this, but just a tip: you can reduce that to just return the `if` expression, e.g. `return parseFloat...` Oh, this is so awesome. Thank you! To help future readers: [here's](http://stackoverflow.com/q/3397479/29) where `gacutil` is hiding It's been a while since your answer was written...is all this still accurate? Tip: make sure your `DbSet`s in your context are `virtual` Link to relevant section: https://github.com/sympy/sympy/wiki/Git-hg-rosetta-stone#rosetta-stone @bonCodigo: if you want the output for a specific culture, specify the culture explicitly. The referenced [answer](http://stackoverflow.com/a/6037277/177570) describes a bunch of different methods for different situations--click through! (@TriQ- thanks for linking it!) @mason: I agree with that _now_. When asked, though, these types of questions were permitted (and common). @mason no problem-- you didn't need to remove your vote :) @Rusty: you need to renew the lock _before_ it expires. If the lock expires in five minutes, renew it 10 seconds earlier. You can renew repeatedly. In my case I saw the same errors, but had an issue with my performance counters being corrupt. If you can't even open perfmon, check this out: http://answers.microsoft.com/en-us/windows/forum/windows_7-performance/perfmon-problems-unable-to-add-counters/e90f231d-0014-457d-8b1f-5f342971597a This does _not_ apply to projects/solutions. Note that the _server_ can respond with multiple `Set-Cookie` headers: http://tools.ietf.org/html/rfc6265#page-7 On a Mac you can try the [Mono Installer](http://www.mono-project.com/download/) This [list of timezone IDs](http://stackoverflow.com/a/7908482/29) might be helpful For Azure Cloud Services and VMs it looks like [this is configurable](http://azure.microsoft.com/blog/2014/08/14/new-configurable-idle-timeout-for-azure-load-balancer/). I haven't found an answer for Azure Websites/WebApps yet. @ZainRizvi it's not so rare for us, which I appreciate points to an app issue. Are you saying that it's not supported? Hi @Zain- an issue I'm seeing with my app is that after deploys (and sometimes hours after a deployment) it responds _very_ slowly (minutes) before ultimately giving 503s. My theory was that the load balancer was cycling VMs or something because they were all thought to be unhealthy. I'm assuming it's an issue with my app.Do you have any advice for where to start with issues that lead to 503s from an Azure site with multiple nodes? Actually...it behaves very similarly to what we see if I "restart" the site--I get 403s and 503s for just about 2 minutes. Is there something we could be doing with our app start process (which would get triggered during a deployment, swap, and occasionally during normal operations) that would look like that? Thank you for those suggestions! I did the "Diagnose Now" action and it did help me to **recreate** the problem--my site locked up for about 10 minutes (extremely slow responses, which were usually 502s or 503s). I'm assuming the diagnostics do not typically disrupt the deployed application? I ran it again and it _didn't_ disrupt things the second time (just a conincidence perhaps). Related, the support portal listed my site status as "This site is unhealthy, and may be affected due to an unknown issue with Azure App Service. Please report this." @Val- the query part isn't that interesting and could even be a match-all. e.g. `{ "sort": { "date_added": { "order": "desc" } }}` @AndreiStefan given my relatively small set maybe I should just always retrieve 200 docs and do pagination outside of Elasticsearch? Then maybe all I need is a way to scope the aggregation to the top N docs (no `from` needed then)--is that possible? Hmmm, now I'm not so sure. Does top_hits more limit individual buckets rather than the set of documents they gather aggregations for? Do you have a reference that indicates AWS R53 health checks can't be used with non-AWS endpoints? It appears to be pretty platform-agnostic to me? ^^ [reference](http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/using-domain-names-with-elb.html): "In a failover configuration, Amazon Route 53 checks the health of the registered EC2 instances for the load balancer to determine whether they are available." Did you find that using non-ssl continued to solve your problems? I tried this and noticed no effect for my setup. @TimothyLeeRussell if you use in-proc state then _just don't do anything_. The _default_ behavior has session/server affinity so you should be fine. In my case I _don't want_ affinity so I have to add this header to remove it. @bobbel I must insist that indexes can absolutely improve retrieval beyond just finding the desired records, *if* they cover the requested columns. Covering indexes can yield a massive performance improvement by answering the entire query/join/etc. from the index itself -- without going to the underlying data that generated the index. I would guess a lot of people refer to this question for parsing user input, which will typically be a _string_. This answer fails in those cases, as you correctly list in the examples, e.g. `Number.isFinite('0') -> false` See also: http://stackoverflow.com/a/37149251/29, which shows another place to put the `siteConfig` block. If this isn't working for you make sure you didn't forget the last parameter-- `, {}`. Without it you get just the first value. Note that you may want to use `.AbsoluteUri`, not `.ToString` https://stackoverflow.com/a/7624992/29 Note that you may want to use `.AbsoluteUri`, not `.ToString` https://stackoverflow.com/a/7624992/29 Yes! `set_unescape_uri` looks like what I want. It looks like it's part of openresty -- I'll get that and try it. Thank you! That did it. I'm all set. Thank you so much! @Bananenaffe- if I'm reading the right warning on that docs page, the concern isn't around anonymous functions, it's with code passed as a `string`, which must be executed via `eval`. If I go that route then I would have an app that would have narrow access to things through ARM/RBAC, which is great. I could limit it to managing Traffic Manager endpoints, for example. But now this narrow access isn't user-specific. Ideally I could both limit the app's access to what the person using it can do (_their_ traffic management endpoints), and further limit it to the types of actions I specifically grant to the app (_enable or disable_, not delete), resulting in an even narrow set of abilities. It sounds like a backup-style tool may be what you're looking for.I've been using SyncBack (one of the versions is free). You could also try out MS SyncToy which tries to make moving, copying, syncing, etc. easy.If you really do copy just random files at random times, you could try Total Copy which has the added benefit of working well over a network (pause, resume, etc.). This utility by Erland Sommarskog is awesomely useful.It's a stored procedure you add to your database. Run it whenever you want to see what queries are active and get a good picture of locks, blocks, etc. I use it regularly when things seem gummed up. What's the cleanest, most effective way to validate decimal numbers in JavaScript?Bonus points for:Clarity. Solution should be clean and simple.Cross-platform.Test cases:01. IsNumeric('-1') =&gt; true02. IsNumeric('-1.5') =&gt; true03. IsNumeric('0') =&gt; true04. IsNumeric('0.42') =&gt; true05. IsNumeric('.42') =&gt; true06. IsNumeric('99,999') =&gt; false07. IsNumeric('0x89f') =&gt; false08. IsNumeric('#abcdef') =&gt; false09. IsNumeric('1.2.3') =&gt; false10. IsNumeric('') =&gt; false11. IsNumeric('blah') =&gt; false This way seems to work well:function IsNumeric(input){ var RE = /^-{0,1}\d*\.{0,1}\d+$/; return (RE.test(input));}And to test it:// alert(TestIsNumeric());function TestIsNumeric(){ var results = '' results += (IsNumeric('-1')?"Pass":"Fail") + ": IsNumeric('-1') =&gt; true\n"; results += (IsNumeric('-1.5')?"Pass":"Fail") + ": IsNumeric('-1.5') =&gt; true\n"; results += (IsNumeric('0')?"Pass":"Fail") + ": IsNumeric('0') =&gt; true\n"; results += (IsNumeric('0.42')?"Pass":"Fail") + ": IsNumeric('0.42') =&gt; true\n"; results += (IsNumeric('.42')?"Pass":"Fail") + ": IsNumeric('.42') =&gt; true\n"; results += (!IsNumeric('99,999')?"Pass":"Fail") + ": IsNumeric('99,999') =&gt; false\n"; results += (!IsNumeric('0x89f')?"Pass":"Fail") + ": IsNumeric('0x89f') =&gt; false\n"; results += (!IsNumeric('#abcdef')?"Pass":"Fail") + ": IsNumeric('#abcdef') =&gt; false\n"; results += (!IsNumeric('1.2.3')?"Pass":"Fail") + ": IsNumeric('1.2.3') =&gt; false\n"; results += (!IsNumeric('')?"Pass":"Fail") + ": IsNumeric('') =&gt; false\n"; results += (!IsNumeric('blah')?"Pass":"Fail") + ": IsNumeric('blah') =&gt; false\n"; return results;}I borrowed that regex from http://www.codetoad.com/javascript/isnumeric.asp. Explanation:/^ match beginning of string-{0,1} optional negative sign\d* optional digits\.{0,1} optional decimal point\d+ at least one digit$/ match end of string Over the last few months/years, I have shared a folder or two with numerous people on my domain. How do I easily revoke those shares to keep access to my system nice and tidy? On Windows XP, go to:Administrative Tools &gt; Computer Management &gt; System Tools &gt; Shared Folders &gt; SharesThis page lists all shares and lets you remove them easily, in one place. First, you never stop testing. When you are done testing and you release it, all that means is that your users are testing instead of you.Second, when your comprehensive test scripts pass with an acceptable level of failure you are ready to move on.Finally, this is highly specific to your case. On some projects, we have a 3 week beta test period where lots of people hack on the system before the smallest of changes can be rolled out. In other areas (less critical), small changes can be moved out with just the nod of another developer. Jon,I didn't mean test scripts to imply automated testing. I was referring to the more traditional approach of a step-by-step list of what to test and how to test it.That said, I don't agree that all automated tests should be required to pass. It all depends on severity and priority. On a large project, we can have devs writing tests that fail based on issues reported by users. Since we can't fix every bug with every release, it's a given that some tests simply won't pass. I've seen a lot of these types of questions lately--optimization to the nth degree.I think it makes sense in certain circumstances:Computing condition 2 is not a constant time operationYou are asking strictly for educational purposes--you want to know how the language works, not to save 3us.In other cases, worrying about the "fastest" way to iterate or check a conditional is silly. Instead of writing tests which require millions of trials to see any recordable (but insignificant) difference, focus on clarity.When someone else (could be you!) picks up this code in a month or a year, what's going to be most important is clarity.In this case, your first example is shorter, clearer and doesn't require you to repeat yourself. Ben's got it. That doc is a little confusing. Refer to the last block on the page, "Nested transactions".  Theoretically, no, they are not unique. It's possible to generate an identical guid over and over. However, the chances of it happening are so low that you can assume they are unique.I've read before that the chances are so low that you really should stress about something else--like your server spontaneously combusting or other bugs in your code. That is, assume it's unique and don't build in any code to "catch" duplicates--spend your time on something more likely to happen (i.e. anything else).I made an attempt to describe the usefulness of GUIDs to my blog audience (non-technical family memebers). From there (via Wikipedia), the odds of generating a duplicate GUID:1 in 2^1281 in 340 undecillion (dont worry, undecillion is not on thequiz)1 in 3.4  10^381 in 340,000,000,000,000,000,000,000,000,000,000,000,000 First, accept the fact that problems with your app (code, usability, etc.) will be discovered.Then, make sure you have a clear way for users to communicate with you (form mail, email, uservoice, etc.). The easier you make this the better. For example, there is a uservoice link on every page of SO.One philosophy I strongly believe in: if it's confusing to your users, it's broken. Be willing to change your app (no matter how "beautiful" the design may be) if your users are confused or not liking it. This doesn't mean you have to cave on your decisions, just that you need to consider revisions to improve the user experience. I think Jeff complained about this recently. One common technique is to drag all the objects into the designer again...I hope someone else chimes in with a better approach! This is a perfectly good use of GUIDs. The only draw backs would be a slight complexity in working with GUIDs over INTs and the slight size difference (16 bytes vs 4 bytes).I don't think either of those are a big deal. Mutex: exclusive-member access to a resourceSemaphore: n-member access to a resourceThat is, a mutex can be used to syncronize access to a counter, file, database, etc.A sempahore can do the same thing but supports a fixed number of simultaneous callers. For example, I can wrap my database calls in a semaphore(3) so that my multithreaded app will hit the database with at most 3 simultaneous connections. All attempts will block until one of the three slots opens up. They make things like doing naive throttling really, really easy. This extension will do it for you:https://addons.mozilla.org/en-US/firefox/addon/2848 Since half of that regex handles the fact that the last segment doesn't have a period at the end, you could cut it in half if you tack a '.' to the end of your possible IP address.Something like this:bool IsValidIPAddress(string possibleIP){ CrazyRegex = \b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){4}\b return Regex.Match(possibleIP+'.', CrazyRegex)} @unsliced: true, this problem can get a little crazy.If you really need to handle any possible IP address then you'll have to put together something more sophisticated.However, if you just want to do basic validation to make sure users are entering properly formatted data, I think it's fair to restrict them to the a.b.c.d model with the above regular expressions. In .NET there's an IPAddress type which has a handy method TryParse.Example: if(System.Net.IPAddress.TryParse(PossibleIPAddress, validatedIPAddress)){ //validatedIPAddress is good}// or more simply:bool IsValidIPAddress(string possibleIP){ return System.Net.IPAddress.TryParse(PossibleIPAddress, null)} How do you shade alternating rows in a SQL Server Reporting Services report?Edit: There are a bunch of good answers listed below--from quick and simple to complex and comprehensive. Alas, I can choose only one... Go to the table row's BackgroundColor property and choose "Expression..."Use this expression: = IIf(RowNumber(Nothing) Mod 2 = 0, "Silver", "Transparent")This trick can be applied to many areas of the report.And in .NET 3.5+ You could use:= If(RowNumber(Nothing) Mod 2 = 0, "Silver", "Transparent")Not looking for rep--I just researched this question myself and thought I'd share. I primarily use Microsoft Enterprise Library Data Access Block to access stored procedures in MS SQL Server databases. This is usually handled with network shares. Share your code folder from your host machine and access it from the VMs. Does your load balancer supports sticky sessions? With this on, the balancer will route the same IP to the same server over and over within a certain time window. This way, all requests (AJAX or otherwise) from one client would always hit the same server in the cluster/farm.  I'm usually in the "shorter is better" camp. Your example is good:ObjectA a = getTheUser(session.getState().getAccount().getAccountNumber());I would cringe if I saw that over four lines instead of one--I don't think it'd make it easier to read or understand. The way you presented it here, it's clear that you're digging for a single object. This isn't better:obja State = session.getState();objb Account = State.getAccount();objc AccountNumber = Account.getAccountNumber();ObjectA a = getTheUser(AccountNumber);This is a compromise:objb Account = session.getState().getAccount();ObjectA a = getTheUser(Account.getAccountNumber());but I still prefer the single line expression. Here's an anecdotal reason: it's difficult for me to reread and error-check the 4-liner right now for dumb typos; the single line doesn't have this problem because there are simply fewer characters. This post addresses your question. The gist of it is:Text Editor &gt; C# &gt; Advanced &gt; Generate XML documentation comments for /// Can you clone the collection and then redirect to the page with the cloned (and modified) collection?I know it's not much better than iterating... You can use one of the builtin validators with a regex that counts the words.I'm a little rusty with regex so go easy on me:(\b.*\b){0,10} The brackets are required if you use keywords or special chars in the column names or identifiers. You could name a column [First Name] (with a space)--but then you'd need to use brackets every time you referred to that column.The newer tools add them everywhere just in case or for consistency. Performance is improved with typed datasets over untyped datasets (though I've never found performance issues with trivial things like that worth worrying about).I'd say the biggest pain is just keeping them in sync with your database--I can't speak for VS 2008 but prior versions do not provide good support for this. I literally drag the procs onto the designer everytime the resultset's schema changes. Not fun.But, you do get compile time type checking which is great and things like Customer.Name instead of Dataset.Tables(0).Rows(0)("Name").So, if your schema is relatively static, they may be worth it, but otherwise, I wouldn't bother.You could also look into a real ORM. Another hack is the old 1x1 transparent pixel trick. Insert an 1x1 transparent gif image and set its width in the image tag to the width you want. This will force the cell to be at least as wide as the image. Alternative syntax:INSERT tbl (Col1, Col2, ..., ColN) SELECT Col1, Col2, ..., ColN FROM Tbl2 WHERE ...The select query can (of course) include expressions, case statements, constants/literals, etc. Are there any tools to facilitate a migration from Sourcegear's Vault to Subversion?I'd really prefer an existing tool or project (I'll buy!).Requirements:One-time migration onlyFull history with commentsOptional:Some support for labels/branches/tagsRelatively speedy. It can take hours but not days.Cost if availableBonus points if you can share personal experience related to this process.One of the reasons I'd like to do this is because we have lots of projects spread between Vault and Subversion (we're finally away from sourcesafe). It'd be helpful in some situations to be able to consolidate a particular customer's repos to SVN.Additionally, SVN is better supported among third party tools. For example, Hudson and Redmine.Again, though: we're not abandoning vault altogether. Once you have data into Date objects in VB, you don't have to worry about globalization until you compare something to it or try to export it.This is fine:Dim FirstDate as Date = Date.UtcNow() 'or this: = NewDate (2008,09,10)'Dim SecondDate as DateSecondDate = FirstDate.AddDays(1)This pulls in the globalization rules and prints in the current thread's culture format:HeaderLabel.Text = SecondDate.ToString()This is bad: Dim BadDate as Date = CDate("2/20/2000")Actually--even that is OK if you force CDate in that case to use the right culture (InvariantCulture):Dim OkButBadPracticeDate as Date = CDate("2/20/2000", CultureInfo.InvariantCulture)If you want to force everything to a particular culture, you need to set the executing thread culture and UI culture to the desired culture (en-US, invariant, etc.).Make sure you aren't doing any work with dates as strings--make sure they are actual Date objects! SQL is a set based language--that's what it does best.I think cursors are still a bad choice unless you understand enough about them to justify their use in limited circumstances.Another reason I don't like cursors is clarity. The cursor block is so ugly that it's difficult to use in a clear and effective way.All that having been said, there are some cases where a cursor really is best--they just aren't usually the cases that beginners want to use them for. A couple questions: Does the user that executes your app (you?) have permission to write to the file? Is the file read-only?What is your connection string?If you're using ASP, you'll need to add the IUSER_* user as in this example. Like everything else: it depends.There is no hard and fast rule regarding column count vs table count.If your customers need to have multiple addresses, then a separate table for that makes sense. If you have a really good reason to normalize the City column into its own table, then that can go, too, but I haven't seen that before because it's a free form field (usually).A table heavy, normalized design is efficient in terms of space and looks "textbook-good" but can get extremely complex. It looks nice until you have to do 12 joins to get a customer's name and address. These designs are not automatically fantastic in terms of performance that matters most: queries.Avoid complexity if possible. For example, if a customer can have only two addresses (not arbitrarily many), then it might make sense to just keep them all in a single table (CustomerID, Name, ShipToAddress, BillingAddress, ShipToCity, BillingCity, etc.).Here's Jeff's post on the topic. Stick with int32. That's what vb's "Integer" and SQL's INT is, anyway.You will not gain any significant performance improvement by using a tinyint/byte or an short/int16 instead of int/int32.In fact, the headaches you might run into in the future caused by all the casting you might have to do for objects that expect int32s will drive you crazy. I am a fan of limiting logins by using a credit card or cell phone SMS (like Craigslist and Gmail). These methods don't cost much (&lt;$1), but can be highly effective in keeping spam accounts under control.However, this is tricky on a site like SO because one of the founding goals is to have minimum friction and allow anonymous users to contribute. I guess that's where the throttling and voting comes into play. Rather than tweaking your files directly, I would recommend compressing them. Most clients support it.I think you'll find that this is easier and just as effective.More details from Jeff's adventures with it. Just set :http_only to true as described in the changelog. Like edg indicated, you'll need a more complex algorithm to handle special names (this is probably why many places force everything to upper case).Something like this untested c# should handle the simple case you requested:public string SentenceCase(string input){ return input(0, 1).ToUpper + input.Substring(1).ToLower;} See this question. I usually view them more in terms of algorithms or structures. For example, you could have a loop invariant that could be asserted--always true at the beginning or end of each iteration. That is, if your loop was supposed to process a collection of objects from one stack to another, you could say that |stack1|+|stack2|=c, at the top or bottom of the loop.If the invariant check failed, it would indicate something went wrong. In this example, it could mean that you forgot to push the processed element onto the final stack, etc. I would use Load if you expect it to take "file-time" and Get if you expect it to take "simple DB" time.That is, if the call is expensive, use "Load". Gut-based estimates come with experience but you really need to detail out the tasks involved to get something reasonable.If you have a spec or at least some constraints, you can start creating tasks (design users page, design tags page, implement users page, implement tags page, write tags query, ...).Once you do this, add it up and double it. If you are going to have to coordinate with others, triple it.Record your actual time in detail as you go so you can evaluate how accurate you were when the project is complete and hone your estimating skills. Yes it's true but you shouldn't care. Go with the one that's easier to read. If you have to benchmark your app, then focus on the bottlenecks. I would guess that string concatenation isn't going to be your bottleneck. Most projects of reasonable size should have a programming/coding standards document that dictates common conventions and naming guidelines that should be followed.Another way to help with this is through code reviews. Obviously some coordination among reviewers is required (the document helps with that, too). Code reviews help keep the greener devs and senior devs alike on track and act as an avenue to enforce the coding standards. A cookie would work just fine. Or you could modify the query string each time with a "mode=x" or "load=x" parameter.This would present a problem if the user tries to bookmark the final page, though. If that's an option, the cookie solution is fine. I would guess they need cookies enabled to get that far in the app anyway? Since ISNULL in Access is a boolean function (one parameter), use it like this:SELECT Column1, Column2, IIF(ISNULL(Column3),0,Column3) + IIF(ISNULL(Column4),0,Column4) AS [Added Values]FROM Table It's for you (and future maintainers), not the compiler. The thread pool is a convenient choice if you have light weight sporadic processing that isn't time sensitive. However, I recall reading on MSDN that it's not appropriate for large scale processing of this nature.I used it for something quite similar to this and regret it. I took a worker-thread approach in subsequent apps and am much happier with the level of control I have.My favorite pattern in the worker-thread model is to create a master thread which holds a queue of tasks items. Then fork a bunch of workers that pop items off that queue to process. I use a blocking queue so that when there are no items the process, the workers just block until something is pushed onto the queue. In this model, the master thread produces work items from some source (db, etc.) and the worker threads consume them. I think this is why a lot of things are sorted by release date.A solution could be to create another column in your table for the "SortKey". This could be a sanitized version of the title which conforms to a pattern you create for easy sorting or a counter. My customers often stipulate what database engine we will be using. We write .net apps against non-SQLServer dbs regularly. In the long run, it's better for the customer because they get to maintain what they know. In most languages, the Date/DateTime/etc. classes have methods for things like this. When using these, it's best-practice to convert all dates to UTC before performing arithmetic.e.g., C#:// In UTC, preferablyDateTime ClockIn;DateTime ClockOut;ClockIn = ...;ClockOut = ...;TimeSpan TimeWorked = ClockOut.Subtract(ClockIn);float HoursWorked = TimeWorked.TotalHours(); I'd populate a hashtable with valid abbreviations and then check it with the input for validation. It's much cleaner and probably faster if you have more than one check per dictionary build. Go with all numbers or all letters. If you must mix it up, then make sure there are no ambiguous characters (Il1m, O0, etc.). When displayed/printed, put spaces in every 3-4 characters but make sure your systems can handle inputs without the spaces.Edit:Another thing to consider is having a built in way to distinguish orders, customers, etc. e.g. customers always start with 10, orders always start with 20, vendors always start with 30, etc. I think the RFC says 4096 chars but IE truncates down to 2083 characters. Stay well under that to be safe.Practically, shorter URLs are friendlier. Requirements must be specific and unambiguous with respect to what's needed, but should be less so on how to meet the requirements. Another approach is to actually linkify the contents of each cell. You could change the style if necessary so they don't look like traditional links.Note that what you are trying to do does break the intuitive user experience a little bit. It needs to be clear that clicking on a row does something. I usually prefer to put an icon at the edge of each row (a magnifying glass, etc.) which drills into a new page. Create a database constraint:ALTER TABLE Table1 ADD CONSTRAINT Constraint1 CHECK (YourCol &gt; 0)You can have pretty sophisticated constraints, too, involving multiple columns. For example:ALTER TABLE Table1 ADD CONSTRAINT Constraint2 CHECK (StartDate&lt;EndDate OR EndDate IS NULL) Running something that large inside a single transaction is not a good idea. Therefore, I'd recommend breaking up the file into smaller, more manageable chunks. Another option is to look at some of the other ways to import CSV data directly. You could use the operating system to move the files. This is what tools like WinMerge do. You click the "copy" button in your app and it pops up the Windows progress box as if you had used Explorer to arrange the copy. This thread describes it. Try "Button" (capital B):&lt;body&gt; &lt;form id="form1" runat="server"&gt; &lt;div&gt; &lt;asp:Button id="button1" runat="server" /&gt; &lt;/div&gt; &lt;/form&gt;&lt;/body&gt; This is exactly what XSLT is for! It transforms XML files into a different output. In your case, you could use a relatively simple XSL transformation to output a list.This might do it:records.xml:&lt;?xml version="1.0"?&gt;&lt;?xml-stylesheet type="text/xsl" href="style.xsl"?&gt;&lt;Records&gt; &lt;Record&gt; &lt;name&gt;adam&lt;/name&gt; &lt;telephonenumber&gt;000&lt;/telephonenumber&gt; &lt;/Record&gt; &lt;Record&gt; &lt;name&gt;mike&lt;/name&gt; &lt;telephonenumber&gt;001&lt;/telephonenumber&gt; &lt;/Record&gt;&lt;/Records&gt;style.xsl&lt;xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0"&gt; &lt;xsl:output method="text" omit-xml-declaration="yes" indent="no"/&gt; &lt;xsl:template match="Record"&gt; &lt;xsl:value-of select="name"/&gt;&lt;xsl:text&gt; &lt;/xsl:text&gt;&lt;xsl:value-of select="telephonenumber"/&gt; &lt;/xsl:template&gt;&lt;/xsl:stylesheet&gt;I tested it with this tool and it works. Yes, you probably want repeatable read. I'd probably handle this via optimistic locking wherein you only update if the existing value is the same as it was when you read (test-and-set). If the value isn't the same, raise an error. This allows you to run read-uncommitted, without deadlocks, and without data corruption.BEGIN TRANSACTIONDECLARE MONEY @amountSELECT Amount AS @amount FROM Deposits WHERE UserId = 123UPDATE Deposits SET Amount = @amount + 100.0 WHERE UserId = 123 AND Amount = @amountIF @@ROWCOUNT &lt;&gt; 1 BEGIN ROLLBACK; RAISERROR(...) ENDELSE COMMIT END Use the I'm Feeling Lucky function.Example:  http://www.google.com/search?hl=en&amp;q=stackoverflow&amp;btnI=I'm+Feeling+Lucky&amp;aq=f&amp;oq=It automatically takes you to the top result. I agree that the design isn't the greatest--an event based structure with a single row for start-end will probably save you a lot of time. In that case, you could create a record with a null end-date when someone clocks in. Then, fill in the end date when they clock out.But, that's not what you asked. This is the solution to your problem:DECLARE @clock TABLE (ClockActionID INT PRIMARY KEY IDENTITY, ActionType INT, ActionDateTime DATETIME)INSERT INTO @clock (ActionType, ActionDateTime) VALUES (1,'20080101 00:00:00')INSERT INTO @clock (ActionType, ActionDateTime) VALUES (2,'20080101 00:01:00')INSERT INTO @clock (ActionType, ActionDateTime) VALUES (1,'20080101 00:02:00')INSERT INTO @clock (ActionType, ActionDateTime) VALUES (2,'20080101 00:03:00')INSERT INTO @clock (ActionType, ActionDateTime) VALUES (1,'20080101 00:04:00')INSERT INTO @clock (ActionType, ActionDateTime) VALUES (2,'20080101 00:05:00')INSERT INTO @clock (ActionType, ActionDateTime) VALUES (1,'20080101 00:06:00')INSERT INTO @clock (ActionType, ActionDateTime) VALUES (2,'20080101 00:07:00')INSERT INTO @clock (ActionType, ActionDateTime) VALUES (1,'20080101 00:08:12')INSERT INTO @clock (ActionType, ActionDateTime) VALUES (2,'20080101 00:09:00')-- Get the rangeSELECT ActionDateTime CheckIn, (SELECT TOP 1 ActionDateTime FROM @clock C2 WHERE C2.ActionDateTime &gt; C.ActionDateTime) CheckOut FROM @clock CWHERE ActionType = 1-- Get the durationSELECT DATEDIFF(second, ActionDateTime, (SELECT TOP 1 ActionDateTime FROM @clock C2 WHERE C2.ActionDateTime &gt; C.ActionDateTime) ) / 60.0 Duration_MinutesFROM @clock CWHERE ActionType = 1Note that I'm using a table variable which works with MS SQL Server just for testing. Change as needed. Also note that SQL Server 2000 does not perform well with queries like this. Here are the test results:CheckIn CheckOut2008-01-01 00:00:00.000 2008-01-01 00:01:00.0002008-01-01 00:02:00.000 2008-01-01 00:03:00.0002008-01-01 00:04:00.000 2008-01-01 00:05:00.0002008-01-01 00:06:00.000 2008-01-01 00:07:00.0002008-01-01 00:08:12.000 2008-01-01 00:09:00.000Duration_Minutes1.0000001.0000001.0000001.0000000.800000 If you end up including automatic email submissions, send them to a new mailbox so you can filter them and route them without disrupting your existing customer support people.Other than that, it might be useful to include:the software build number in the error message if you have multiple versions of your product floating around.the date/time in UTC the operating system/browser/environment/etc. (whatever's relevant)the user's security role, login, etc.follow up contact info (phone, email, etc.) for the usercontact information for YOU on the error screen It is executing the dragged in file with a path relative to the .bat file (and not where those dlls actually are)? How can I retrieve raw time-series data from a Proficy Historian/iHistorian?Ideally, I would ask for data for a particular tag between two dates. A coworker of mine put this together:In web.config:&lt;add name="HistorianConnectionString" providerName="ihOLEDB.iHistorian.1" connectionString=" Provider=ihOLEDB.iHistorian; User Id=; Password=; Data Source=localhost;"/&gt;In the data layer: public DataTable GetProficyData(string tagName, DateTime startDate, DateTime endDate){ using (System.Data.OleDb.OleDbConnection cn = new System.Data.OleDb.OleDbConnection()) { cn.ConnectionString = webConfig.ConnectionStrings.ConnectionStrings["HistorianConnectionString"]; cn.Open(); string queryString = string.Format( "set samplingmode = rawbytime\n select value as theValue,Timestamp from ihrawdata where tagname = '{0}' AND timestamp between '{1}' and '{2}' and value &gt; 0 order by timestamp", tagName.Replace("'", "\""), startDate, endDate); System.Data.OleDb.OleDbDataAdapter adp = new System.Data.OleDb.OleDbDataAdapter(queryString, cn); DataSet ds = new DataSet(); adp.Fill(ds); return ds.Tables[0]; }}Update: This worked well but we ran into an issue with tags that don't update very often. If the tag didn't update near the start or end of the requested startDate and endDate, the trends would look bad. Worse, still were cases where there were no explicit points during the window requested--we'd get no data back.I resolved this by making three queries:The previous value before the start-dateThe points between startDate and endDate The next value after the endDateThis is a potentially inefficient way to do it but It Works:public DataTable GetProficyData(string tagName, DateTime startDate, DateTime endDate){ DataSet ds = new DataSet(); string queryString; System.Data.OleDb.OleDbDataAdapter adp; using (System.Data.OleDb.OleDbConnection cn = new System.Data.OleDb.OleDbConnection()) { cn.ConnectionString = proficyConn.ConnectionString; cn.Open(); // always get a start value queryString = string.Format( "set samplingmode = lab\nselect value as theValue,Timestamp from ihrawdata where tagname = '{0}' AND timestamp between '{1}' and '{2}' order by timestamp", tagName.Replace("'", "\""), startDate.AddMinutes(-1), startDate); adp = new System.Data.OleDb.OleDbDataAdapter(queryString, cn); adp.Fill(ds); // get the range queryString = string.Format( "set samplingmode = rawbytime\nselect value as theValue,Timestamp from ihrawdata where tagname = '{0}' AND timestamp between '{1}' and '{2}' order by timestamp", tagName.Replace("'", "\""), startDate, endDate); adp = new System.Data.OleDb.OleDbDataAdapter(queryString, cn); adp.Fill(ds); // always get an end value queryString = string.Format( "set samplingmode = lab\nselect value as theValue,Timestamp from ihrawdata where tagname = '{0}' AND timestamp between '{1}' and '{2}' order by timestamp", tagName.Replace("'", "\""), endDate.AddMinutes(-1), endDate); adp = new System.Data.OleDb.OleDbDataAdapter(queryString, cn); adp.Fill(ds); return ds.Tables[0]; }}And yes, I know, those queries should be parameterized. I'm trying to assert that one object is "equal" to another object. The objects are just instances of a class with a bunch of public properties. Is there an easy way to have NUnit assert equality based on the properties?This is my current solution but I think there may be something better:Assert.AreEqual(LeftObject.Property1, RightObject.Property1)Assert.AreEqual(LeftObject.Property2, RightObject.Property2)Assert.AreEqual(LeftObject.Property3, RightObject.Property3)...Assert.AreEqual(LeftObject.PropertyN, RightObject.PropertyN)What I'm going for would be in the same spirit as the CollectionEquivalentConstraint wherein NUnit verifies that the contents of two collections are identical. I want to write unit tests with NUnit that hit the database. I'd like to have the database in a consistent state for each test. I thought transactions would allow me to "undo" each test so I searched around and found several articles from 2004-05 on the topic:http://weblogs.asp.net/rosherove/archive/2004/07/12/180189.aspxhttp://weblogs.asp.net/rosherove/archive/2004/10/05/238201.aspxhttp://davidhayden.com/blog/dave/archive/2004/07/12/365.aspxhttp://haacked.com/archive/2005/12/28/11377.aspxThese seem to resolve around implementing a custom attribute for NUnit which builds in the ability to rollback DB operations after each test executes.That's great but... Does this functionality exists somewhere in NUnit natively?Has this technique been improved upon in the last 4 years? Is this still the best way to test database-related code?Edit: it's not that I want to test my DAL specifically, it's more that I want to test pieces of my code that interact with the database. For these tests to be "no-touch" and repeatable, it'd be awesome if I could reset the database after each one.Further, I want to ease this into an existing project that has no testing place at the moment. For that reason, I can't practically script up a database and data from scratch for each test. You need to profile the load you are expecting. Then, you should choose a provider that can meet your anticipated demand and provide a path for growth. It's a lot easier growing if your colo provider can handle the growth gracefully. That is, if your project is the biggest one your provider has ever done or requires more sophisticated hardware than they are used to, you need to look for someone bigger.When you know what you want, be very specific, but not overly aggressive with your requirements. For example, if you need 8gb of memory, say 8gb. Don't say 4gb required but 16gb would be nice.I'd also request quotes on two systems: what you need today and what you might need in a year. Your conditions don't require that the next church for a given pastor be randomly selected. Couldn't you just iterate through the church list?That is, assign each pastor a number, 0-12. Assign each church a number, 0-12. The first month: Month 0: pastor-0 --> church-0 pastor-1 --> church-1 pastor-2 --> church-2 ... pastor-n --> church-n The next month, just increment one of the counters (with wrap-around) Month 1: pastor-0 --> church-1 pastor-1 --> church-2 pastor-2 --> church-3 ... pastor-n --> church-0 Then repeat for the remaining months: Month 3: pastor-0 --> church-2 pastor-1 --> church-3 pastor-2 --> church-4 ... pastor-(n-1) --> church-0 pastor-n --> church-1 There's a very simple loop to all this (O(n)). If it's confusing to you, I suggest trying the loop on paper with say n=3.If the randomness is a requirement then please update your question.EDIT BY PAXI'm deleting my answer and up-voting this one since it's O(n) and the expansion of mine to cater for the edits would have been at least O(n^2).You can still have randomness by making the pastor-0 through pastor-N values indexes into an array of pastors that has been randomly sorted so that makes this solution at least as good as mine.END EDIT BY PAX I have been asked to find training resources to bring engineers up to speed on VBA programming.The target trainee will have some systems engineering experience but little to no non-systems programming experience. I'm hoping for a computer-based training course or DVD that we can purchase and give to the engineers for a couple days to bring them up to speed with the basics.Unfortunately, my Google-fu is having a hard time cutting through the marketing sites to any obviously credible information. Any feedback on good (or bad) resources would be much appreciated.Edit: the engineers will be applying their new VBA skills in non-Office products. While reference materials are useful, I really need something that guides them through the basics. If you really can't accurately (and easily) predict the size of the list, don't bother.Don't build any code around determining it in advance (less code == better code).Also, doubling is a pretty effective way to grow the list with respect to performance.4 8 16 32 64 128 256 512 1024...you get the idea. What convention requires that tables have singular names? I always thought it was plural names.A user is added to the Users table.This site agrees:http://vyaskn.tripod.com/object_naming.htm#TablesThis site disagrees (but I disagree with it):http://justinsomnia.org/writings/naming_conventions.htmlAs others have mentioned: these are just guidelines. Pick a convention that works for you and your company/project and stick with it. Switching between singular and plural or sometimes abbreviating words and sometimes not is much more aggravating. Both, but primarily development history. The trunk doesn't need to be in a deployable state all the time--that'd be crazy.Instead, you commit commit commit until you are ready to deploy. Then, you tag/label/branch your repository to indicate what code was deployed. The style property is a collection. Do this:l_genericControl.Style.Add("css-name", "css-value")Or if you are using CSS classes, then change the CssClass property:l_genericControl.CssClass = "on-nav";If you're trying to toggle the CSS class with your javascript, try something like this (untested):l_genericControl.Attributes.Add("onmouseover", "this.className='on-nav';");l_genericControl.Attributes.Add("onmouseout", "this.className='off-nav';");If you want to change the style with your javascript, this might work:l_genericControl.Attributes.Add("onmouseover", "this.style.color='red'; this.style.backgroundColor='yellow';");l_genericControl.Attributes.Add("onmouseout", "this.style.color='black'; this.style.backgroundColor='none';"); I think you usually see those headers because the systems send them by default. I routinely remove them as they provide no real value and could, as you suggested reveal information about the server. I deployed an update to my ASP.NET application and started seeing this error on my page that used foo.dll: Unable to load foo.dll. The specified module could not be found. (Exception from HRESULT: 0x8007007E)foo.dll is in my system32 and application bin directory (which are in the path environment variable). What gives? It turns out that foo.dll depended on another dll which was missing. I used Dependency Walker to discover which files were missing. Once I copied over the missing files, the page started working fine. UPDATE Cells SET Cell = LEFT(Cell, 1) + '08' + SUBSTRING(Cell, 1, LEN(Cell)-1)  Possible Duplicate: Fastest way to determine if an integer&#39;s square root is an integer What's a way to see if a number is a perfect square?bool IsPerfectSquare(long input){ // TODO}I'm using C# but this is language agnostic.Bonus points for clarity and simplicity (this isn't meant to be code-golf).Edit: This got much more complex than I expected! It turns out the problems with double precision manifest themselves a couple ways. First, Math.Sqrt takes a double which can't precisely hold a long (thanks Jon). Second, a double's precision will lose small values ( .000...00001) when you have a huge, near perfect square. e.g., my implementation failed this test for Math.Pow(10,18)+1 (mine reported true). Just in case this isn't obvious: the sort order of your index does not promise much about the the sort order of the results in a query.In your queries, you must still add an ORDER BY KeyA, KeyBorORDER BY KeyB, KeyAThe optimizer may be pleased to find the data already physically ordered in the index as desired and save some time, but every query that is supposed to deliver data in a particular order must have an ORDER BY clause at the end of it. Without an order by, SQL Server makes no promises with respect to the order of a recordset, or even that it will come back in the same order from query to query. One of my favorite solutions to this problem is similar to the producer/consumer pattern.I create a master thread (pretty much my program's Main()) which holds a blocking queue object.This master thread spins off several worker threads which simple pop things off the central blocking thread and process them. Since it's a threadsafe blocking queue, the synchronization bits are easy--the TaskQueue.Dequeue() call will block until a task is enqueued by the producer/main thread.You can dynamically manage the number of workers you want or fix it according to a configuration variable--since they're all just popping things off the queue, the number of workers doesn't add any complexity.In my case, I have a service which processes several different types of tasks. I have the queue typed to handle something generic like TaskQueueTask. Then I subclass that and override the Execute() method. I've also tried the .NET threadpool approach where in you can throw things into the pool very easily. It was extremely simple to use but also provided little control, and no guarantee of execution order, timing, etc. It's recommended only for light-weight tasks. We use SQL Server 2000/2005 and Vault or SVN on most of our projects. I haven't found a decent solution for capturing database schema/proc changes in either source control system.Our current solution is quite cumbersome and difficult to enforce (script out the object you change and commit it to the database).We have a lot of ideas of how to tackle this problem with some custom development, but I'd rather install an existing tool (paid tools are fine).So: how do you track your database code changes? Do you have any recommended tools?Edit:Thanks for all the suggestions. Due to time constraints, I'd rather not roll my own here. And most of the suggestions have the flaw that they require the dev to follow some procedure.Instead, an ideal solution would monitor the SQL Database for changes and commit any detected changes to SCM. For example, if SQL Server had an add-on that could record any DML change with the user that made the change, then commit the script of that object to SCM, I'd be thrilled.We talked internally about two systems: 1. In SQL 2005, use object permissions to restrict you from altering an object until you did a "checkout". Then, the checkin procedure would script it into the SCM. 2. Run a scheduled job to detect any changes and commit them (anonymously) to SCM.It'd be nice if I could skip the user-action part and have the system handle all this automatically. In your global.asax.vb file, you can set the culture of the current page load:Thread.CurrentThread.CurrentCulture = System.Globalization.CultureInfo.CreateSpecificCulture("en-US")Thread.CurrentThread.CurrentUICulture = Thread.CurrentThread.CurrentCultureThis will make all the culture-aware functionality work nicely. e.g., (5000.25).ToString() will use commas vs. periods depending on whatever culture you set. Also, reading a inputs from the user into a numeric type will be parsed according to their culture rules. Dates will be displayed properly (12/9/08 vs. 9/12/08). You get all that basically for free.This obviously causes problems when talking to other systems that are expecting everything in the same culture. To solve this, you write your queries with the invariant culture:(5000.25).ToString(CultureInfo.InvariantCulture) This will explicitly set that output to something that Mysql can get along with.Note: if you have a proper data layer and you pass numeric types into it, you can probably avoid a lot of this mess. Are you persisting the entire list from the database in the viewstate or just the uncommitted additions?If it's just the additions, then this is a fine use of viewstate.If the list from the DB isn't very large or volatile, then I guess that'd be OK, too. I agree with you (and am also annoyed by it). I think it's just a slight misunderstanding that IsGood == true evaluates to bool, which is what IsGood was to begin with.I often see these near instances of SomeStringObject.ToString().That said, in languages that play looser with types, this might be justified. But not in C#. If this number will be ever be referenced by humans, I encourage you to follow these guidelines in your solution:What is the best format for a customer number, order number?If you can't synchorize with the database to see what the next number will be, and you can't use GUIDs or a comparably long random string, then you need to include some sort of local value in the ID. e.g., if all clients will be on a known network, you can end each number in each client's ip address D block. Or, if clients have to login and each user can login only once at a time, you can include their userid in the number somewhere. Constraints must go in the database at a minimum. If you have to replicate them in code (or infer them from the database) to provide a better user experience, so be it.The database must be consistent. I have wasted so much time tracking down issues that are the result of "invalid data". These are solved by adding the appropriate constraint and fixing whatever app created the invalid data. I would much rather have 10 tickets because someone can't save an invoice (easy to trace), than one ticket because somehow a report got a weird value which stemmed from bad invoice data. If you can open your page in Firefox, I'd check the error console (c-s-J). It has helped me find many, many typos.Also, your code seems to missing a lot of semicolons. Maybe some of them are optional but... How about adding them as a constraint?dt.Constraints.Add("PKC", Columns, true)If that still allows duplicates, does the .HasErrors property provide any indication?Edit from the comments:What ultimately worked for OP was this work-around: add the constraints before filling the table.  If this is a readonly textbox, you need to explicitly set your BackColor first, then your statement will work.txtLala.BackColor = System.Drawing.SystemColors.Info;txtLala.ForeColor = txtLala.BackColor;Ref: http://bytes.com/groups/net-c/233961-read-only-textboxThen again, if it's readonly, a label might be better. If you're trying to hide it, perhaps setting .Visible = false would be better still.Edit: This seems to be a common question on the web. With respect to winforms: This site suggests dropping the box into a frame and setting Enabled = false on the frame, not the textbox. Once you do that, you may be able to maintain control of the forecolor. This isn't too far off from what viewstate is designed for--I'd stick with that. Other less-desirable alternatives include sessions, database tables, and httpcontext. How are you generating the radio button list? If you're just using HTML:&lt;input type="radio" onclick="alert('hello');"/&gt;If you're generating these via something like ASP.NET, you can add that as an attribute to each element in the list. You can run this after you populate your list, or inline it if you build up your list one-by-one:foreach(ListItem RadioButton in RadioButtons){ RadioButton.Attributes.Add("onclick", "alert('hello');");}More info: http://www.w3schools.com/jsref/event_onclick.asp Cast the datetime to a date, then GROUP BY using this syntax:SELECT SUM(foo), DATE(mydate) FROM a_table GROUP BY DATE(a_table.mydate);Or you can GROUP BY the alias as @orlandu63 suggested:SELECT SUM(foo), DATE(mydate) DateOnly FROM a_table GROUP BY DateOnly;Though I don't think it'll make any difference to performance, it is a little clearer. Is the destination address on the same host as your smtp server? If not, this would explain a relaying error.The SMTP server you use needs to be either the final destination of the mail message or the first hop in the mail exchange. For example, if you're sending mail to a yahoo address from a gmail address, the first mail server to see the message must be your gmail server, or the yahoo server. Servers in between will reject the message because they have relaying disabled (to cut down on spam, etc.).If they are the same host, are you able to send mail to it directly any other way?Try this test via telnet to see if your smtp server is behaving properly: http://www.messagingtalk.org/content/470.html You are setting the property name inside your property--not the field name. This would work better:private string m_firstName;public String firstName;{ get { return m_firstName; } set { m_firstName = value; }} Yes, you could do this with some really ugly hits into the system tables. You'd probably need to fall into the world of dynamic sql. I really, really do not recommend this approach.If that didn't deter you, then this might get you started (ref):select table_name, column_name, ordinal_position, data_typefrom information_schema.columnsorder by 1,3 Things to check:Reboot (oldie but goodie, and doesn't always go without saying)OS version (you did this)Web browser (you did this)Web browser settings (you covered this by trying multiple browsers)Network connectivity and Hosts file rulesUser permissions (you covered this)Application permissions (you covered this)OS locale settings (control panel: Regional and Language Options)Try and capture more information.http://www.communitymx.com/content/article.cfm?cid=A66B8http://forums.asp.net/p/1163435/2673051.aspxhttp://projects.nikhilk.net/WebDevHelper/Default.aspxhttp://www.fiddlertool.com/fiddler/IIS logs; Server Event LogIn this situation, I'd probably download a virgin browser to try to rule out browser settings. I'd throw Google Chrome onto a known good machine and a known bad machine to see what happens. If it works in both cases, then I'd look further at browser settings. I know that this isn't likely the case since it fails in both FF and IE, but IE this simple test could help provide a little more info nonetheless.It's a weird one. Since it affects both IE and FF, I'd also look at the connectivity angle, the hosts file, and permissions. If you are limiting yourself to displaying a single email, name, website, etc. for each person in this query, I'd use subqueries:SELECT cp.ID profile ,cp.Name ,(SELECT value FROM contact_attributes WHERE type = 'email' and profile = cp.id) email ,(SELECT value FROM contact_attributes WHERE type = 'website' and profile = cp.id) website ,(SELECT value FROM contact_attributes WHERE type = 'phone' and profile = cp.id) phoneFROM contact_profiles cpIf you're using SQL Server, you could also look at PIVOT.If you want to show multiple emails, phones, etc., then consider that each profile must have the same number of them or you'll have blanks.I'd also factor out the type column. Create a table called contact_attribute_types which would hold "email", "website", etc. Then you'd store the contact_attribute_types.id integer value in the contact_attributes table. I think it'd be more confusing if your comparison algorithm were "clever". I'd go with the numerous comparison methods you suggested.The only exception for me would be equality. For unit testing, it's been useful to me to override the .Equals (in .net) in order to determine if several fields are equal between two objects (and not that the references are equal). I'd configure my load balancer with stickey sessions to avoid this problem.With sticky sessions, you'll be directed to the same server over and over again during the session. Instead of using -c, just pipe it to wc -l.grep string * | wc -lThis will list each occurrence on a single line and then count the number of lines.This will miss instances where the string occurs 2+ times on one line, though. Use sticky sessions as mentioned in this similar post. This will keep users on the same machine for a period of time.I don't think it wise to allow a single user to hit three different versions of the framework in a single session. When trying to link some well established tools to my company's active directory, I hit a roadblock. I was told that: "Sorry, I cannot trust our domain admin password to [F/OSS] software...".This question deals specifically with how to convince IT that F/OSS software isn't (automatically) less trustworthy than any other software just because it's free/oss. I'm doing fine with adopting OSS software (I'm a linux ninja at heart) so to put it another way: How can I promote the acceptance of OSS at my company?The technical issue of tying into AD without an admin account is for another post.EDIT:I got some clarification on these issues. This really has little to do with the active directory and all to do with trust of F/OSS in general. So I think my original bolded questions are still valid, just ignore the part about the "admin password". You should have a column in your table for CivilStatus (int) which is foreign key reference to the CivilStatuses table which contains all possible civil statuses.Even though you don't expect it to change, I'd still query it from the database. This will make other things easier in the future like localization/globalization. You could then have enumerations in your code, as others have said, to make the mapping easier. However, any time you display text to the user, it's got to come from the database or a resource file--not from the code directly. If you are interested in parsing the format, then I'd use a regular expression. Here's a good one (source):bool IsDottedDecimalIP(string possibleIP){ Regex R = New Regex(@"\b(?:\d{1,3}\.){3}\d{1,3}\b"); return R.IsMatch(possibleIP) &amp;&amp; Net.IPAddress.TryParse(possibleIP, null);}That regex doesn't catch invalid IPs but does enforce your pattern. The TryParse checks their validity. If these are giving you pause, I'd suggest writing out the tables on paper to get a better feel for what it means to join things together. Suppose for example that you have a table for Books and a table for Prices. The Prices table may have multiple entries for each book (since the price can change). If you want to get a list of the current books and prices, you have to join the two tables together.I'd work through this on paper by drawing arrows between each book and its corresponding "current" price. Then I'd write that into logic which would become part of the join condition or subquery.Once you get the hang of it, the complex queries get easier to parse. // Function for basic field validation (present and neither empty nor only white spacefunction IsNullOrEmptyString($str){ return (!isset($str) || trim($str) === '');} To add to @EndangeredMassa:You can also do something similar if you are already doing unions:SELECT 0 QueryType, Desc, GrandTotalFROM YourTableUNION ALLSELECT 1 QueryType, Desc, LineItemsFROM YourTableORDER BY QueryType, DescNote: unions may not be ideal in this example...it's just an example! My app sends lots and lots of data to SAP. To di this, it builds up an SAP table object and sends it over. I get this error somewhat regularly, but not reliably:System exception thrown while marshaling .NET type 20081219 to RFCTYPE_BCD at SAP.Connector.Rfc.RfcMarshal.NetFieldToRfcField(Object src, RFCTYPE type, Encoding encoding, Byte[] dest, Int32 offset, Int32 len, Int32 charSize, Int32 decimals) at SAP.Connector.Rfc.RfcStructureUtil.ToRfcStructure(Object obj, Byte[] dest, Type t, Encoding encoding, Boolean isUnicode, PropertyInfo[] propinfos, RfcStructInfo structInfo) at SAP.Connector.Rfc.RfcStructureUtil.GetITabFromList(SAPConnection conn, Object list, Type t, RfcStructInfo structInfo, Int32 itab) at SAP.Connector.Rfc.RfcClient.PrepareClientParameters(Type classType, MethodInfo m, Boolean isTQRfc, Object[] MethodParamsIn, RFC_PARAMETER[]&amp; paramsIn, RFC_PARAMETER[]&amp; paramsOut, RFC_TABLE[]&amp; tables, ParameterMap[]&amp; paramMaps) at SAP.Connector.Rfc.RfcClient.RfcInvoke(SAPClient proxy, String method, Object[] methodParamsIn) at SAP.Connector.SAPClient.SAPInvoke(String method, Object[] methodParamsIn)What's weird is that this doesn't happen every time. Also, the .NET type it complains about, "20081219" is the data I'm passing (a date)--not a type. I think the type of that field is RFCTYPE.RFCTYPE_TIME.Any suggestions on how to troubleshoot this intermittent error? Is there some kind of state I should be clearing between calls to the SAP RFCs?Update:As requested, here's the code that calls SAP:Using sapConnection As New MySapProxy(ConnectionString) sapConnection.Connection.Open() sapConnection.TheSapRfcICall(SapOpCode, Nothing, Nothing, sapTable, ResultTable)End UsingI'm thinking maybe multiple threads are using the same connection some how. Using SAP.Connector.GetNewConnection instead didn't change anything. Update:It seems this problem occurs even when I run a single thread! What's the deal??Is there a way to disable the connection pool to see if that fixes it?Update:@Igal Serban's answer seems to be working for me. I'll check the logs tomorrow morning and (hopefully) award the bounty! Thanks so much.Update:As requested, my version of librfc32.dll is 6403.3.78.4732. I'd turn it into a while loop to make the condition more clear:dim i as integer = 0While i &lt; originalList.Count dim isMatch as boolean = false for each t as string in targetList if String.compare(originalList(i), t, true) = 0 then isMatch = true Exit for end if next if isMatch then originalList.RemoveAt(i) else i += 1 end ifnext YAML. From the site: YAML is a human friendly data serialization standard for all programming languages.Example (again, from the site): Below is an example of an invoice expressed via YAML(tm). Structure is shown through indentation (one or more spaces). Sequence items are denoted by a dash, and key value pairs within a map are separated by a colon.invoice: 34843date : 2001-01-23bill-to: &amp;id001 given : Chris family : Dumars address: lines: | 458 Walkman Dr. Suite #292 city : Royal Oak state : MI postal : 48046ship-to: *id001product: - sku : BL394D quantity : 4 description : Basketball price : 450.00 - sku : BL4438H quantity : 1 description : Super Hoop price : 2392.00tax : 251.42total: 4443.52comments: &gt; Late afternoon is best. Backup contact is Nancy Billsmer @ 338-4338. I don't recommend deleting old code on a new-to-you project. That's really asking for trouble. In the best case, it might tidy things up for you, but isn't likely to help the compiler or your customer much. In all but the best case, something will break.That said, I realize it doesn't really answer your question. For that, I point you to this related question:Is there a custom FxCop rule that will detect unused PUBLIC methods? SO was build with ASP.NET MVC. Jeff hired good developers, had a good vision, and ran his screens through a real designer. What are you hoping to accomplish by compressing 150 bits? Unless you aggregate several of this 19b messages, I'm not sure what you hope to gain. Is it a UI issue--wherein you want your users to send/receive "codes"?How about base 64 encoding? This will take binary data and turn it into coded characters for easy transmission or entry. You need to do a left-join:SELECT g.Game_Number, g.PutColumnsHere, count(t.Game_Number) FROM games gLEFT JOIN tickets t ON g.Game_Number = t.Game_NumberGROUP BY g.Game_Number, g.PutColumnsHereAlternatively, I think this is a little clearer with a correlated subquery:SELECT g.Game_Number, G.PutColumnsHere, (SELECT COUNT(*) FROM Tickets T WHERE t.Game_Number = g.Game_Number) Tickets_CountFROM Games gJust make sure you check the query plan to confirm that the optimizer interprets this well. I definitely prefer the first version. The continue statement is very nice when not overused.I'd treat this along the same lines as multiple return statements. They are good for guard clauses and have good usefulness when clarity is improved, but shouldn't be overused.Also, two spaces on a line should insert a line break for you in code blocks. They are constant. Yes, compile time.Reference:http://msdn.microsoft.com/en-us/library/sbbt4032.aspxFrom the intro: The enum keyword is used to declare an enumeration, a distinct type that consists of a set of named constants called the enumerator list.Under "Robust Programming": Just as with any constant, all references to the individual values of an enum are converted to numeric literals at compile time. This can create potential versioning issues as described in Constants (C# Programming Guide). I try to keep things simple. In this case, I'd make the first-name column not-nullable and allow blanks. Otherwise, you'll have three cases to deal with anywhere you refer to this field:Blank first nameNull first nameNon-blank first nameIf you go with 'blank is null' or 'null is blank' then you're down to two cases. Two cases are better than three.To further answer your question: the user entering data probably doesn't (and shouldn't) know anything about what a "null" is and how it compares to an "empty". This issue should be resolved cleanly and consistently in the system--not the UI. [Edit: added "select" before references to last_insert_id()]What about running "select last_insert_id();" after your insert?MySqlCommand comm = connect.CreateCommand();comm.CommandText = insertInvoice;comm.CommandText += "\'" + invoiceDate.ToString("yyyy:MM:dd hh:mm:ss") + "\', " + bookFee + ", " + adminFee + ", " + totalFee + ", " + customerID + ");"; + "select last_insert_id();"int id = Convert.ToInt32(comm.ExecuteScalar());Edit: As duffymo mentioned, you really would be well served using parameterized queries like this.Edit: Until you switch over to a parameterized version, you might find peace with string.Format:comm.CommandText = string.Format("{0} '{1}', {2}, {3}, {4}, {5}); select last_insert_id();", insertInvoice, invoiceDate.ToString(...), bookFee, adminFee, totalFee, customerID); amt.value = parseFloat(hiddenamt) + parseFloat(fee); Are you looking for something like Scribd's iPaper viewer?You can embed it on your site or host with them. This is a gotcha in VB.NET. The Visual Basic result won't reinitialize the variable in this example:For i as Integer = 1 to 100 Dim j as Integer Console.WriteLine(j) j = iNext' Output: 0 1 2 3 4...This will print 0 the first time (Visual Basic variables have default values when declared!) but i each time after that.If you add a = 0, though, you get what you might expect:For i as Integer = 1 to 100 Dim j as Integer = 0 Console.WriteLine(j) j = iNext'Output: 0 0 0 0 0... Here's a nice list: Debugging Tools:  Attach to Remote Process SQL-CLR Debugging XSLT Debugger T-SQL Debugging   Data Tools:  Database Projects SQL Server Projects Server Explorer  Reporting:  Crystal Reports Application &amp; Crystal Reports for Visual Studio  Office development:  VSTO for Office 2003 and Office 2007 Sharepoint 2007 State Machine workflow template  Smart Device Development:  Device Emulator Project Templates Debugging Tools Moocha and Filip Ekberg provided a really good reference to the feature matrix.From the comments:ctacke: Smart device development is better supported under Pro (Search for "Smart Device Development" on the feature matrix) I'm sure I'll get flamed for saying this but--you could just ignore Opera. If you like how things look in the other browsers (IE,FF,Safari/Chrome), then I'd say you've got 99% of your bases covered.You may want to file a bug against Opera, of course. (though I guess it could be jquery--it may have a different code path for Opera). If you could make a simple HTML page to reproduce the problem, you'd know. Then, attach it to the bug report. I would guess that AI systems are generally considered more complex. Complexity is usually a bad thing, especially when it relates to "magic" which is how some people perceive AI systems.That's not to say that the alternative is necessarily simpler (or better).When we've done control systems coding, we've had to show trace tables for every single code path, and permutation of inputs. This was required to insure that we didn't put equipment into a dangerous state (for employees or infrastructure), and to "prove" that the programs did what they were supposed to do.That'd be awfully tricky to do if the program were fuzzy and non-deterministic, as @tvanfosson indicated. I think you should accept that answer. I put all the things you listed (wiki, docs, etc.) into the logbook initially. Once the notes are entered into OneNote, the Wiki, etc., I cross them off the logbook. I don't throw the notes away as there's some possibility that I might need to check back into them.I use the logbook as just a short term memory buffer. I get its contents into a searchable computer regularly--usually immediately. The bind address is the local IP address of the server, not the allowable client addresses. In your situation, you can provide the static address of your server (in place of localhost) or, if your IP might change, just comment it out.Again, to clarify: the bind-address is the address on which the server listens for client connections (you could have multiple NICs, or multiple IP addresses, etc.). It is also possible to change the port you want mysql to listen to.You will want to make sure you configure the root password if you haven't already:mysql&gt; SET PASSWORD FOR 'root'@'localhost' = PASSWORD('yourpassword');You would then use other means to restrict access to MySql to something like the local network (i.e. your firewall). Yes, cast it to an IDictionary and lock on .SyncRoot:Generic.Dictionary&lt;int, int&gt; dic = new Generic.Dictionary&lt;int, int&gt;();lock (((IDictionary)dic).SyncRoot){ // code}Thanks to this source for the info.Of course a thread-safe dictionary would be nice, too, as others have suggested. There's nothing wrong with joining 10 tables if that's ultimately what you need to do. Generally SQL is good at this kind of thing. However, if there isn't that tight of a coupling between your 5-6 queries, then run them separately.If you choose to break up the query, hitting the DB 5-6 times is fine--absolutely nothing wrong with that. Your access method (e.g. ADO.NET) probably gives you connection pooling for free anyway so the overhead of multiple queries is very small. There is nothing wrong with it -- it's good enough to generate simple passwords. A simple example (source):Random RandomClass = new Random();int RandomNumber = RandomClass.Next(); // Random number between 1 and 2147483647double RandomNumber = RandomClass.Next(1,10); // Random number between 1 and 10double RandomDouble = RandomClass.NextDouble(); // Random double between 0.0 and 1.0The article How To: Generate a Random Password (C#/VB.NET) has a very comprehensive example of generating good, easy-to-read passwords with specified complexity. It may be overkill for you, but it might provide a nice source to copy ideas from.If you need something more for cryptography, there's another namespace for that:System.Security.CryptographySpecifically, you can use this:System.Security.Cryptography.RNGCryptoServiceProvider.GetBytes(yourByte)An example is Using Crypto for your Random Numbers in VB.NET, and another one is Crypto Random Numbers.If you're thinking about rolling your own, the site Developer Guidance Share has some information to talk you out of it. Suppose you have a table with an auto-increment/identity column. You normally cannot specify values for this column when you do inserts since it is automatically populated.However, if you call SET IDENTITY_INSERT YourTable ON first, you can insert specific values into the identity column.I use this most often when merging tables manually--I've never used it in a regularly executed block of code.Also note that you can only specify this on a single table at a time. It might put you at ease to know that you don't actually publish your .cs/.vb files with the website when you publish as a dll. I think this is the easiest road block to put in place.I realize that you can still get code out of the DLLs but the source files themselves don't need to be there.Convert your web project into a Web Application and build it. The output will be a dll. Push this along with all the media files (aspx, gif, png, etc.) out and your source should be hidden from less-than-diligent people. No.All the results of a single row from a select are atomic. That is, you can view them all as if they occur in parallel and cannot depend on each other.If you're referring to computed columns, then you need to update the formula's input for the result to change during a select. Think of computed columns as macros or mini-views which inject a little calculation whenever you call them.For example, these columns will be identical, always:-- assume that 'Calc' is a computed column equal to Salaray*.25SELECT Calc, Salary*.25 Calc2 FROM YourTableAlso keep in mind that the persisted option doesn't change any of this. It keeps the value around which is nice for indexing, but the atomicity doesn't change. As others are saying: SELECT * is a bad idea.Some reasons:Get only what you need (anything more is a waste)Indexing (index what you need and you can get it more quickly. If you ask for a bunch of non-indexed columns, too, your query plans will suffer. You can throw this into a scalar function, which makes handling nulls a little easier. Obviously it isn't going to be any faster than the inline case statement.ALTER FUNCTION [fnGetMaxDateTime] ( @dtDate1 DATETIME, @dtDate2 DATETIME) RETURNS DATETIME ASBEGIN DECLARE @dtReturn DATETIME; -- If either are NULL, then return NULL as cannot be determined. IF (@dtDate1 IS NULL) OR (@dtDate2 IS NULL) SET @dtReturn = NULL; IF (@dtDate1 &gt; @dtDate2) SET @dtReturn = @dtDate1; ELSE SET @dtReturn = @dtDate2; RETURN @dtReturn;END I generally have a Files table that stores files more generically. Then in your other tables, you could have a column for each image (file) which is just a reference into the files table. Your files table would have all the normal stuff like ID, Filename, Size, type, etc. Then yes, you'd just join into it to get what you need for whatever query you're running.In case there is any doubt--I'd strongly discourage you from storing files directly in the database. I don't think that's what your after but if anyone else gets that idea--just don't do it! What MS has done here is created their ASP controls with a .net feel to them. However, since they're supposed to work with browsers, they render as standard HTML controls. So in the code-behind cs/vb, you see .Checked (bool), while in the client/javascript you see .value.If what you want is a unique identifier, then you need to be looking at ID or ClientID. Alternatively, you could add an attribute to the checkboxt (.Attributes.Add()) and use that. If you decide to roll your own, here's a nice guide.I'm assuming you're going this route because Enterprise Edition is so costly?If you don't need a "live-backup", but really just want a frequently updated backup, I think this approach makes a lot of sense.One more thing:Make sure you regularly verify that your backup strategy is working.  I'd guess it's from a Smarty template for PHP. Even if the filename is valid, you may still want to touch it to be sure the user has permission to write.If you won't be thrashing the disk with hundreds of files in a short period of time, I think creating an empty file is a reasonable approach.If you really want something lighter, like just checking for invalid chars, then compare your filename against Path.GetInvalidFileNameChars(). The first option can be more robust because the database will be maintaining the field. This comes with the possible overhead of using triggers.If you could have other apps writing to this table in the future, via their own interfaces, I'd go with a trigger so you're not repeating that logic anywhere else.If your app is pretty much it, or any other apps would access the database through the same datalayer, then I'd avoid that nightmare that triggers can induce and put the logic directly in your datalayer (SQL, ORM, stored procs, etc.). Of course you'd have to make sure your time-source (your app, your users' pcs, your SQL server) is accurate in either case.Regarding why I don't like triggers:Perhaps I was rash by calling them a nightmare. Like everything else, they are appropriate in moderation. If you use them for very simple things like this, I could get on board. It's when the trigger code gets complex (and expensive) that triggers start to cause lots of problems. They are a hidden tax on every insert/update/delete query you execute (depending on the type of trigger). If that tax is acceptable then they can be the right tool for the job.  You have to put it into the page somehow. Using hidden form fields is one approach. Using webmethods like your link is a more sophisticated approach which gives you some ajax-powers.If you don't actually need this value to update from the server except on post-back, you can just use the hidden input control HtmlInputHidden. I think this is why a lot of people use PayPal and Google Checkout. They make some nice integration buttons you can use. I've personally used Google Checkout a bit and their API is extremely easy to use. You can tailor the whole thing behind the scenes and then just kick the user over to Google to actually pay you for whatever "product" you generated on your site.Additionally, you can send invoices to users directly from Google which will prompt them to go to Google CO to pay you.I found their fees reasonable. You can go with encapsulation instead of inheritance.That is, create your class (which won't inherit anything) and in it, have an instance of the object you want to extend.Then you can expose only what you want.The obvious disadvantage of this is that you must explicitly pass-through methods for everything you want exposed. And it won't be a subclass... I'm a little confused by your question. This brings up the Recording window for me (ref):sndvol32 -recordAre you trying to hide all mixers but one? Having not been involved in SO development, I only speak generally:I've found that tables are often easier and more consistent across browsers than CSS-based layouts.Also, emitting random CSS here and there often happens when trying to get things done. It can be refactored later, I suppose.With respect to why they chose to set a table's width in HTML instead of CSS, I couldn't say. I know that SO used a real, honest to goodness designer when they started. I don't know, though, if that designer gave them an image of what the site should look like or actual markup. Please don't flame me for saying so. We're not all CSS ninjas. The mantra is:You should only catch exceptions ifyou can properly handle themThus:You should not catch generalexceptions. In your case, yes, you should just catch those exceptions and do something helpful (probably not just eat them--you could throw after you log them).Your coder is using throw (not throw ex) which is good.This is how you can catch multiple, specific exceptions:try{ // Call to a WebService}catch (SoapException ex){ // Log Error and eat it}catch (HttpException ex){ // Log Error and eat it}catch (WebException ex){ // Log Error and eat it}This is pretty much equivalent to what your code does. Your dev probably did it that way to avoid duplicating the "log error and eat it" blocks.  From Wikipedia:  LF: Multics, Unix and Unix-like systems (GNU/Linux, AIX, Xenix, Mac OS X, FreeBSD, etc.), BeOS, Amiga, RISC OS, and others CR+LF: DEC RT-11 and most other early non-Unix, non-IBM OSes, CP/M, MP/M, DOS, OS/2, Microsoft Windows, Symbian OS CR: Commodore machines, Apple II family, Mac OS up to version 9 and OS-9 I translate this into these line endings in general:Windows: '\r\n'Mac (OS 9-): '\r'Mac (OS 10+): '\n'Unix/Linux: '\n' You need to make your scanner/parser handle the unix version, too. Because it's not a priority to them. Normal users don't care about URLs. This site was built as an MVC app which has at its core, simple URLs.My apps don't always have elegant URLs because my customers have never said, "I wish the URLs were shorter".I agree with you that there is some value in a clean URL, but unless you start with it as a goal, it difficult to work in later and more difficult still to justify. Create a baseline by running fxCop once and excluding everything it finds.Save this as a .fxcop file and use that to run future checks.Then, as you make changes to your code you'll create new, manageable violations. FxCop will reflag things if you change a method's signature, for example.If you have time, you can tackle a category of violations one at a time after that by un-excluding them. This is a Feature (though not what I expected, either).This thread suggests making your key a Primary key to get the behavior you expected: This is a feature - a NULL value is an undefined value, therefore two NULL values are not the same. Can be a little confusing but makes sense when you think about it. A UNIQUE index does ensure that non-NULL values are unique; you could specify that your column not accept NULL values. You can use Zip for this. You would use a compression level of something like "none" or "store", which just combines the files without compression. This site enumerates some of them:  Maximum - The slowest of the compression options, but the most useful for creating small archives.  Normal - The default value. Low - Faster than the default, but less effective. Minimum - Extremely fast compression, but not as efficient as other methods. None - Creates a ZIP file but does not compress it. File size may be slightly larger if archive is encrypted or made self-extracting. Here are some C# examples:CodeProjectEggheadCafeFor the unix unaware, this is exactly what tar does. When you see .tar.gz files, it's just a bunch of files combined into a tar file, and then run through gzip. The easy way:OtherFormClass NewForm = new OtherFormClass();NewForm.Show();If you can handle the memory, you can create the form in the background and popup when desired. This should give the user a nice, quick experience.There may be other optimizations to alleviate memory pressure. I don't agree with this: Duplicate untested code is better than common untested code (you break only one project).If you are all equally likely to create bugs by implementing the same thing, then you'll all have to fix potentially different bugs in each instance of the "duplicate" library.It also seems that it'd be much faster/cheaper to write the library once and, instead of having multiple other teams write the same thing, have some resources allocated to testing.Now to solve your actual problem: I'd mimic what we do with real third-party libraries. We use a particular version until we're ready, or compelled to upgrade. I don't upgrade everything just because I can--there has to be a reason.Once I see that reason (bug fix, new feature, etc.), then I upgrade with the risk that the new library may have new bugs or breaking changes.So, you're library project would continue development as necessary, without impacting individual teams until they were ready to "upgrade". You could publish releases or peg/branches/tag svn to help with all this.If all teams have access to the bug tracker, they could easily see what known issues exist in the upgrade-candidate before they upgrade, too. Or, you could maintain that list yourself.@Brian Clapper provides some excellent guidelines for how to run your library as a project in his answer. Your API shouldn't allow callers to "break" anything by mucking up the state of the internals (e.g. reordering collections, etc.). To solve that problem, your exposed interfaces should be read only when necessary.With respect to complexity, I lean far in the direction of simple, basic methods. I try very hard not to over-engineer anything with what I think will be needed down the road.Write to today's requirements (maybe tomorrow's), but not beyond. You can always extend in the future. It's much harder to just drop things that you can't maintain anymore. Making the computer obey me. Awesome.I also love (love to hate) that the computer will obey even when I'm wrong.But seriously folks.I was hooked when:I saw that you can do rich and dynamic things with code. That the machine is generally consistent. That programming is like math in the sense that for all the "it depends" out there, we still have more than our fair share of questions with actual, provable answers.That I could automate menial tasks with logic and loops. I think that's a reasonable approach. It follows the normal filter pattern nicely and should give good performance. The values displayed on the execution plan are estimates based on statistics. Normal queries like:SELECT COUNT(*) FROM Tableare 100% accurate for your transaction*.Here's a related question.*Edge cases may vary depending on transaction isolation level.More information on stats:Updating statisticsHow often and how (maintenance plans++) I did a quick and dirty implementation of a bunch of members by concatenating them with pipes and then getting the hascode of that:(Member1.ToString() + "|" + Member2.ToString()).GetHasCode();In my case, I know that I won't ever have pipes in the members so I knew the results would be pretty good.Actually, in my case I implemented ToString for debugging purposes so I just used that:this.ToString().GetHashCode();Xors is another approach I've often seen. This is a little wonky but it might work--it counts the number of times the first character is repeated:strlen($line) - strlen(ltrim($line, $line[0]));If you just want to remove all the stars from beginning, then this is a little easierstrlen($line) - strlen(ltrim($line, '*')); You need to mount a remote share on your windows machine. This is what Samba/smb is for.What you'll be doing is turning your Linux box into an SMB server, which lets it share files in a way that plays nice with Windows.If you're not on the same network, you'll need to tunnel this through your SSH connection which may not be worth the effort. You're looking at the wrong docs. Check this out: http://msdn.microsoft.com/en-us/library/system.web.httpserverutility_methods.aspx http://msdn.microsoft.com/en-us/library/system.web.httpserverutility.htmlencode.aspx http://msdn.microsoft.com/en-us/library/system.web.httpserverutility.htmldecode.aspx Note: if you are limiting this to "3" just so you don't overwhelm the machine running your app, I'd make sure this is a problem first. The threadpool is supposed to manage this for you. On the other hand, if you don't want to overwhelm some other resource, then read on!You can't manage the size of the threadpool (or really much of anything about it).In this case, I'd use a semaphore to manage access to your resource. In your case, your resource is running the web scrape, or calculating some report, etc.To do this, in your static class, create a semaphore object:System.Threading.Semaphore S = new System.Threading.Semaphore(3, 3);Then, in each thread, you do this:System.Threading.Semaphore S = new System.Threading.Semaphore(3, 3);try{ // wait your turn (decrement) S.WaitOne(); // do your thing}finally { // release so others can go (increment) S.Release();}Each thread will block on the S.WaitOne() until it is given the signal to proceed. Once S has been decremented 3 times, all threads will block until one of them increments the counter.This solution isn't perfect. If you want something a little cleaner, and more efficient, I'd recommend going with a BlockingQueue approach wherein you enqueue the work you want performed into a global Blocking Queue object.Meanwhile, you have three threads (which you created--not in the threadpool), popping work out of the queue to perform. This isn't that tricky to setup and is very fast and simple.Examples:Best threading queue example / best practiceBest method to get objects from a BlockingQueue in a concurrent program? Absolutely. This is one way that cross-site scripting (XSS) attacks work:I inject javascript into a pageI wait for someone to look at the pageThe javascript I injected sends me your cookiesI login as you and do bad thingsThis particular issue bit SO during the private beta. Maintain the state of what's happening in a form variable and have your async method check that state before it does anything. Make sure you synchronize access to it, though! Mutexes and semaphores are good for this kind of thing. If you can download different files simultaneously, you'll need to keep track of what's being downloaded in a list for reference.If only one file can be downloaded at a time, and you don't want to queue things up, you could just unhook the event while something is being downloaded, too, and rehook it when the download is complete. If you have a consistent UOM for things, then your DBA's policy is OK.For example, if timespans are ALWAYS in minutes, etc.If the UOM could change, then you should store it in another column, alongside the qty.That said, I tend to side with you on this. Clarity trumps most things, including this. I'd rather see DurationMinutes than Duration and have to guess what the UOM is. Hashing alone doesn't have anything to do with memory.What it is often used for is a hashtable. Hashtables work by computing the hash of what you are keying off of, which is then used as an index into a data structure.Hashing allows you to reduce the key (string, etc.) into a more compact value like an integer or set of bits. That might be the memory savings you're referring to--reducing a large key to a simple integer.Note, though, that hashes are not unique! A good hashing algorithm minimizes collisions but they are not intended to reduce to a unique value--doing so isn't possible (e.g., if your hash outputs a 32bit integer, your hash would have only 2^32 unique values). You can, but if you're using SQL Server 2000, you'll have to pass in the value of "now"--UDFs can't generate any non-deterministic values themselves in SQL Server 2000.This untested stab at it might be close:CREATE FUNCTION dbo.GetStoryScore ( @Now DATETIME, @Posted DATETIME, @Votes INT, @Comments INT) RETURNS FLOAT ASBEGIN RETURN @Votes + @Comments - DATEDIFF(HOUR, @Posted, @Now)/24.0ENDExample usage:SELECT S.ID, dbo.GetStoryScore(GETDATE(), S.Posted, S.Votes, S.Comments) AS ScoreFROM Stories AS SWHERE ...Notes: The datediff is performed in hours (not days) because the integer result gives you a little more precision when you use finer units.I passed in all the values because I've found lookups within functions to be a really, really bad thing for performance.When referenced in SQL, don't forget the dbo. in front of the function name.If you're using SQL Server 2005, you can remove the @Now variable and use GETDATE() inline, instead. If you catch an exception and then want to rethrow it, this pattern is pretty simple:try: do_something_dangerous()except: do_something_to_apologize() raiseOf course if you want to raise the exception in the first place, that's easy, too:def do_something_dangerous(self): raise Exception("Boo!")If that's not what you wanted, please provide more information! Have you looked at Text Template Transformation Toolkit (T4)?This post has a lot of information on it. This takes longer because the query can't just pick the first 4 items it finds. It has to order the entire list and then choose the top 4 from that.Fix this by adding an index which includes table1{column4, ...}. If you only need a few columns from table 1 (and they're narrow), I'd add them all to the index (covering index). If indexed properly, the SQL engine can pull just the first four columns that you want--not the entire set.If you do have indexing and it's not helping, run the query with EXPLAIN to see what the execution plan looks like (good tip, @IronGoofy):EXPLAIN SELECT table1.*,table2.* FROM table1 LEFT OUTER JOIN table2 ON table1.column2=table2.column3 WHERE table1.column1='value' ORDER BY table1.column4 DESC LIMIT 4 Using print CSS files is a really slick approach to reformatting pages for printing.A lot of people fall back to PDF because it can be more powerful and easier.For most things, though, I think CSS markup is simpler and easier.Look at the source for pages in StackOverflow and you'll see references to media="print" (print.css)--a set of styles applied only when a browser prints the page.&lt;link href="/Content/print.css" rel="stylesheet" media="print" type="text/css" /&gt;You can use these to hide navbars, ads (or show different ads). Do some basic pagination, etc.If you need more control over things like margins, you have to go outside the browser (PDF, Word, XPS, etc.). I wouldn't say Google is anti-flash. Non text-based systems are simply difficult to index. Google indexes Office docs, PDFs, images, text in images, some text in flash files...they are improving but these are hard problems.What you are asking for is Google to run the flash file and extract text from it while it's running. That can get very tricky. If the string really doesn't contain encoded values before you send, take a look at this:$subject= mb_encode_mimeheader($subject,"UTF-8", "B", "\n");// or$subject= mb_encode_mimeheader($subject,"UTF-7", "Q", "\n");Take a look at these posts related to SugarCRM:http://www.sugarcrm.com/forums/showthread.php?t=11940http://www.sugarcrm.com/forums/showthread.php?t=11106&amp;highlight=iso-8859-1 It's not random, but this is a nice and easy way to do it, provided you have a realtively uniform distribution of IDs:UPDATE Buildings SET Use = 'warehouse' WHERE ID % 6 = 0UPDATE Buildings SET Use = 'office' WHERE ID % 6 = 1UPDATE Buildings SET Use = 'market' WHERE ID % 6 = 2UPDATE Buildings SET Use = 'retail' WHERE ID % 6 = 3UPDATE Buildings SET Use = 'workshop' WHERE ID % 6 = 4UPDATE Buildings SET Use = NULL WHERE ID % 6 = 5This is almost certainly going to be easier and faster than a "random" approach. Then again, it might not be random enough. Can I assume that there's a good reason you're not using relative URLs? This site explains how to do it with another app. Just change the path and you should be all set.Create this key/value:[HKEY_CLASSES_ROOT\*\shell\Edit with AppName\command]@=\C:\\Program Files\\Notepad2\\Notepad2.exe\ \%1\"Here's another reference, which is a little easier to follow. XML or JSON are excellent methods to store things like this.As Spence said--this is a hard problem--I don't recommend rolling your own.Scroll down to the bottom of that JSON link for implementations in most languages. Look at the Environment class. There're lots of nice things in there, including the MachineName:string CurrentMachineName = Environment.MachineName;According to the docs, this could generate an InvalidOperationException so you'll need to be aware of that possibility. The risk probably doesn't warrant wrapping it in a try/catch, though. I'm making some assumptions here:If you're table stores a row for each of your messages (added/updated), then this query would return one row per article, with the columns you need (articleNum, Created, Updated):SELECT A.articleNum, MCreated.Timestamp AS Created, MUpdated.Timestamp UpdatedFROM Articles AJOIN Messages MCreated ON MCreated.articleNum = A.articleNum AND MCreated.Message = 'added'LEFT JOIN Messages MUpdated ON MUpdated.articleNum = A.articleNum AND MUpdated.Message = 'updated' I'm looking into horizontal partitioning for a table that has time-series data in it. I've discovered that partitioning is much easier in 2005 than it was in 2000 but I can't seem to find this answer:Can I add/drop columns of a partitioned table?Are special steps required because it's partitioned? I couldn't find a definitive answer (I found the doc @E.J. Brennan referenced to be a little dense and unclear). So I added to this example and have tested that, yes, you can add/drop columns:USE adventureworksgocreate partition function YearPF(datetime) as range right for values ('20050101');-- Now we need to add filegroups that will contains partitioned valuesalter database adventureworks add filegroup YearFG1;alter database adventureworks add filegroup YearFG2;-- Now we need to add file to filegroupsalter database adventureworks add file (name = 'YearF1', filename = 'C:\Program Files\Microsoft SQL Server\MSSQL.1\MSSQL\Data\AdvWorksF1.ndf') to filegroup YearFG1;alter database adventureworks add file (name = 'YearF2', filename = 'C:\Program Files\Microsoft SQL Server\MSSQL.1\MSSQL\Data\AdvWorksF2.ndf') to filegroup YearFG2;-- Here we associate the partition function to -- the created filegroup via a Partitioning Schemecreate partition scheme YearPS as partition YearPF to (YearFG1, YearFG2)-- Now just create a table that uses the particion schemecreate table PartitionedOrders( Id int not null identity(1,1), DueDate DateTime not null,) on YearPS(DueDate)-- And now we just have to use the table!insert into PartitionedOrders values('20020101')insert into PartitionedOrders values('20030101')insert into PartitionedOrders values('20040101')insert into PartitionedOrders values('20050101')insert into PartitionedOrders values('20060101')-- Now we want to see where our values has falledselect *, $partition.YearPF(DueDate) from PartitionedOrders-- see if we can add a columnALTER TABLE PartitionedOrders ADD NewColumn INT NULL-- add some more records, populating the new columninsert into PartitionedOrders values('20010101', 1)insert into PartitionedOrders values('20070101', 2)-- see that they were inserted properlyselect *, $partition.YearPF(DueDate) from PartitionedOrdersALTER TABLE PartitionedOrders DROP COLUMN NewColumn-- see that the column droppedselect *, $partition.YearPF(DueDate) from PartitionedOrders/* clean updrop table PartitionedOrdersdrop partition scheme YearPS;drop partition function YearPF;alter database adventureworks remove file YearF1;alter database adventureworks remove file YearF2;alter database adventureworks remove filegroup YearFG1;alter database adventureworks remove filegroup YearFG2;*/ In your case, I'd strongly recommend avoiding a lot of branching. It's really a fairly advanced process and not necessary for small projects and small teams. There is no maximum. Any max you are encountering is application specific or site specific.I've downloaded DVD isos from Microsoft using HTTP and FTP without issue (~4gb).I've also uploaded huge files via both methods.Can you elaborate on what you're trying to do? Yes, transactions are enabled by default--I don't think this is something you can disable. Each time you run a query, it probably runs as an autocommit, implicit transaction, unless otherwise specified.MSDTC comes into play if you run distributed transactions. I'd avoid it if you can. That aspect can be disabled. If that's what you're using, then, you will need to make sure it's configured on the destination system.Just using the DBTransaction object for simple, successive queries or transactions within stored procedures won't need MSDTC. If you wrap your statements inside a transaction, they will all be performed atomically. You may need to increase the transaction isolation level depending on your needs, though.For example, if you don't want anyone else reading or writing to a particular table while you execute a bunch of statements, this statement at the top will make that happen:SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;I don't recommend escalating to this level unless absolutely necessary, though, because it basically breaks the concurrency benefits.Instead, consider using something lower or reworking your logic to remove the need of the critical section. Use the :hover pseudo class. For example:&lt;html&gt;&lt;head&gt; &lt;style&gt; IMG.HoverBorder {border:5px solid #eee;} IMG.HoverBorder:hover {border:5px solid #555;} &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;img class="HoverBorder" src="test.png" /&gt;&lt;/body&gt;&lt;/html&gt;The above code works well on all sane browsers I have access to. If you need IE 6 support, take a deep breath and check this out (thanks to @Brian Kim for reminding me about IE6):&lt;html&gt;&lt;head&gt; &lt;style&gt; a:hover{ background-color:white; } a:link img, a:visited img{ border:5px solid #eee; } a:hover img{ border:5px solid #555; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;a href="#"&gt;&lt;img class="HoverBorder" src="03 messed up status log edit IE6.png" /&gt;&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;There are several variants on this approach--I suggest you click through to that site for other options that might be more suitable to your situation. This is not possible--at least not in a way that will work with many clients. You'll need to just attach the file.If you have only one client to worry about, it might be possible--but not likely without manually changing settings on each client. This won't do what you are expecting:&lt;img src="image1.gif" alt="image2.gif" /&gt;The ALT attribute is text-only--it won't do anything special if you give it an image URL. If you want to initially display a low res image, then replace it with a high res image, you could do some javascript coding to swap out the images. Or, perhaps load the image into a div which has a background pattern filled with the low res image. Then, when the high res image loads, it'll load overtop the background.Unfortunately, there's no direct way to do this.Your second attempt will create a link to image2, but actually display image1.&lt;a href="image2.gif" &gt;&lt;img src="image1.gif"/&gt;&lt;/a&gt;If you want to popup a higher res version, @Sam's suggestion is a good idea.This CSS might work for you (it works for me in Firefox 3):&lt;html&gt;&lt;head&gt; &lt;style&gt; .lowres { background-image: url('low-res.png');} &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="lowres" style="height:500px; width:500px"&gt; &lt;img src="hi-res.png" /&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;In that example, you have to set the div height/width to that of the image. It will actually load both images simultaneously, but presuming the low-res one loads quick, you might see it first while the hi-res image downloads. I've got apache2.2 on windows. I'm trying to serve both subversion (/svn) and redmine (/redmine). I have svn running fine with this config:&lt;Location /svn&gt; DAV svn SVNParentPath C:/svn_repository ...&lt;/Location&gt;This is working great--my svn users can hit http://mybox/svn just fine.Now I want to add another directory for a rails app (RedMine):I followed the advice in this question to setup a mongrel server and have apache proxy clients through to it. It works fine if I make it the root--but I'm having trouble making it in a subdirectory:&lt;Location /redmine&gt; ProxyPass http://localhost:3000/ ProxyPassReverse http://localhost:3000/&lt;/Location&gt;Any suggestions? Here's what I had to change:I removed the trailing slash:&lt;Location /redmine&gt; ProxyPass http://localhost:3000 ProxyPassReverse http://localhost:3000/&lt;/Location&gt;And in my rails app:# added to end of file C:\redmine\config\environment.rbActionController::AbstractRequest.relative_url_root = "/redmine"Now it's working!I wasn't completely happy with this approach--I ran into some redirect issues. This is another attempt which seems to be working well so far. Fast CGI and Fast CGI without VirtualHostsTuning Fast CGIThis second approach seems better.UPDATE:As noted in the comments, for more recent apps running on Rails 2.3.2+, use this instead:config.action_controller.relative_url_root = '/redmine'I put it in the new additional_environment.rb file. Try this formula:=SUBSTITUTE(TEXT(A1/B1,"?/?"),"/",":")Result:A B C33 11 3:125 5 5:16 4 3:2Explanation:TEXT(A1/B1,"?/?") turns A/B into an improper fractionSUBSTITUTE(...) replaces the "/" in the fraction with a colonThis doesn't require any special toolkits or macros. The only downside might be that the result is considered text--not a number--so you can easily use it for further calculations.Note: as @Robin Day suggested, increase the number of question marks (?) as desired to reduce rounding (thanks Robin!). You can't do this as a single insert because inserts are atomic--that is, the ID isn't determined until the statement completes.Wrap both statements in a transaction and you will get your ID, and atomicity. This site has an example using LINQ:CultureInfo[] cultures = System.Globalization.CultureInfo.GetCultures (CultureTypes.SpecificCultures);var selectCulture = from p in cultures where p.Name == value select p;if (selectCulture.Count() == 1){ // your culture is good}It seems a bit heavy, though. I'd probably stick with what you have. I have Apache/SVN running on Windows Server 2003 with authentication via LDAP/Active Directory and a flat-file.It's working great except that any LDAP user can access everything. I'd like to be able to limit SVN repositories by user or group.Ideally, I'd get to something like this:&lt;Location /svn/repo1&gt; # Restricted to ldap-user1, file-user1, or members of ldap-group1, # all others denied&lt;/Location&gt;&lt;Location /svn/repo2&gt; # Restricted to ldap-user2, file-user2, or members of ldap-group2, # all others denied&lt;/Location&gt;The real trick might be that I have mixed authentication: LDAP and file:&lt;Location /svn&gt; DAV svn SVNParentPath C:/svn_repository AuthName "Subversion Repository" AuthType Basic AuthBasicProvider ldap file AuthUserFile "svn-users.txt" #file-based, custom users AuthzLDAPAuthoritative On AuthLDAPBindDN ldapuseraccount@directory.com AuthLDAPBindPassword ldappassword AuthLDAPURL ldap://directory.com:389/cn=Users,dc=directory,dc=com?sAMAccountName?sub?(objectCategory=person) Require valid-user&lt;/Location&gt;In my googling, I've seen some people accomplish this by pulling in the authz file like this:&lt;Location /svn&gt; ... AuthzSVNAccessFile "conf/svn-authz.txt"&lt;/LocationThen, I'd need to map the AD users. Any examples of that approach? This was actually a lot easier than I thought it would be. I added this to my location:&lt;Location /svn&gt; ... AuthzSVNAccessFile "conf/svn-authz.txt"&lt;/LocationIn that file, I just specified normal SVN permissions (the system doesn't seem to distinguish between file users and LDAP users at this point):[groups]@admin = haren###### Deny all but administrators to the tree###[/]* =@admin = rw###### Allow more specific people on a per-repository basis below###[repo1:/]ldap-user1 = rwfile-user1 = rw[repo2:/]ldap-user2 = rwfile-user2 = rwI'm still playing around with the LDAP group syntax to get that part working. Any suggestions there are appreciated. Try this, using Row_Number:-- insert into temp tableSELECT *, ROW_NUMBER() OVER (ORDER BY SortColumn) AS SortColumn INTO #TempTable FROM FirstTable WHERE &lt;complex where clause&gt;-- check the results and drop the tableSELECT * FROM #TempTable WHERE SortColumn BETWEEN 45 AND 179 ORDER BY SortColumnDROP TABLE #TempTableObviously you'll need to replace SortColumn with whatever makes sense in your caseEdit:If you're just trying to do paging, there are lots of examples of that:http://www.davidhayden.com/blog/dave/archive/2005/12/30/2652.aspxhttp://www.sqlteam.com/article/server-side-paging-using-sql-server-2005http://www.google.com/search?q=sql+server+2005+paging I'm using SVN through Apache with dav_svn_module like this:&lt;Location /svn&gt; DAV svn SVNParentPath C:/svn_repository AuthName "Subversion Repository" ...&lt;/Location&gt;This lets me access my repos:C:/svn_repository/repo1C:/svn_repository/repo2C:/svn_repository/repo3via these URLs:https://examples.com/svn/repo1https://examples.com/svn/repo2https://examples.com/svn/repo3Those URLs work great. When I go to just /svn (no repo name), I get a 403/forbidden response. What I'd like to see if a list of repos. Is that possible?  I'd guess it isn't a big deal. References for your viewing pleasure:http://www.nthelp.com/upnpscrewup.htmhttp://forums.snapstream.com/vb/showthread.php?p=129675http://www.google.com/search?hl=en&amp;q=239.255.255.250&amp;btnG=Google+SearchQuestions for you:How do you know it's your windows app? ZoneAlarm.Are you using multicast for anything? No.Are you running any multicast apps or apps that might use uPNP? No.Are you doing any networking with your app? If so, what classes are you using?Try this the next time you see the alert:Start&gt; Run&gt; cmd.exe:netstat /b /oThat might give you more information on where the alert is coming from. Actually, in this case it's quite simple: apply the vertical align to the image. Since it's all in one line, it's really the image you want aligned, not the text.  &lt;!-- moved "vertical-align:middle" style from span to img --&gt; &lt;div&gt; &lt;img style="vertical-align:middle" src="https://placehold.it/60x60"&gt; &lt;span style=""&gt;Works.&lt;/span&gt; &lt;/div&gt;   Tested in FF3.Now you can use flexbox for this type of layout.  .box { display: flex; align-items:center; } &lt;div class="box"&gt; &lt;img src="https://placehold.it/60x60"&gt; &lt;span style=""&gt;Works.&lt;/span&gt; &lt;/div&gt;    One performance tip that I see off the bat is using UNION ALL instead of UNION unless you intentionally want distinct records. A simple UNION will eliminate duplicates which takes time. UNION ALL doesn't do that.You could rewrite it with dynamic SQL and a loop but I think the result would be worse. If there is enough duplicate code to justify the dynamic sql approach, then I guess it could be justified.Alternatively, have you considered moving the logic out of the stored procedure into something like LINQ? For many, this isn't an option so I'm just asking.A final note: resist the urge to fix what's not broken just to make it look cleaner. If cleanup will aide in maintenance, verification, etc., then go for it. System.out.println("1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0");But seriously, folks, this is an untested first pass:for(int i=1; i&lt;100; i++){ System.out.print("1 "); for(int j=0; j&lt;i; j++){ System.out.print("0 "); }}If you looking for basic info on how to get started, Google is your friend. For example, try googling for "for loop java" and you'll get a lot of good examples. Also, to learn basic things in any language, a google search for "&lt;language&gt; hello world" is very reliable. I'd recommend the TOP 1 approach. It will probably help performance (not likely to hurt it). The notion that without it you'll catch errors is honorable but a little misplaced. If an error occurs here months from now, it will NOT be intuitive at all why it occurred or what's going on. Instead, I'd focus on enforcing data integrity elsewhere. You could update your hosts file to alias your machinename to DevServer:127.0.0.1 localhost# Comment this line out when back on the normal network:127.0.0.1 DevServer Add this rule above your existing rewrite rules to stop redirecting if the request has already been redirected once (ref):RewriteCond %{ENV:REDIRECT_STATUS} 200RewriteRule .* - [L] If you insist on using NVARCHAR instead of UNIQUEIDENTIFIER, you need to specify the size: @cartGUID nvarchar(36)Without it, your guids are being truncated (to 30 characters).You can confirm this behavior by running this modified version of your working query:DECLARE @cart nvarchar, @sizedcart nvarchar(36)SET @cart = '32390b5b-a35a-4e32-8393-67d5629192f0'SET @sizedcart = '32390b5b-a35a-4e32-8393-67d5629192f0'-- worksDelete FROM k_ShoppingCart Where CartGUID = '32390b5b-a35a-4e32-8393-67d5629192f0'-- will not workDelete FROM k_ShoppingCart Where CartGUID = @cart-- should workDelete FROM k_ShoppingCart Where CartGUID = @sizedcartI agree with @Marc Gravell, though, uniqueidentifier is the way to go here. Make sure you have indexes or this will perform very badly:SELECT posts.id, posts.title, posts.contentFROM posts WHERE NOT EXISTS ( SELECT post_id from tags WHERE tags.tag LIKE '%$keywords%' AND posts.id=tags.post_id)This gets a list of all posts, excluding those that have a tag matching the tag you specified. (Your orginal query referenced a 'jobs' table. I assumed that was a typo for 'posts'.)Table aliases make this a little cleaner:SELECT p.id, p.title, p.contentFROM posts pWHERE NOT EXISTS ( SELECT t.post_id from tags t WHERE t.tag LIKE '%$keywords%' AND p.id=t.post_id)Then, I'd create these indexes:Posts: id, tag_idTags: post_id, tagThen, run your query with 'explain' to see if it's performing well. Update your question with the results and someone will offer further advice. Index tuning is more trial and error than anything else so testing really is necessary. Pass re.IGNORECASE to the flags param of search, match, or sub:re.search('test', 'TeSt', re.IGNORECASE)re.match('test', 'TeSt', re.IGNORECASE)re.sub('test', 'xxxx', 'Testing', flags=re.IGNORECASE) This is not common.If you really need it, then you can either do what @Sergio suggested or, actually remove the items you want to skip from the dom, or possibly mark them as disabled when you submit (though some browsers my do different things with disabled controls--you'd have to check).This really isn't common. If you have so many selects that sending them is causing problems, you have too many selects.The normal way to handle this is to use your magic value, "-1", to know when to ignore certain values on the server side. You need to redirect stderr to stdout, so you can capture it. This example routes stdout to devnull (thus ignoreing it) and routes stderr to you:exec('ls * 2&gt;&amp;1 1&gt;/dev/null'); SELECT * FROM Table1 T1WHERE NOT EXISTS ( SELECT * FROM Table1 T2 WHERE T2.Serial = T1.Serial AND T2.Step = 'exit' AND T2.Date &gt; T1.Date) E-commerce/shopping cart design is good because most people understand the concept and you can push it in many different directions.You can do simple things like cart, cart_items, users, orders, order_items, etc.Then you can go deeper with user_addresses, user_emails, items, item_details, item_history, etc.This can provide a lot of good debate because there are lots of judgment calls.  Yes, they are safe. Although you're not getting the speed benefits you might hope for since JS bit operations are "a hack". When creating your conditional formatting, set the range to which it applies to what you want (the whole sheet), then enter a relative formula (remove the $ signs) as if you were only formatting the upper-left corner.Excel will properly apply the formatting to the rest of the cells accordingly.In this example, starting in B1, the left cell would be A1. Just use that--no advanced formula required.If you're looking for something more advanced, you can play around with column(), row(), and indirect(...). This is exactly what Cron (linux) or Scheduled Tasks (windows) are for. You can run them on your application server to keep everything in one place.For example, I have a cron running on my home server to backup its MySQL databases every day. Only one system is involved in this process. In your example, you can break the string into two pieces:alert ( "Please Select file" + " to delete");Or, when it's a string, as in your case, you can use a backslash as @Gumbo suggested:alert ( "Please Select file\ to delete");Note that this backslash approach is not necessarily preferred, and possibly not universally supported (I had trouble finding hard data on this). It is not in the ECMA 5.1 spec.When working with other code (not in quotes), line breaks are ignored, and perfectly acceptable. For example:if(SuperLongConditionWhyIsThisSoLong &amp;&amp; SuperLongConditionOnAnotherLine &amp;&amp; SuperLongConditionOnThirdLineSheesh){ // launch_missiles();} From this forum: parseInt() returns primitive integer type (int), whereby valueOf returns java.lang.Integer, which is the object representative of the integer. There are circumstances where you might want an Integer object, instead of primitive type. Of course, another obvious difference is that intValue is an instance method whereby parseInt is a static method. You can store the data files on an external drive. The server software itself, though, I'd install naively on each machine you use.This method assumes that your database is small and or you don't care about performance that much.For SQLServer, you'll probably have good luck if you set it to "autoclose". This will unlock the data files when the db isn't in use for some time. Otherwise, manually detaching the database or stopping SQL Server is advised when you pull the drive.This is almost certainly an unsupported use case so I'd make sure to keep regular backups in place in case something goes wrong. Feel free to add to this list:Internet Explorer since 6 sp1 (source, source)Firefox since 2.0.0.5 (source)Opera since 9.5 (possibly earlier) (source)Safari since 4 (source)Chrome since 1.0.154 (source) I migrated an SVN server today and ran into an issue. I have a repo that has an svn:externals property on a trunk subfolder. This folder has been branched a bunch of times and now this svn:externals reference needs updated on every single branch to refer to the new server.Is there an easy way to update all of these properties?I'm not excited about updating them individually by hand.I'm on windows, too, so a fancy bash script won't work. There's got to be an easier way!Note: this is from the old pre-1.5 days when svn:externals references had to be absolute.Update: a simple relocate won't do it since these are absolute URLs.  How do I get the number of days between two dates in JavaScript? For example, given two dates in input boxes:&lt;input id="first" value="1/1/2000"/&gt;&lt;input id="second" value="1/1/2001"/&gt;&lt;script&gt; alert(datediff("day", first, second)); // what goes here?&lt;/script&gt; I need to create an install for my app that executes the following actions:Copies filesWrites registry settingsRegisters a windows serviceWrites an XML app.config file (based on user supplied info during install--a connection string)Executes SQL scripts against a remote database (connection info obtained in #4)Installs and registers a COM dllAdds entry to Control Panel>Add/Remove programs for uninstallI don't need any fancy logic to allow the user to customize these steps--I can hard-code them with user-supplied info injected where appropriate.I looked at Wix but found the documentation and examples don't line up well with recent releases.I also looked at NSIS but found support for writing XML to be too limited (the plugin for this can only handle strings up to 64 bytes).I initially brushed off the VS2005 built in Setup project as incapable of handling these tasks but I'm ready to reconsider after stumbling with what I thought were better options.Any suggestions? I want to add some OSIsoft RtWebParts to a Sharepoint page. I want these trends to be shown in different timezones for different users. What I'm finding is that they are always shown in EDT. Ideally, I want a solution for configuring the presented timezone by page or by user. I vote for the lean approach. If you have good class names that make sense for CSS and jQuery--use them. If the names don't make sense for jQuery, then add new ones or rename the existing classes.If you are worried about developers breaking the script by renaming classes, then just add a note to the CSS that they need to search for jQuery references when changing class names. You can convert your list of IDs into a temp-table (or table-var if MySql supports them) and join with it. The table would only live as long as the query so you're not actually storing anything in a table. 100 GB will be plenty. You'll have OS, apps, but no music, pics, videos. 100GB is probably overkill, especially if you can resize it if needed. The official response from OSIsoft is: this cannot be done.RtWebparts objects always use the timezone of the Sharepoint site hosting them. Period.Other than spinning up a new sharepoint site for each timezone you care about, there is one unappealing workaround: Create your display in ProcessBook wherein you configure the time offset as desiredInclude the ProcessBook PDI file within an RtActiveView web partRepeat for each timezone You're still stuck with one timezone (set in the SVG) but now at least you can get multiple timezones without multiple servers. List would be better than Collection as noted in this semi-duplicate question.A hashset in 3.5 would be better still. What version of .net are you using? Try using Fiddler to see exactly what is being downloaded in your session. This will be very useful as it can capture downloads triggered by scripts, analytics, etc.I used fiddler on your page and found that WebResource.axd isn't being loaded with https. This is probably included because of an AJAX library like ASP.NET AJAX.This page describes your problem precisely and if it doesn't explicitly resolve it for you, it should at least give you some direction. That's just how aspnet works. Controls provide the clientid method for you to use in your code behind for this reason. If you want to refer to objects from js, you can either inject the clientid or use classes or other attributes. Edit: Note that this only applies to the ASP.NET controls. If you use the HTML controls, the given IDs are preserved. You can access them in your code behind by adding the runat=server attribute to them, too. Obviously these controls break the webforms model with viewstate, etc. but they do give you your desired functionality.Of course it's been a while since I worried about it so I could be wrong...(please comment or edit if I am!). It's always nice to take a poorly written, cursor-laden query and eliminate cursors, cut the code by half, and improve performance many-fold.Some of the best improvements are in clarity (and often result in nice performance boosts, too). You need the TFS power tools. Look towards the bottom for the check-in policy pack. You're right--usually this isn't what you want.However, there are plenty of cases where you need to throttle yourself down to a single connection. By serializing your access to the database through a singleton, you can address other issues or constraints like load, bandwidth, etc.I've done something similar in the past for a bulk processing app. Instead, though, I used a semaphore to synchronize access to the database so I could allow n concurrent db operations. Note that numeric-only IDs are invalid. See this post for more info.The short and sweet of it is: ID and NAME tokens must begin with a letter ([A-Za-z]) and may be followed by any number of letters, digits ([0-9]), hyphens ("-"), underscores ("_"), colons (":"), and periods ("."). The default scope is "default". It's weird--see these references for more info. The ID approach really is best but if you want to go by name, use getElementsByName.In this case, it might look like this:&lt;script&gt; // retrieves array of objects with the name 'keyword1' // and takes the first one var key1 = document.getElementsByName('keyword1')[0]; key1.focus(); key1.select();&lt;/script&gt; The issue here is that getNames returns an arraylist of objects--not ints.You could rewrite your code with this change: foreach (object nameobj in getNames()) { string name = (string)nameobj; MessageBox.Show(name); }Alternatively, you could (and should) use generics to keep everything nice and tidy. That might look like this (untested) code:private void testToolStripMenuItem_Click(object sender, EventArgs e){ foreach (string name in getNames()) { MessageBox.Show(name); }}private IList&lt;string&gt; getNames(){ //some code... List&lt;string&gt; names = new List&lt;string&gt;(); names.Add("Scott"); .. ... return names;}Add a using for System.Collections.Generic. Also, as others noticed, I changed it to string from int. The sort order matters when you want to retrieve lots of sorted data, not individual records.Note that (as you are suggesting with your question) the sort order is typically far less significant than what columns you are indexing (the system can read the index in reverse if the order is opposite what it wants). I rarely give index sort order any thought, whereas I agonize over the columns covered by the index.@Quassnoi provides a great example of when it does matter. How can I format a number to a fixed number of decimal places (keep trailing zeroes) where the number of places is specified by a variable?e.g. int x = 3;Console.WriteLine(Math.Round(1.2345M, x)); // 1.234 (good)Console.WriteLine(Math.Round(1M, x)); // 1 (would like 1.000)Console.WriteLine(Math.Round(1.2M, x)); // 1.2 (would like 1.200)Note that since I want to control the number of places programatically, this string.Format won't work (surely I ought not generate the format string):Console.WriteLine( string.Format("{0:0.000}", 1.2M)); // 1.200 (good)Should I just include Microsoft.VisualBasic and use FormatNumber?I'm hopefully missing something obvious here. Are there such high concurrency or performance requirements that you can't do simple locking, either exclusive/pessimistic or optimistic? Suppose you have a queue that holds objects of type task. Now, you can subclass task for various reasons. If you are loading your tasks from some source like a database, you could use a factory to determine what task type to load.For example:private IEnumerable&lt;Task&gt; GetTasks(DataTable Table){ Task NewTask; foreach(DataRow Row in Table){ switch(tasktype){ case tasktypes.TaskTypeA: NewTask = NewTaskA(...); break; case TaskTypes.TaskTypeB: NewTask = NewTaskB(...); break; ... } yield return NewTask; }}Later you could then call virtual methods on the tasks in your queue, like "consume" or "process", for example.The advantage to the factory approach (in this case) is that you only have to switch on task type once (when the task is created), and let polymorphism handle most everything else. System.Threading.Timer is extremely lightweight. You could create a separate timer for each task so that the timer comes due when the task is supposed to execute.Internally, I believe that the system will keep track of what timer is due next so it only has to monitor one timer at any given time (source/similar question). Try this:protected void Page_Init(object sender, EventArgs e){ HtmlLink css = new HtmlLink(); // add conditional logic to add correct css file css.Href = "css/fancyforms.css"; css.Attributes["rel"] = "stylesheet"; css.Attributes["type"] = "text/css"; css.Attributes["media"] = "all"; Page.Header.Controls.Add(css);} Sourcegear's Diffmerge is very nice and free. You would need to cut your code into different files so they could be compared side/side. You can use this (and most similar utilities) to compare three files at once. First, I strongly recommend that you not use triggers. If you're getting a syntax error, check that your parens are balanced as well as your begin/ends. In your case, you have an end (at the end) but no begin. You can fix that be just removing the end. Once you fix that, you'll likely get some more errors like "columns x,y,z not in an aggregate or group by". That's because you have several columns that are not in either. You need to add thread.rating, thread.voters, etc. to your group by or perform some kind of aggregate on them.This is all assuming that there are multiple records with the same threadID (ie, it's not the primary key). If that's not the case, then what's the purpose of the group by?Edit:I'm stumped on the syntax error. I worked around it with a couple correlated sub queries. I guessed at your table structure so modify as needed and try this:--CREATE TABLE ThreadRating (threadid int not null, userid int not null, rating int not null)--CREATE TABLE Thread (threadid int not null, rating int not null, voters int not null)ALTER TRIGGER thread_rating ON threadratingAFTER INSERTAS UPDATE ThreadSET Thread.rating = (SELECT (Thread.Rating * Thread.Voters + SUM(I.Rating)) / (Thread.Voters + COUNT(I.Rating)) FROM ThreadRating I WHERE I.ThreadID = thread.ThreadID) ,Thread.Voters = (SELECT Thread.Voters + COUNT(I.Rating) FROM ThreadRating I WHERE I.ThreadID = Thread.ThreadID) FROM ThreadJOIN Inserted ON Inserted.ThreadID = Thread.ThreadIDIf that's what you wanted, then we can check the performance/execution plan and modify as needed. We might be able to get it to work with the group by yet.Alternatives to triggersIf you are updating data that impact ratings in only a few select places, I'd recommend updating the ratings directly there. Factoring the logic into a trigger is nice but provides lots of problems (performance, visibility, etc.). This can be aided by a function.Consider this: your trigger will execute every single time someone touches that table. Things like view counts, last updated dates, etc. will execute this trigger. You can add logic to short circuit the trigger in those cases but it gets complicated rapidly. If your customer uses active directory already, then you can use a logon script to download the master configuration files they might need.This would only occur when they login while connected to the domain so your connectivity requirement is met, and since it'd only be downloaded at that time all your client apps could load the data locally satisfying the locality requirement.Then, when you deploy an updated configuration file, all users would need to do is login again while connected to the network.This script would not be unlike the scripts often used to mount available network shares or configure local printers. In each case, you can determine where a user is located and thus what config file they should download.That is of course presuming that these config values don't change very often. If it's likely that they will change so often as to make a logout/login inconvenient, you'll have to go with another approach. As part of my app's config process, I have a sanity checker that validates all user-supplied data. This includes email server settings that the app uses to send email. I'd like a simple sanity check on those settings without actually sending any email. It'd be great if this could support all standard flavors of SMTP setups including those with authentication/ssl/etc.It doesn't need to be exhaustive but the more coverage, the better. Currently all I do is verify I can open a connection to the given server on the given port. Something a little deeper would be nice.Note: I'm not trying to validate email addresses--that's not relevant to this question. I'm using a library that generates a bunch of classes for me.These classes all inherit from a common base class but that base class doesn't define a couple methods that are common to all subclasses.For example:SubClassA : BaseClass{ void Add(ItemA item) {...} ItemA CreateNewItem() {...}}SubClassB: BaseClass{ void Add(ItemB item) {...} ItemB CreateNewItem() {...}}Unfortunately, the base class doesn't have these methods. This would be great:BaseClass{ // these aren't actually here, I'm just showing what's missing: abstract void Add(ItemBaseClass item); // not present! abstract ItemBaseClass CreateNewItem(); // not present!}Since there is a common base class for my A+B objects and a common base class for the Item objects, I had hoped to benefit from the wonderful world of polymorphism.Unfortunately, since the common methods aren't actually present in the base class, I can't call them virtually. e.g., this would be perfect:BaseClass Obj;Obj = GetWorkUnit(); // could be SubClassA or SubClassBItemBaseClass Item = Obj.CreateNewItem(); // Compile Fail: CreateNewItem() isn't in the base classItem.DoSomething();Obj.Add(Item); // Compile Fail: Add(...) isn't in the base classObviously casting would work but then I'd need to know which type I had which would negate the benefits.How can I "force" a call to these methods? I'm not worried about getting an object that doesn't implement the method I'm trying to call. I can actually do what I want in VB--I don't get intellisense but the compiler's happy and it works:CType(Obj, Object).Add(Item) // Note: I'm using C#--NOT VBAgaint, I have no control over these classes (which I think rules out partial classes). Update: Here's a similar questionSuppose I have a DataTable with a few thousand DataRows in it.I'd like to break up the table into chunks of smaller rows for processing. I thought C#3's improved ability to work with data might help.This is the skeleton I have so far:DataTable Table = GetTonsOfData();// Chunks should be any IEnumerable&lt;Chunk&gt; typevar Chunks = ChunkifyTableIntoSmallerChunksSomehow; // ** help here! **foreach(var Chunk in Chunks){ // Chunk should be any IEnumerable&lt;DataRow&gt; type ProcessChunk(Chunk);}Any suggestions on what should replace ChunkifyTableIntoSmallerChunksSomehow?I'm really interested in how someone would do this with access C#3 tools. If attempting to apply these tools is inappropriate, please explain!Update 3 (revised chunking as I really want tables, not ienumerables; going with an extension method--thanks Jacob):Final implementation:Extension method to handle the chunking:public static class HarenExtensions{ public static IEnumerable&lt;DataTable&gt; Chunkify(this DataTable table, int chunkSize) { for (int i = 0; i &lt; table.Rows.Count; i += chunkSize) { DataTable Chunk = table.Clone(); foreach (DataRow Row in table.Select().Skip(i).Take(chunkSize)) { Chunk.ImportRow(Row); } yield return Chunk; } }}Example consumer of that extension method, with sample output from an ad hoc test:class Program{ static void Main(string[] args) { DataTable Table = GetTonsOfData(); foreach (DataTable Chunk in Table.Chunkify(100)) { Console.WriteLine("{0} - {1}", Chunk.Rows[0][0], Chunk.Rows[Chunk.Rows.Count - 1][0]); } Console.ReadLine(); } static DataTable GetTonsOfData() { DataTable Table = new DataTable(); Table.Columns.Add(new DataColumn()); for (int i = 0; i &lt; 1000; i++) { DataRow Row = Table.NewRow(); Row[0] = i; Table.Rows.Add(Row); } return Table; }} I think you should start with your user table and then join to the other tables from there:SELECT U.user_id, d.dining_table, p.poker_table, c.computer_tableFROM Users ULEFT JOIN Dining_Table D ON D.bus_boy = U.user_id OR D.waiter = U.user_id or D.server = U.user_idLEFT JOIN Poker_Table P ON P.dealer = U.user_id OR P.pit_boss = U.user_idLEFT JOIN Computer_Table C ON C.programmer = U.user_idWHERE U.Name = 'Joe Smith'-- only return rows with at least one table match-- or leave off to always return the user)AND NOT ( d.dining_table IS NULL AND p.poker_table IS NULL AND c.computer_table IS NULL)This will give you one row per user, indicating which table the user is at (or null).If you really want a straight list for a single user only, then the union approach may be preferred. However, if this query will be run for a roster or users, I think my approach is better. This approach smells funny but I'll ignore that for now. To fix your problem, you need to cast the objects you are passing with "(IDisposable)"I concede to the will of the compiler, and Jon Skeet. You need an actual object for this:IDisposable _BazD = (IDisposable)_Baz;DisposeObject(ref _BazD);I'd also add a null check in your DisposeObject() in addition to the try/catch. The "obj==null" will be a quick and easy check when compared to expensive exception catching should this get hit multiple times for the same object. Hmm...was that there a minute ago? Nevermind. Excluding recursion, I wouldn't worry about call stack issues until they appear (which they likely won't).Regarding recursion: it must be carefully implemented and carefully tested no matter how it's done so this would be no different. I would go with the mantra that those are the wrong tools for the job (assuming they are in your case). It'd be like using a screw driver as a hammer. For one nail, it might work with a lot of sweat and tears. For a real project, through, this is likely doomed.I'd boast about the tools you are familiar with--how much better the tooling is in terms of performance, security, maintenance (esp. maintenance cost).You could say something like he's paying someone to write a new app with decade old technology which may not be supported for much longer (if it still is...). C# tends to default everything to the minimum scope necessary. This is a nice convention and quoted in Skeet's book (C# In Depth, p 224 "Note/Trivia"):  [Properties are the] only place where private is requiredEverywhere else in C#, the default access modifier in any given situation is the most private one possible. In other words, if something can be declared to be private, then leaving out the access modifiers entirely will default it to being private. This is a nice element of language design, because its hard to get it wrong accidentally: if you want something to be more public than it is, youll notice when you try to use it. Suppose I have these tables:Fruits - FruitID INT PK - FruitName NVARCHAR(30) - FruitStatusID INT FK: StatusesStatuses - StatusID INT PK - StatusName NVARCHAR(30)How do I update both the Fruit's name and its status in the database in these situations?:Update a piece of Fruit that came from a previous L2E callgiven an integer corresponding to the FruitID (that is, I don't have a full Fruit object in hand to start with)VB or C# is fine, thanks! This works but isn't what I was hoping for:int StatusID = 4; // Some IDFruit.FruidIDReference.EntityKey = New EntityKey("MyEntities.Statuses", "StatusID", StatusID)Surely there's a cleaner way to do this that doesn't require hard-coding strings (which introduces run-time exceptions if I make a typo). Given this schema:Fruits - FruitID INT PK - FruitName NVARCHAR(30) - FruitStatusID INT NULL FK: StatusesStatuses - StatusID INT PK - StatusName NVARCHAR(30)If I have a FruitID in hand (just an int, not a Fruit object), how do I update the FruitName and null out FruitStatusID without loading the Fruit object from the database first?Note: this solution gets me pretty far, but I can't figure out how to null out a FK column.Answers in C# or VB, thanks! This works but seems unnecessarily complicated:''//initialize the values I'm going to null out to somethingDim Tag As Data_Tag = New Data_Tag() With { .Data_Tag_ID = DataTagID, .Last_Error_DateTime = New DateTime(), .Last_Error_Message = "", .Last_Error_Severity_Type_ID = -1 }''//start change trackingDB.Data_Tags.Attach(Tag)''//record changes to these properties (must be initialized above)Tag.Last_Error_DateTime = NothingTag.Last_Error_Message = NothingTag.Last_Error_Severity_Type_ID = NothingDB.SubmitChanges()Surely there's a better way!(note: the weird comment syntax is solely for the code highliger--it doesn't like VB-style comments) When inserting into a table with an identity column, you don't specify anything for the identity column:DECLARE @ERR INTINSERT INTO CaseTypeList (TypeID, CaseID) --Column1 is auto-number, skip itVALUES (@TypeID, @CaseID)-- capture error var and last inserted identity valueSELECT @ERR = @@ERROR, @ID = SCOPE_IDENTITY()-- IF @ERR &lt;&gt; 0 handle error, otherwise returnYou don't need identity insert or anything like that unless you want to explicitly control the number. In that case, you wouldn't set it to identity.Also, I kind of guessed on your columns.Edit: OK, so it looks like you don't actually need the identity column at all. Instead, you need to generate the next number in a sequence if one isn't provided. In this case, you can leave the identity column in there--it won't hurt anything, but might help later if you want a single unique key:CREATE PROCEDURE [dbo].[AddCaseType]( @RefID INTEGER = NULL OUT, @TypeID INTEGER)ASBEGIN TRANSACTION IF @RefID IS NULL BEGIN SELECT @RefID = MAX(RefID)+1 FROM CaseTypeList END IF @@ERROR &lt;&gt; 0 BEGIN ROLLBACK; RAISERROR('Could not get ID', 16, 1) END INSERT INTO CaseTypeList(RefID, TypeID) VALUES (@RefID, @TypeID) IF @@ERROR &lt;&gt; 0 BEGIN ROLLBACK; RAISERROR('Could not insert', 16, 1) ENDCOMMIT TRANSACTION Note: you should probably have a Unique Key Constraint on RefID and TypeID if there cannot be duplicates. If you make an array of a reference type, I think only the references are kept in the variable. That is:Dim strArray(5) As StringWill only actually be 6 references big with something like 4 bytes per reference (not sure on that).The actual data will be stored (probably) on the heap.This doesn't mean that changing a string's length is trivial, though--they must still be reallocated each time they are changed. This article says you cannot assume FIFO, though seems to slightly imply that FIFO is what is generally expected. I might be overstating that, though.This article confirms that they are not guaranteed to be released in any order: Semaphores in C# are not First in First Out, the implementation actually does not guarantee the order in which tasks are released. A coworker relayed the following problem, let's say it's fictional to protect the guilty: A team of 5-10 works on a project which is issue-driven. That is, the typical flow goes like this:a chunk of work (bug, enhancement, etc.) is created as an issue in the issue trackerThe issue is assigned to a developerThe developer resolves the issue and commits their code changes to the trunkAt release time, the frozen, and heavily tested trunk or release branch or whatever is built in release mode and releasedThe problem he's having is that a couple newbies made several bad commits that weren't caught due to an unfortunate chain of events. This was followed by a bad release with a rollback or flurry of hot fixes.One idea we're toying with: Revoke commit access to the trunk for newbies and make them develop on a per-developer branch (we're using SVN):Good: newbies are isolated and can't hurt othersGood: committers merge newbie branches with the trunk frequently Good: this enforces rigid code reviews Bad: this is burdensome on the committers (but there's probably no way around it since the code needs reviewed!) Bad: it might make traceability of trunk changes a little tougher since the reviewer would be doing the commit--not too sure on this.Update: Thank you, everyone, for your valuable input. I have concluded that this is far less a code/coder problem than I first presented. The root of the issue is that the release procedure failed to capture and test some poor quality changes to the trunk. Plugging that hole is most important. Relying on the false assumption that code in the trunk is "good" is not the solution.Once that hole--testing--is plugged, mistakes by everyone--newbie or senior--will be caught properly and dealt with accordingly.Next, a greater emphasis on code reviews and mentorship (probably driven by some systematic changes to encourage it) will go a long way toward improving code quality.With those two fixes in place, I don't think something as rigid or draconian as what I proposed above is necessary. Thanks! Check out the linux command find.Alternatively, this post pipes together ls and tail to delete the oldest file in a directory. That could be done in a loop while there isn't enough free space.For reference, here's the shell code that does it (follow the link for more alternatives and a discussion): ls -t -r -1 /path/to/files | head --lines 1 | xargs rm It has nothing to do with comments. It does it that way only when you tell it to "include IF NOT EXISTS". The reason is that it can only programmatically include or exclude objects if they are executed dynamically.You can disable this is stored procedures by selecting "False" in Options\SQL Server Object Explorer\Scripting - Check for object existence. Use SqlCmd.exe.For example:sqlcmd -S myServer\instanceName -i C:\myScript.sqlor to save output to a file:sqlcmd -S myServer\instanceName -i C:\myScript.sql -o C:\EmpAdds.txt I'm looking at adding master pages to an existing site but have found that once I do, the elements' IDs get prepended with a code (e.g. ctl00_MainPageContent_).Unforunately, this breaks existing scripts on the page that use the original, unmodified element ID. I realize that I can replace it with &lt;%= Element.ClientID %&gt; but it'd be awesome if I could disable this behavior altogether.So, can I keep the original IDs? There are two schools of thought on this (at least). Throw the work on a queue and have something else outside your web-stack handle it.Throw the work on a queue and have something else in your web-stack handle it.In either case, you create work units in a queue somewhere (e.g. a database table) and let some process take care of them. I typically work with number 1 where I have a dedicated windows service that takes care of these things. You could also do this with SQL jobs or something similar.The advantage to item 2 is that you can more easily keep all your code in one place--in the web tier. You'd still need something that triggers the execution (e.g. loading the web page that processes work units with a sufficiently high timeout), but that could be easily accomplished with various mechanisms. You need to include a negative sign.I don't have access to test this right now but I'd bet if you tried this value instead:Integer min = Integer.MIN_VALUE + 1;It wouldn't bomb, but would give you a positive number (not negative) when you ran ParseInt(min,16).A string of bits doesn't really have enough info to determine sign in this context so you need to provide it. (consider the case where you use min = "F". Is that +/-F? If you converted it to bits and saw 1111, and you knew it was a byte, you might conclude that it's negative, but that's a lot of ifs. If you can use LINQ, this will give you the insurance company names:var Names = (from Row in YourDataSet.YourTable select Row.InsuranceCompanyName).Distinct();You could also add .ToArray() or .ToList() or orderby depending on your needs, if necessary.If you can't use LINQ or change the SQL call, it's more complicated. You should be using mysql_insert_id instead of doing a select to get the ID. this T obj would need to be a ref argument. Since that's not allowed (MSDN or C# In Depth p258, Skeet), you can't.I would suggest you not push this idea too far, though. It seems like a confusing application of extension methods, especially when the alternative is still a short one line. I'm getting started with Selenium IDE and trying to test a webapp that's full of modal dialogs (window.showModalDialog).Recording the test seems to work (except there's nothing in the log when the dialog pops up) but they don't play back properly. The script actually opens the window (triggered by a button click), but then just waits indefinitely.Any suggestions?  I prefer the second option where the most recently written table comes first.I think Linq requires it to be the other-way-round, though (option 1). I'm trying to do some unit/integration tests between pages of my ASP.NET site but can't seem to find any tool that can work effectively with modal dialogs generated by the showModalDialog command (FF3, IE).Does anyone have experience testing these annoying things?Update: @bbmud was right--WatiN supports modal dialogs very well. Here's the example that got me started.Thanks! Given this markup:// Calendar.html?date=1/2/2003&lt;script&gt; $(function() { $('.inlinedatepicker').datepicker(); });&lt;/script&gt;...&lt;div class="inlinedatepicker" id="calendar"/&gt;This will display an inline datepicker with very little effort (awesome!). How do I preset the datepicker to the date passed in via the query string?Note that in this case, I don't have an input box--just a calendar attached to a div. I start with Yahoo's reset/base CSS files (they are tiny). They make styles consistent between browsers from day 1. Then when I add custom styles, they are typically well received and consistent in all browsers.Of course you'll still need the occasional hack for this and that. There's nothing special about user profiles. What you are asking for applies to nearly every app I've ever worked on: store and share data.Different platforms are better at different things but there's no silver bullet for this problem--this is what software is all about.For example, you can create a users table in a database and some CRUD screens to manage it. You could create an API into that data using any number of approaches.When your requirements change, repeat (and hope you don't have to change too much). As I indicated in my other answer, the solution to your problem is: apply software engineering. This is what we do--there's no simple solution (e.g. use framework x or library y) to a broad question like this. I have various .Debugify extension methods that are useful for dumping objects to a log file. For example, here's my Dictionary debugify (I have these for List, Datatable, param array, etc.):public static string Debugify&lt;TKey, TValue&gt;(this Dictionary&lt;TKey, TValue&gt; dictionary) { string Result = ""; if (dictionary.Count &gt; 0) { StringBuilder ResultBuilder = new StringBuilder(); int Counter = 0; foreach (KeyValuePair&lt;TKey, TValue&gt; Entry in dictionary) { Counter++; ResultBuilder.AppendFormat("{0}: {1}, ", Entry.Key, Entry.Value); if (Counter % 10 == 0) ResultBuilder.AppendLine(); } Result = ResultBuilder.ToString(); } return Result;}And here's one for a DbParameterCollection (useful for dumping database calls to the log file):public static string Debugify(this DbParameterCollection parameters) { List&lt;string&gt; ParameterValuesList = new List&lt;string&gt;(); foreach (DbParameter Parameter in parameters) { string ParameterName, ParameterValue; ParameterName = Parameter.ParameterName; if (Parameter.Direction == ParameterDirection.ReturnValue) continue; if (Parameter.Value == null || Parameter.Value.Equals(DBNull.Value)) ParameterValue = "NULL"; else { switch (Parameter.DbType) { case DbType.String: case DbType.Date: case DbType.DateTime: case DbType.Guid: case DbType.Xml: ParameterValue = "'" + Parameter .Value .ToString() .Replace(Environment.NewLine, "") .Left(80, "...") + "'"; // Left... is another nice one break; default: ParameterValue = Parameter.Value.ToString(); break; } if (Parameter.Direction != ParameterDirection.Input) ParameterValue += " " + Parameter.Direction.ToString(); } ParameterValuesList.Add(string.Format("{0}={1}", ParameterName, ParameterValue)); } return string.Join(", ", ParameterValuesList.ToArray());}Example result:Log.DebugFormat("EXEC {0} {1}", procName, params.Debugify);// EXEC spProcedure @intID=5, @nvName='Michael Haren', @intRefID=11 OUTPUTNote that if you call this after your DB calls, you'll get the output parameters filled in, too. I call this on a line that includes the SP name so I can copy/paste the call into SSMS for debugging.These make my log files pretty and easy to generate without interrupting my code. The reset simply resets things so that you don't have to reconnect to reset them. It wipes the connection clean of things like SET or USE operations so each query has a clean slate.The connection is still being reused. Here's an extensive list:sp_reset_connection resets the following aspects of a connection:It resets all error states and numbers (like @@error)It stops all EC's (execution contexts) that are child threads of a parent EC executing a parallel queryIt will wait for any outstanding I/O operations that is outstandingIt will free any held buffers on the server by the connectionIt will unlock any buffer resources that are used by the connectionIt will release all memory allocated owned by the connectionIt will clear any work or temporary tables that are created by the connectionIt will kill all global cursors owned by the connectionIt will close any open SQL-XML handles that are openIt will delete any open SQL-XML related work tablesIt will close all system tablesIt will close all user tablesIt will drop all temporary objectsIt will abort open transactionsIt will defect from a distributed transaction when enlistedIt will decrement the reference count for users in current database; which release shared database lockIt will free acquired locksIt will releases any handles that may have been acquiredIt will reset all SET options to the default valuesIt will reset the @@rowcount valueIt will reset the @@identity valueIt will reset any session level trace options using dbcc traceon()sp_reset_connection will NOT reset:Security context, which is why connection pooling matches connections based on the exact connection stringIf you entered an application role using sp_setapprole, since application roles can not be revertedThe transaction isolation level(!) No. You can obviously add the .ToString() in the calling code, but you can't do what you propose without different names like this:private DateTime m_internalDateTime;public DateTime SetDateTime { set { m_internalDateTime = value; } }public string GetDateTime { get { return m_internalDateTime.ToString(); } } Or, even better to use methods instead of properties (as noted in the comments):private DateTime m_internalDateTime;public void SetDateTime(DateTime dateTime) { m_internalDateTime = dateTime; }public string GetDateTime() { return m_internalDateTime.ToString(); }Keep in mind that var is for implicitly, compile-time typed variables, not dynamic variables.Definitely do not do what you noted in your edit. It introduced a break in convention, possible performance implications (albeit slight), and significant localization problems. It's likely that your app pool workers are recycling (idle or otherwise) and thus starting up with an empty cache. This will be much easier if you just let each of your four threads write to the database themselves. In this scenario you don't have to worry about threading (except for what files each thread works on) as each worker thread could maintain their own datatable and consume 25% of the files.Alternatively, you can have a single datatable that all the threads use--just make sure to wrap accesses to it with a lock like so:lock(YourTable.Rows.SyncRoot){ // add rows to table}Of course this is all moot if the bottleneck is the disk, as @David B notes. Try this (a one-liner):var Countries = new List&lt;string&gt;() { "Denmark", "USA", "Mexico" };return Countries.OrderBy(c=&gt; c=="USA"? " ": c);Explanation:This sorts the list of countries by name, subsituting " " for the one that should be first. Since whitespace comes before any other letter alphabetically, the "default" country will be listed first. The optimizer will do whatever it thinks will be fastest. You can force certain behaviors with join hints or encourage certain behaviors with statistics and indexes. It's usually best to Trust the Optimizer, though.If you want a detailed explanation of how a query is executed, look at the execution plan. You should pass in the desired culture to all of your formatting functions (InvariantCulture, usually). Alternatively, you can set the culture on the page like so. That code could also go in the Application BeginRequest override in your asax.cs file in order to affect all pages. Check out this outerHTML plugin. Just add "and category"...SELECT * FROM links WHERE category LIKE '1|%' AND category NOT LIKE '1|6|199|%','1|6|200|%' ORDER BY score DESC LIMIT 9Actually, the comma separated condition is not a syntax I'm familiar with. If that's not working, try this instead:SELECT * FROM links WHERE category LIKE '1|%' AND category NOT LIKE '1|6|199|%' AND category NOT LIKE '1|6|200|%' ORDER BY score DESC LIMIT 9 Given a table name and column name in a pair of variables, can I perform a select query without using dynamic sql? for example, I'd like something nicer than this:CREATE PROCEDURE spTest (@table NVARCHAR(30), @column NVARCHAR(30)) AS DECLARE @sql NVARCHAR(2000) SELECT @sql = N'SELECT ' + @column + N' FROM ' + @table PRINT @sql EXEC sp_executesql @sqlI'd like to do this because my dynamic sql version is 3x slower than the non-dynamic version (which doesn't support a programmable table/column name, hence this question).  How do I update the factory layout templates in Proficy Change Management (i.e. where are they located when checked out?). e.g. generic.htm? Procedure:Open Proficy Change ManagementCheck out the desired factory layoutOpen Explorer (Win-E) and go to C:\fx\fxLayout\FactoryLayoutNameMake your changes (edit, create, etc.)Publish and check in the factory layoutThe path will vary based on your configuration but it is likely to be similar to what's noted above. Any files you change or add to that folder will be captured when you publish or check in. This is a bug. It doesn't seem to have a lot of attention around it, through, so I'd suggesting following up with that report.The uninspiring workaround appears to be to ignore negative values:long elapsedMilliseconds = Math.Max(0, stopwatch.ElapsedMilliseconds); You want Double.TryParse:Dim PossibleDouble as DoubleIf Double.TryParse("hello", PossibleDouble) Then ''//Success!Else ''//Not a doubleEnd If Here's a sample page with a couple datepickers. Here's the Drip result for that:alt text http://www.picvault.info/images/537090308_omoya.pngThis page leaks indefinitely in IE6sp1 when I click the Refresh button repeatedly (IE6sp3+, Opera 9, Chrome2, and FF3+ seem to be good). The memory goes up and never goes down until I actually close the browser completely.I've also tried using the latest nightly of jquery (r6414) and the latest stable UI (1.7.2) but it didn't make any difference. I've tried various things with no success (CollectGarbage, AntiLeak, others).I'm looking for a solution other than "use a different browser!!1" as I don't have any control over that. Any help will be greatly appreciated!Update 1: I added that button event to a loop and this is what happens (the sudden drop off is when I terminate IE):Update 2: I filed a bug report (fingers crossed).Update 3: This is also on the mailing list.Update 4: This (as reported on the mailing list) doesn't work, and in fact makes things worse:$(window).bind("unload", function() { $('.hasDatepicker').datepicker('destroy'); $(window).unbind();}); It's not enough to just call destroy. I'm still stranded with this one and getting very close to ripping jquery out of the project. I love it (I really do!) but if it's broken, I can't use it.Update 5: Starting the bounty, another 550 points to one helpful individual!Update 6: Some more testing has shown that this leak exists in IE6 and IE6sp1, but has been fixed in IE6sp2+. Now, about the answers I have so far...So far all answers have been any one of these:Abandon IE6sp0/sp1 users or ignorethemDebug jquery and fix the problem myselfI can't repro the problem.I know beggars can't be choosers, but those simply are not answers to my problem.I cannot abandon my users. They make up 25% of the userbase. This is a custom app written for a customer, designed to work on IE6. It is not an option to abandon IE6sp0/sp1. It's not an option to tell my customers to just deal with it. It leaks so fast that after five minutes, some of the weaker machines are unusable.Further, while I'd love to become a JS ninja so I can hunt down obscure memory leaks in jquery code (granted this is MS's fault, not jquery's), I don't see that happening either. Finally, multiple people have reproduced the problem here and on the mailing list. If you can't repro it, you might have IE6SP2+, or you might not be refreshing enough.Obviously this issue is very important to me (hence the 6 revisions, bounty, etc.) so I'm open to new ideas, but please keep in mind that none of those three suggestions will work for me.Thanks to all for your consideration and insights. Please keep them coming!Update 7: The bounty has ended and Keith's answer was auto-accepted by SO. I'm sorry that only half the points were awarded (since I didn't select the answer myself), but I'm still really stuck so I think half is fair. I am hopeful that the jquery/jquery-ui team can fix this problem but I'm afraid that I'll have to write this off as "impossible (for now)" and stop using some or all of jquery. Thanks to everyone for your help and consideration. If someone comes along with a real solution to my problem, please post and I'll figure out some way to reward you. Why wouldn't you just checkin the modifications as a change? That's what svn is for.If you really want to replace the version in there, you can delete it first, then re-add. But, the original version will be available if you walk back in time (again, that's what svn is for). If you want to destroy the history, I'd just recreate the repo. This is the only sane way to restart the revision number, especially for beginners.Seriously, though, there's nothing wrong with checking in a bunch of revisions as your get your source code cleaned up.  PHP doesn't support this. (non-explicit ref) You need to bind a function to the select list so that when it changes, your function decides if the div should be shown. Something like this (untested, hopefully syntactically close). Here's a live example.$(document).ready( function() { $('#YourSelectList').bind('change', function (e) { if( $('#YourSelectList').val() == 241) { $('#OtherDiv').show(); } else{ $('#OtherDiv').hide(); } });}); You're doing an aggregate. Since the aggregate is defined for 0-n rows (in this case, 0 rows yields null), you will always get one result back (exactly one in this case).To put it another way, you're not asking for rows from the table--you're asking for the average of one column in the table and that's what you're getting back. Getting anything other than one row in this case would be weirder.If you had asked for non-aggregated columns, too, e.g. SELECT Salesperson, AVG(Sale)FROM SalesGROUP BY Salespersonthen I would expect you to get no rows back because there wouldn't be anything to satisfy the non-aggregate selects. I would go with something more event-natured like this work around for PHP's missing event support. It looks similar to what you had in mind with pre-registering.If you can't do that or prefer not to, a bunch of empty function calls will not hurt performance (though thousands of them? Maybe). I'd do some basic profiling to see where time is spent serving a page. If it is shown that empty functions take a significant amount of time then I would worry about it. I cannot imagine a case where the page is so complex as to require that many triggers, though, and not have other more imposing bottlenecks. That is, if the page has so much going on, the added triggers become even less significant. You should create a new class for that test which has only the setup (or lack of setup) that it needs.Alternatively, you could unfactor the setup code into a method that all the other tests call, but I don't recommend this approach. It's all HTML and Javascript, plus a lot of video trucks, satellites (and airplanes?), and google magic.. More information:How does Google Maps work? Here you go (live demo):$(document).ready( function (){ alert( $('a.Tag.Resource').html() ); });Your issue is either that you wanted one class but used a space so it became two; or that when referring to classes with a jquery selector, you need to prefix them with a period.In any case, the above code will help. If you really just wanted one class, change it to $('a.Tag-Resource')... This is a classic problem. You have a lot of solutions available:Probably the easiest way is to configure your webserver to server CSS files as never-cache/expire immediately. Obviously you wouldn't want this on a production environment. With IIS, this is very easy to do.Add a random value to the name of the file you're including, e.g. Site.css?v=12. This is what SO does for their includes. I do this in house so that on the development machine, the parameter changes each time (a guid) the file is served, but when deployed it uses the svn version number. A little trickier but more robust.Many, many more I'm sure Those scenarios are cases advocating for the use of DST. It doesn't matter what you display as long as you store and sort values in UTC. That is, if you use UTC properly, the problems presented in those scenarios are solved.Yes, it would be confusing to see records like this: 12:30, 1:20, 1:10, 3:30 but if that's how they are ordered according to UTC (what really happened), I think that's the right way to do it.SO avoids this problem altogether by recording everything in UTC and then displaying it all in UTC or relative times (like "17 mins ago...").If you're referring to user supplied dates/times as suggested in the comments, I have some bad news for you: it sucks. I think the best, most obvious solution is to pick a rule and run with it. If you really do need to handle it perfectly, your UI will need to be expanded to pedantically handle this edge case that occurs a mere 1 hour each year and then only to transactions created not-in-real-time (because if they were real-time, you'd know the DST equivalent). Perhaps describe a little bit more as to what you're trying to accomplish?$('#wrow .text').addClass("error"); $('#wrow .text').removeClass("error");Will take any descendent of #wrow with the .text class and add the error class to those elements.If you want to find the #wrow element when it also has the class "text", then it should look like this:$('#wrow.text').addClass("error"); // no space in the selectorI don't think that's what you want either because you'd really only have one #wrow in the page (if you have more, you have another problem as IDs are supposed to be unique) so please clarify. If you want to grep recursively, use -R/-r and a path:grep -R "TODO" .So either you're missing the path (.) or I misunderstand your question. I always strive to go with Good and Fast. Often what is delivered is Cheap and Fast, sadly.I think the frequent mistake people make is to go with "cheap" without considering a total cost over the project life cycle, including support and maintenance. If initial bids included these extra items (which I suggest are far more costly for "cheap" projects than non-cheap projects) the cheap option often looks less appealing (and is often the most expensive in the long run).Just some thoughts from my experience... You must profile your process before making any decisions.Where is the time spent (creating the messages, retrieving recipients, submitting the messages to SMTP, SMTP sending messages, etc.)?Do not guess or assume you know where the bottleneck it, especially when considering a parallel approach. You could easily make things worse (or have no impact). We have a continuous integration server running Hudson CI. I'm thinking about putting up an LCD display in the office with various build stats and am curious what others have put together. I'm currently thinking about buying a WIFI-enabled digital picture frame that I can send generated images to. Or repurposing an old laptop...Thoughts? Experiences?  I'm seeing this issue.I have a relatively simple ASP.NET page with a gridview and some buttons. When I click a button, the page re-binds the grid and posts back.What's strange is that every other time I click the refresh button, the IE progress bar (in the status area) stays "on", signaling that the user that the page is still loading...forever.I've reproduced this on other pages--it seems to occur every time a post-back occurs.Confirmed in IE7 and IE8, but doesn't happen in FF3.5.Any ideas?Update 1: This appears to happen only when the server is configured for HTTP Compression. In either case (compressed or not), fiddler shows just a single request which is served successfully. But, when compression is enabled, I get the problematic behavior. I have a bunch of users making ad-hoc queries into a database running SQL Server. Occasionally someone will run a query that locks up the system for a long period of time as they retrieve 10MM rows.Is it possible to set some options when a specific login connects? e.g.:transaction isolation levelmax rowcountquery timeoutIf this isn't possible in SQL Server 2000, is it possible in another version? As far as I can tell, the resource governor does not give you control like this (it just lets you manage memory and CPU).I realize the user's could do much of this themselves but it'd be awesome if I could control it from the server per user.Obviously I'd like to move the users away from direct table/view access but that's not an option at the moment. I have a large report currently rendered as a regular HTML table. I'd like to be able to group columns together and expand/collapse them with a button. This is a very common practice for rows but not so much for columns. I was wondering if anyone has any tips for doing it with columns.My stack includes jquery so that's available to you (though certainly not required!). Try this:var paragraphsWithoutImages = $('p').not(':has(img)')(Live example) I found an online JS calculator and a PHP solution:&lt;?phpfunction DMStoDEC($deg,$min,$sec){// Converts DMS ( Degrees / minutes / seconds ) // to decimal format longitude / latitude return $deg+((($min*60)+($sec))/3600);} function DECtoDMS($dec){// Converts decimal longitude / latitude to DMS// ( Degrees / minutes / seconds ) // This is the piece of code which may appear to // be inefficient, but to avoid issues with floating// point math we extract the integer part and the float// part by using a string function. $vars = explode(".",$dec); $deg = $vars[0]; $tempma = "0.".$vars[1]; $tempma = $tempma * 3600; $min = floor($tempma / 60); $sec = $tempma - ($min*60); return array("deg"=&gt;$deg,"min"=&gt;$min,"sec"=&gt;$sec);} ?&gt;  Here's my scenario: I have two tables A, B which (for the sake of this question are identical):Table X (PK)ID 12Table A:ID FKID Value Sort1 1 a 12 1 aa 23 1 aaa 34 2 aaaa 15 2 aaaaa 2Table B:ID FKID Value Sort1 1 b 12 1 bb 23 2 bbb 14 2 bbbb 25 2 bbbbb 3Desired Output:FKID ValueA ValueB Sort1 a b 11 aa bb 21 aaa (null) 32 aaaa bbb 12 aaaaa bbbb 22 (null) bbbbb 3So record 1 has 3-As and 2-Bs and record 2 has 2-As and 3-Bs all nicely paired up by the Sort integer column.My current solution involves cross joining with a Numbers table. It works but since the number of items in these tables is unbounded my numbers table is largish (the application is theorhetically unbounded but practically, I can limit it to 1000).I could also generate the numbers table with a function and a subquery but that feels even worse for performance (I know, I need to test it!). So I was thinking: perhaps there's a better way to approach this problem? I'm hoping for a happy medium between where I am now and merging the tables together.One more thing: I'm stuck on SQL Server 2000 :P.Update: Added PK table above to clarify what I was looking for. I also fixed the desired output. Sorry about that. Update: Complete solution:DECLARE @X AS TABLE (ID INT)DECLARE @A AS TABLE (ID INT, FKID INT, Value VARCHAR(10), Sort INT)DECLARE @B AS TABLE (ID INT, FKID INT, Value VARCHAR(10), Sort INT)INSERT INTO @X (ID) VALUES (1)INSERT INTO @X (ID) VALUES (2)INSERT INTO @A (ID, FKID, Value, Sort) VALUES (1, 1, 'a', 1)INSERT INTO @A (ID, FKID, Value, Sort) VALUES (2, 1, 'aa', 2)INSERT INTO @A (ID, FKID, Value, Sort) VALUES (3, 1, 'aaa', 3)INSERT INTO @A (ID, FKID, Value, Sort) VALUES (4, 2, 'aaaa', 1)INSERT INTO @A (ID, FKID, Value, Sort) VALUES (5, 2, 'aaaaa', 2)INSERT INTO @B (ID, FKID, Value, Sort) VALUES (1, 1, 'b', 1)INSERT INTO @B (ID, FKID, Value, Sort) VALUES (2, 1, 'bb', 2)INSERT INTO @B (ID, FKID, Value, Sort) VALUES (3, 2, 'bbb', 1)INSERT INTO @B (ID, FKID, Value, Sort) VALUES (4, 2, 'bbbb', 2)INSERT INTO @B (ID, FKID, Value, Sort) VALUES (5, 2, 'bbbbb', 3)SELECT * FROM @XSELECT * FROM @ASELECT * FROM @BSELECT COALESCE(A.FKID, B.FKID) ID ,A.Value ,B.Value ,COALESCE(A.Sort, B.Sort) SortFROM @X XLEFT JOIN @A A ON A.FKID = X.IDFULL OUTER JOIN @B B ON B.FKID = A.FKID AND B.Sort = A.Sort I have some ad-hoc reporting users hitting some SQL Server views. Occasionally the read locks taken by these users for particularly lengthy queries causes trouble elsewhere in the system. I am considering adding some strategic with(nolock) hints to the views but wanted to know if there are any gotchas associated with hints in views.Please ignore the obvious issues with letting users run queries this close to the SQL metal :).Also, I know that nolock hints are an advanced feature not to be used lightly and I am well aware that they introduce fun things like dirty reads. Finally, if you're thinking that read_committed_snapshot makes sense here, I must sadly say that it's not available for 2000. Here's my markup (live repro):&lt;body&gt; &lt;div style="text-align:center"&gt;header &lt;input class='datepicker'/&gt;&lt;/div&gt; &lt;table&gt;&lt;tr&gt;&lt;td&gt;really wide table.....................&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/body&gt;When the datepicker is activated, the header div's width changes from the width of the screen to the width of the table (larger). This causes the header's centered contents to shift to its new center...which is very annoying. This occurs in IE6 but not in FF3.5, IE8, or IE8-compat-mode.What's the best way to fix the width of the header div to the width of the window (not the content)?Note: there is probably a much simpler example than the datepicker--probably something that doesn't involve jQuery--that's just the trigger that hit me so I'm posting it that way. Here's an example that adds a dom element without triggering this problem. No simple combination of containers or CSS directives seemed to work for me. Here's what I ended up doing (I already have jquery in my stack):// set the header div's width in px on page load/window resize$(window).bind('load resize', function() { $('#header').css('width', $(window).width() - 20 /* scrollbars */);});This is a duct-tape solution for sure: it treats the symptoms more than the root cause...but it seems to work well enough that I can move on to better things.I'm confident a pure-css solution exists to this problem...if you have it, please post it! Given markup like this:&lt;body&gt; &lt;div style='text-align:center'&gt;header&lt;/div&gt; &lt;table&gt; &lt;tr&gt;&lt;td&gt; really_wide_table................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................ &lt;/td&gt;&lt;/tr&gt; &lt;/table&gt;&lt;/body&gt;How should it be rendered if the table is so wide that horizontal scrollbars are introduced?Should the header div be centered in the left-most visible screen, or centered above the table? Or something else?Note: I know what does happen, what I'm looking for is an official reference that defines what should happen (I ran into an issue). Suppose I'm using transactional replication to replicate articles from one server to another (both running SQL Server 2000). This is setup and working great.Then, I decide to add a new article. First, I add it to the publication via Publication Properties &gt; Articles &gt; Objects to Publish. Then, what do I do? It'd be nice if I could have the new article replicate without having to generate a new snapshot from scratch...and then wipe out the subscriber and rebuild it from scratch. That's an awful lot of work for just adding 1 table. I guess your looking for the break; statement, which will drop you out of a loop.$walk = 15for ( $counter = 1; $counter &lt;= $walk; $counter += 1) { .... if($walk_jail){ echo "$counter) &lt;span class='bad'&gt;$walk_txt&lt;/span&gt;&lt;br&gt;"; break; // ** this will drop out of the loop }elseif($walk_money){ echo "$counter) &lt;span class='win'&gt;$walk_txt&lt;/span&gt;&lt;br&gt;"; }elseif($walk_item){ echo "$counter) &lt;span class='win'&gt;$walk_txt&lt;/span&gt;&lt;br&gt;"; }elseif($walk_money == 0 &amp;&amp; $walk_jail == 0 &amp;&amp; $walk_hp == 0){ echo "$counter) $walk_txt&lt;br&gt;"; }} This is called a spin-wait and is not the best way to accomplish your task:// IsConversionComplete will be set by some other threadwhile(!IsConversionComplete){ Thread.Sleep(100);}// carry onA much more efficient solution requires a synchronization structure like a mutex or use of events. You should take advantage of the fall through of switch statements:switch ($foo) { case 3: case 5: bar(); break; case 2: apple(); break; }The PHP man page has some examples just like this. Every zip program I've ever used has this ability.7zip is my current favorite on windows. It has a nice command line version, too. It looks like the stat command might be in order. From the article: stat /etc/passwd File: `/etc/passwd' Size: 2911 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 324438 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2008-08-11 05:24:17.000000000 -0400 Modify: 2008-08-03 05:11:05.000000000 -0400 Change: 2008-08-03 05:11:05.000000000 -0400 I'm not convinced that this type of foolery is necessary but I'm not an extension dev so who knows. If this is the approach you want, then just have the setTimeout call refer to the same function:var index;firstfunction: function() { // do something with `index` and increment it when you're done // check again in a few seconds (`index` is persisted between calls to this) setTimeout("firstfunction", 5000);} That's a new one for me.Go to Tools > Import and Export Settings and export all your settings to a file for safe keeping. Then go in there again and reset everything. Report back if that helped. If it did, try importing your settings again to see what happens. I would call that hover...but I don't know if there's a standard or built in way to do it (sorry). Or for an OS9 throw back you could call it click and hold. This question screams for a screenshot. Are you seeing one of these?  Fiddler2 can do this very easily. Plus, it does so much more that is useful when doing development. That's as easy as IsNull(FieldName, 0)Or more completely:SELECT iar.Description, ISNULL(iai.Quantity,0) as Quantity, ISNULL(iai.Quantity * rpl.RegularPrice,0) as 'Retail', iar.Compliance FROM InventoryAdjustmentReason iarLEFT OUTER JOIN InventoryAdjustmentItem iai on (iar.Id = iai.InventoryAdjustmentReasonId)LEFT OUTER JOIN Item i on (i.Id = iai.ItemId)LEFT OUTER JOIN ReportPriceLookup rpl on (rpl.SkuNumber = i.SkuNo)WHERE iar.StoreUse = 'yes' eval will do that:var myText = 'hello world!!';var someString = eval('myText');document.getElementById('hello').innerHTML = someString;As demonstrated here. Put it in single quotes, with the escaping slash:grep -lire '\$DATA_PATH . \$AWARDS_YEAR' *Also note, that the dot (.) is a regex character. If you don't want it to be, escape it, too (or don't use the -e option).Here's a nice reference with more general info. You can cast the int? to an int or use a.Value:if (a.HasValue){ blah = DoSomething((int)a); // or without a cast as others noted: blah = DoSomething(a.Value);}If this is followed by an else that passes in a default value, you can handle that all in one line, too:// using coalesceblah = DoSomething(a?? 0 /* default value */);// or using ternaryblah = DoSomething(a.HasValue? a.Value : 0 /* default value */);// or (thanks @Guffa)blah = DoSomething(a.GetValueOrDefault(/* optional default val */)); Yes you should (when feasible). You should be able to take a fresh machine and build your project with as few steps as possible. For me, it's:Install IDE (e.g. Visual Studio)Install VCS (e.g. SVN)CheckoutBuildAnything more has to have very good justification.Here's an example: I have a project that uses Yahoo's YUI compressor to minify JS and CSS. The YUI .jar files go in source control into a tools directory alongside the project. The Java runtime however, does not--that has become a prereq for the project much like the IDE. Considering how popular JRE is, it seems like a reasonable requirement. If I understand you correctly, try this:$('#viewContainerTop &gt; [class^=row]').not('.row2').hide();The &gt; is optional--it excludes matching of any deeper objects that start with row.Here's a live example that shows this, too (hit refresh to see the selector dim the desired elements). You could check for the query token and redirect to the file if it matches:&lt;?php if(isset($_GET['token']) &amp;&amp; $_GET['token'] == 42){ header('Location: http://example.com/file.blah'); } else{ die('sorry!'); }?&gt;Please note that this is really week security by obscurity. It won't take much for a user to notice the redirect and hit the file directly. A better solution would require that you stream the file...as @Ciaran describes (thanks for posting it better and more clearly than I was just about to!). As @Ciran notes, this isn't very secure, either. If the file isn't very sensitive, it might be "good enough" to just have it expire after some period of time. You should create an array of actual buttons (not their names). Then when you grab a random button into a button object, it'll actually be a button so you can change it's text property.Since you're just passing around references to the actual buttons, this should work pretty well.Dim buttons(8) As Buttonbuttons(0) = tlbuttons(1) = tc''# ... Use the P format string. This will vary by culture:String.Format("Value: {0:P2}.", 0.8526) // formats as 85.26 % (varies by culture) If you want a date object, with class-controlled formatting, you need two properties:public DateTime DateField { get; set; }// a read only string public String DateFieldString { get { return DateField.ToString(/* your format */); } } You need to print out the max after you've scanned all of them:for (int counter = 1; counter &lt; decMax.length; counter++){ if (decMax[counter] &gt; max) { max = decMax[counter]; // not here: System.out.println("The highest maximum for the December is: " + max); }} System.out.println("The highest maximum for the December is: " + max); You need to update the destination table, not the logical table. You join with the logical table, though, to figure out which rows to update:UPDATE YourTableSET TheColumnToBeUpdated = ( SELECT TheValueCol FROM AnotherTable.ValueCol WHERE AnotherTable.ValudCol1 = INSERTED.ValueCol1 )FROM YourTable YJOIN Inserted I ON Y.Key = I.KeyWHERE I.ValueCol IS NULL Computed columns cannot reference other computed columns. Though you ought to be able to just repeat the expression you would like to reference. From MSDN: A computed column is computed from an expression that can use other columns in the same table. The expression can be a noncomputed column name, constant, function, and any combination of these connected by one or more operators. The expression cannot be a subquery. I should also add that if this were to work as you would hope, it would present all kinds of new issues you'd have to deal with. Presently, updates across many columns/rows occur in parallel and atomically. Therefore, it wouldn't make sense to use a computed column in your calculation because it wouldn't exactly have a value...yet. If anything, you'd be using an old, un-updated value.If you really wanted to avoid duplicating the expression, you could do this in a trigger, though I strongly urge you not do that. Triggers are no fun and should only be used by very savvy people in rare cases. If you have control over the serialized string, I strongly suggest you look into JSON. It's an awesome format for things like this. It's lightweight, easy to read, and portable. For example, from the link (note: the whitespace is not significant--this could all be on one line):[ [0, -1, 0], [1, 0, 0], [0, 0, 1]]JSON provides a clean and safe mechanism for encoding strings in there, too. Click through for a lot of examples. I don't have access to a SQL box right now (so this may be syntax-weak) and I'm not a huge fan of the db structure but this ought to get you going:SELECT team, SUM(win) AS wins, SUM(loss) AS lossesFROM (SELECT team1 AS team, CASE WHEN score1&gt;score2 THEN 1 END AS win, CASE WHEN score2&gt;score1 THEN 1 END AS loss FROM YourTable UNION ALL SELECT team2 AS team, CASE WHEN score2&gt;score1 THEN 1 END AS win, CASE WHEN score1&gt;score2 THEN 1 END AS loss FROM YourTable)GROUP BY teamAlso, this ignores ties.Note: I made this CW--please update if you can improve it A string is an immutable type. It has bad performance characteristics when performing lots of string manipulation like concatenation.Stringbuilders on the other hand overcome this weakness by keeping a growing buffer so that each concatenation is less likely to require a new string to be allocated.Since string builders add some overhead, they are only really necessary when some significant string work is to be done (e.g. in a loop). If your code is fast, don't worry about it. If it's not, use a profiler to see if this issue matters in your case.One final note: this answer really has nothing to do with ASP.NET--this is true of strings in all of .net and lots of other languages, too.  When you wrap an object or run a selector, you get a set or collection. So this would return a collection and then add another collection to it, and then perform jqueryfunction() to the combined set:$('someSelector').add('anotherSelector').jqueryfunction()This works with contexts, too. That is a combined date/time representation as defined by ISO8601. It often has a timezone/offset appended to it, e.g. 2008-09-18T00:00:00Z would denote UTC time. Try closing the .aspx page and opening it up again as per this answer. If that improves things at all (e.g. enable intellisense) but doesn't solve it, please post any new errors you get.You could also add the Public modifier to your Module or class definition. If you're using Modules, it really doesn't make sense to me that it would be required, but some discussion on this forum indicates that it might help. The web platform is specifically designed to prevent sites from writing arbitrary data to client machines. There are a few exceptions to this that you can explore:A plugin like Google Gears; or data store in HTML5 (not widely available) (easily lost)Cookies (easily lost)URL (limited by length, easily lost)Files (more conventional albeit clumsy)The web clearly operates better from a server. If you are hoping to deploy desktop installs, you can deploy a thick application that uses a lot of browser-based UI. That app could easily have access to the local system for files, etc. If a possibility, please comment. I think linking to Google's edge cache servers usually makes sense. Google is almost certainly going to have better up time than you and they are likely to be at least as responsive. Plus, there's the advantage that an incoming user has already cached jQuery from them so they don't have to download it at all.The only situation I can think of where I wouldn't do this would be for a site that was primarily used as in intranet, wherein the local copy would truly be local to most visitors (e.g. on the lan). As long as your predicate calculations do not include references to the columns of the table you're querying, your approach shouldn't matter either way (go for clarity).If you were to include something from Table1 in the calculation, though, I'd watch out for table scans or covering index scans as it may no longer be sargable.In any case, check (or post!) the execution plan to confirm. If you are using webforms, get a book. It's a very different approach to web development than anything else out there. It will hurt your head and you will write terrible code unless you either are trained on it or read a lot about it.If you are using a stateless model like MVC, the transition will be much smoother as it's closer to what you've already done. Use ALT and TITLE together. Put your nice, helpful text in the alt tag and then nothing in the title tag like so:&lt;img src="http://www.google.com/intl/en_ALL/images/logo.gif"o alt="Goooooooogle!" title="" /&gt; If ALT is no longer "valid" (is it?!), I suggest that any solution around this slight validation annoyance will be far worse than ignoring it. The two are almost completely unrelated. A database log is used to rollback transactions, recover from crashes, etc. All good things to ensure database consistency. It has updates/inserts/deletes in it--not really anything about intent or what your app is trying to do unless it directly affects data in the database.The application log on the other hand (with Log4Net) can be extremely useful when building and debugging your application. It is driven by you and should contain information that traces what your app is doing. This is something that can safely be turned off or reduced (by toggling the log level) when you no longer need it. You can make this a single UPDATE statement:UPDATE transactions SET transaction_name1 = Replace(transaction_name1,'''',''), transaction_name2 = Replace(transaction_name2,'''','') ... (and so on)That would likely improve the performance by something approaching a factor of 5.Edit:Since this is a one shot thing on a huge dataset (90MM rows), I suggest adding in a where clause and running it in batches.If your transactions have a primary key, partition the updates on that, doing maybe 500k at once.Do this in a loop with explicit transactions to keep your log use to a minimum:DECLARE @BaseID INT, @BatchSize INTSELECT @BaseID = MAX(YourKey), @BatchSize = 500000 FROM transactionsWHILE @BaseID &gt; 0 BEGIN PRINT 'Updating from ' + CAST(@BaseID AS VARCHAR(20)) -- perform update UPDATE transactions SET transaction_name1 = Replace(transaction_name1,'''',''), transaction_name2 = Replace(transaction_name2,'''','') -- ... (and so on) WHERE YourKey BETWEEN @BaseID - @BatchSize AND @BaseID SET @BaseID = @BaseID - @BatchSize - 1ENDAnother note:If the quotes must not appear in your data, you can create a check constraint to keep them out. It's a last ditch effort as any app attempting to put them in would need to handle a database exception, but it will keep your data clean. Something like this might do it:ALTER TABLE transactions ADD CONSTRAINT CK_NoQuotes CHECK( CHARINDEX('''',transaction_name1)=0 AND CHARINDEX('''',transaction_name2)=0 AND -- and so on... ) I have this sole route in my app:routes.MapRoute( "Default", "{controller}/{action}/{id}", new { controller = "Home", action = "Index", id = ""} );This works great for URLs like: /Blah/Index /Blah/Create /Blah/Details/5 I want to add text to that last one like SO does: /Blah/Details/5/Page-Title-Here-Or-WhateverSo my question is:What should my routes look like to accomplish this? (or if it doesn't have anything to do with routes...what do I do?)  Using .NET 4, how do I add custom properties to a document? I'm assuming it goes something like this:WordApp // an instance of Microsoft.Office.Interop.Word.Application .ActiveDocument .CustomDocumentProperties .Add...?I cannot seem to find documentation for this that applies to .NET4/interops v14. It took a lot of guessing (much more than 12 minutes worth, I'm embarrassed to say!) to figure this out:WordApp // an instance of Microsoft.Office.Interop.Word.Application .ActiveDocument .CustomDocumentProperties .Add(Name: "PropertyName", LinkToContent: false, Type: 4, Value: "PropertyValue");I couldn't find a decent enum for the types, so I dug the magic number "4" out of a forum post for string and it works...For casual browsers, this was tricky because CustomDocumentProperties is dynamic, so I get no Intellisense. And for some reason, I cannot find docs on this. I think most actions that normally require transactions can be reworked to occur without them.For example, the classic bank transfer. Suppose I want to move $100 from account A to B:Begin Transaction /Debit A, $100 /Credit B, $100Commit TransactionThis could be reworked as: /Transfer A, B, $100 In this way, the server might do this in two steps, but the action from the client is a single, atomic operation that makes logical sense.I'm sure there are lots of examples where it is more convenient to do an all or nothing set of operations (and I'm curious what people can come up with to address them), but I usually rework things in this way. I think you'll find a semaphore is an excellent fit for this.A semaphore will enable you to manage access to a resource (i.e. the threadpool) in a nice, thread safe manner.Note, though, that the threadpool is really for lightweight processing--not a lot of heavy lifting. If you're planning to do some real computationally intense things, you might consider some of the PFX (parallel framework extenstions?) in .NET, or managing your own worker threads. When building code like this:&lt;script type="text/javascript" src="&lt;%=ResolveUrl("~/js/js.js")%&gt;"&gt;&lt;/script&gt;or&lt;input type="image" src="&lt;%=ResolveUrl("~/img/submit.png")%&gt;" /&gt;Should I use Url.Content or ResolveUrl()? What's the difference? Is there anything wrong with checking so many things in this unit test?:ActualModel = ActualResult.AssertViewRendered() // check 1 .ForView("Index") // check 2 .WithViewData&lt;List&lt;Page&gt;&gt;(); // check 3CollectionAssert.AreEqual(Expected, ActualModel); // check 4The primary goals of this test are to verify the right view is returned (check 2) and it contains the right data (check 4).Would I gain anything by splitting this into multiple tests? I'm all about doing things right, but I'm not going to split things up if it doesn't have practical value.I'm pretty new to unit testing, so be gentle. That is IPv6. Your statement that IPv6 addresses have just 6 numbers is incorrect. Here's an IPv6 example next to your address:2a01 : e35 : 2f20 : f770 : 6c54 : 3ee8 : 67fb : df8 // you3ffe : 1900 : 4545 : 3 : 200 : f8ff : fe21 : 67cf // exampleTo the initiated (including me), IPv6 is very confusing. If you have this just once on your page, balalakshmi's answer will work. If you have more than one, go with this:$('.title').click(function() { $(this).next('.description').fadeOut(fadeTime);})Note the use of next, which looks at the next element at the same level in the dom,instead of find which looks for decedents.Finally, if the effect you are really trying to achieve is a toggle on title click, use slideToggle or one of the many fadeToggle plugins. Your queries look ok except the first one should be an inner join, not a left join. If you want to try something else, consider this:INSERT INTO matched_articles SELECT * FROM articles a INNER JOIN info i ON a.id = i.article_id WHERE i.tag_id = 5;INSERT INTO unmatched_articles SELECT * FROM articles a LEFT JOIN info i ON a.id = i.article_id AND a.id &lt;&gt; 5WHERE a.id IS NULLThat might be faster but really, what you have is probably ok if you only have to do it once. I think plotting those functions would be very helpful to understand what's going on. I want a regular expression to match valid input into a Tags input field with the following properties:1-5 tagsEach tag is 1-30 characters longValid tag characters are [a-zA-Z0-9-]input and tags can be separated by any amount of whitespaceFor example: Valid: tag1 tag2 tag3-with-dashes tag4-with-more-dashes tAaG5-with-MIXED-caseHere's what I have so far--it seems to work but I'm interested how it could be simplified or if it has any major flaws:\s*[a-zA-Z0-9-]{1,30}(\s+[a-zA-Z0-9-]{1,30}){0,4}\s*// that is: \s* // match all beginning whitespace[a-zA-Z0-9-]{1,30} // match the first tag(\s+[a-zA-Z0-9-]{1,30}){0,4} // match all subsequent tags\s* // match all ending whitespacePreprocessing the input to make the whitespace issue easier isn't an option (e.g. trimming or adding a space).If it matters, this will be used in javascript. Any suggestions would be appreciated, thanks! This isn't something that jQuery is generally helpful with--it works more at the node level than the text/html level. However, this might help (source):$('p:contains(&amp;)').each(function(){ $(this).html( $(this).html().replace('&amp;amp;','&lt;span class=\'fancy\'&gt;&amp;amp;&lt;/span&gt;') );});Obviously if you can restrict the initial search to something better than all paragraphs, it'd perform better. You should also test it to see if the :contains filter actually helps.It's not pretty but it seems to work. If you come up with a jQuery way of doing document.write(), it'll be bad for all the same reasons. You are better off just using document.write() if that's what you need, or better yet, manipulating an existing element or appending a new element somewhere in the DOM--that's what jQuery is good at. Add a :last to your selector like so (demo, source):$(function(){ $('a#add').click(function(){ $('#table &gt; tbody:last').append('&lt;tr&gt;&lt;td&gt;&lt;select&gt;&lt;option value ="one"&gt;one&lt;/option&gt;&lt;option value="two"&gt;two&lt;/option&gt;&lt;/select&gt;&lt;/td&gt;&lt;td&gt;&lt;input type="text"&gt;&lt;/input&gt;&lt;/td&gt;&lt;td&gt;&lt;input type="text"&gt;&lt;/input&gt;&lt;/td&gt;&lt;/tr&gt;'); return false; });});Since your headers are not part of tbody or thead, the browser automatically creates a tbody for them. Thus your rendered table has two tbodys. The better solution is to keep your current selector and put the header in a thead section like this:&lt;thead&gt;&lt;th&gt;Col 1&lt;/th&gt;&lt;th&gt;Col2&lt;/th&gt;&lt;th&gt;col3&lt;/th&gt;&lt;/thead&gt;Or just put it in the already existing tbody so the browser won't make a new one. Since you're using a fixed width column, it's already of size 5 (with whitespace). You need to trim it:DECLARE @table1 TABLE (col1 char(5))INSERT INTO @table1 (col1) VALUES ('12345')INSERT INTO @table1 (col1) VALUES ('1')SELECT RIGHT('00000'+RTRIM(col1),5) FROM @table1-- Output:-- 12345-- 00001Or use varchar instead:DECLARE @table2 TABLE (col1 varchar(5))INSERT INTO @table2 (col1) VALUES ('12345')INSERT INTO @table2 (col1) VALUES ('1')SELECT RIGHT('00000'+col1,5) FROM @table2-- Output:-- 12345-- 00001 This should help: UPLOAD_ERR_OK Value: 0; There is no error, the file uploaded with success. UPLOAD_ERR_INI_SIZE Value: 1; The uploaded file exceeds the upload_max_filesize directive in php.ini. UPLOAD_ERR_FORM_SIZE Value: 2; The uploaded file exceeds the MAX_FILE_SIZE directive that was specified in the HTML form. UPLOAD_ERR_PARTIAL Value: 3; The uploaded file was only partially uploaded. UPLOAD_ERR_NO_FILE Value: 4; No file was uploaded. UPLOAD_ERR_NO_TMP_DIR Value: 6; Missing a temporary folder. Introduced in PHP 4.3.10 and PHP 5.0.3. UPLOAD_ERR_CANT_WRITE Value: 7; Failed to write file to disk. Introduced in PHP 5.1.0. UPLOAD_ERR_EXTENSION Value: 8; A PHP extension stopped the file upload. PHP does not provide a way to ascertain which extension caused the file upload to stop; examining the list of loaded extensions with phpinfo() may help. Introduced in PHP 5.2.0.The gist of it is that when you are handling an uploaded file, you check the error value ($_FILES['userfile']['error']) to see the status of the file. The switch statement just breaks it down by checking the possible error codes that could be present. These are basically "hardwired". I don't actually see any jQuery .live() code. Regular events added with bind, click, etc. are not "live" events.In any case, all you need to do here is check the item that was passed into the event to see if it's the canvas:$('#canvas').click(function(e){ if($(this).is('#canvas')){ // it really was the canvas that was clicked! // could also check "e.currentTarget"--it's the same as "this" // do your thing and return false }} Your question is a little unclear to me. I'm assuming you have a collection of some object A and A has a collection property. If that's the case:Your solution is the most straightforward way so I'd go with that.You could use linq, but it won't really make this any faster or clearer. Something akin to this with SelectMany, which flattens many IEnumerables into one:foreach(var x in obj.SelectMany(z=&gt;z.b)) { } bullet-point is not a valid value for list-style. Instead, use one of these:none No markercircle The marker is a circledisc The marker is a filled circle. This is defaultsquare The marker is a squarearmenian The marker is traditional Armenian numberingdecimal The marker is a numberdecimal-leading-zero The marker is a number padded by initial zeros (01, 02, 03, etc.)georgian The marker is traditional Georgian numbering (an, ban, gan, etc.)lower-alpha The marker is lower-alpha (a, b, c, d, e, etc.)lower-greek The marker is lower-greek (alpha, beta, gamma, etc.)lower-latin The marker is lower-latin (a, b, c, d, e, etc.)lower-roman The marker is lower-roman (i, ii, iii, iv, v, etc.)upper-alpha The marker is upper-alpha (A, B, C, D, E, etc.) upper-latin The marker is upper-latin (A, B, C, D, E, etc.)upper-roman The marker is upper-roman (I, II, III, IV, V, etc.)inherit Specifies that the value of the list-style-type property should be inherited from the parent elementClick through to read more about this, including browser support ASP.NET will render TextBoxes as textareas (in your case, because it's multiline) or inputs. These are standard HTML fragments which are just plain text containers. You can style them, but you can't really linkify the contents of them.If you really just want to put the text of a link into a box, do this:// either from the server:txtOtherApps.Text = YourLinkString;// or from the client:&lt;script&gt; document.getElementById('&lt;%=txtOtherApps.ClientID%&gt;').value = YourJsLinkValue;&lt;/script&gt;If you want something to happen with the user clicks on the text area, you can add an onclick handler to it...but this would be weird. svnsync is an awesome way to do this. It lets you replay all the commits from one repo to another. What you're really doing here is mirroring. Once you're done with the sync, you can disable it and cutover to the new repo.Or keep both--one as a backup!If you can get a file up there somehow, the regular backup/restore process works well, too, and is fast. An understanding of fundamentals of algorithms (e.g. time complexity) and some knowledge about the metal is essential to designing/writing smells-good code.I would suggest, though, that just as important is education in modern abstractions and profiling. I feel that modern abstractions make me so much more productive than I would be without them that they are at least as important as good fundamentals, if not more so.An important element that lacked in my education was the use of profilers. When used routinely and correctly, profilers can help mitigate problems with poor fundamentals. This will iterate over each OL, but once at a time:// loop over each &lt;ol&gt;$('ol').each(function(olIndex){ // loop over each &lt;li&gt; within the given &lt;ol&gt; ("this") $(this).find('li').each(function(liIndex){ // do your &lt;li&gt; thing here with `liIndex` as your counter });});As for all that stuff in the middle, you might be able to improve it with some nicer selectors:$('ol').each(function(){ $(this).find('li') .filter(':lt(6)').addClass('column-1') // &lt;li&gt; 1-5 .filter(':first').addClass('reset').end().end() // &lt;li&gt; 1 .filter(':gt(5):lt(12)').addClass('column-2') // &lt;li&gt; 6-11 .filter(':first').addClass('reset').end().end() // &lt;li&gt; 6 .filter(':gt(11)').addClass('column-3') // &lt;li&gt; 12+ .filter(':first').addClass('reset'); // &lt;li&gt; 12});Of course if we're making columns here, maybe we should be getting these counts dynamically?$('ol').each(function(){ var $lis = $(this).find('li'); var len = $lis.size(); var colLen = Math.ceil(count / 3); // and so on with the filter stuff with }); Click on the file and open its properties (F4), then change its Build Action to "Content". This will cause it to be included whenever "Content" files are deployed. In this case, you may also want to consider enabling the Copy to Output Directory option (see below), which will copy the chosen files to the output folder. When copied, directory structure (if applicable) will be maintained, too. That loads all.css with a different query string so that if version 6637, for instance, is already cached on your machine, you'll get the new one (6638). Changing that number (in this case) will not give you a different file.This is just a cache trick so they can send the file down with no expiration (i.e. you never have to ask for it again), because when it does change, the "file name", changes.That said, you could make it so you load a different version based on the query string parameter. Doing so would be slightly non-trivial and akin to how you get different questions when you pass a different question ID to the URL of this page. It's good you're asking for help, please don't let what I'm about to say discourage you--keep working at it! There are a lot of issues with this, so I'll just toss out a few: this doesn't really do anything because it doesn't return anything (if $sql is global, it shouldn't be)en.wikipedia.org/wiki/SQL_injectionor die(...) wouldn't belong in a string builder like this--it's not going to handle SQL failures here since all it's testing for is if the given line succeeds. Use whatever form best describes your intent. Do not follow the single exit principle if things are this simple, though--it just makes it more confusing. The demo page gives some sample HTML that you can style against:&lt;div id="ui-datepicker-div" class="ui-datepicker ui-widget ui-widget-content ui-helper-clearfix ui-corner-all ui-helper-hidden-accessible"&gt; &lt;div class="ui-datepicker-header ui-widget-header ui-helper-clearfix ui-corner-all"&gt; &lt;a class="ui-datepicker-prev ui-corner-all"&gt;title="Prev"&gt;&lt;span class="ui-icon ui-icon-circle-triangle-w"&gt;Prev&lt;/span&gt;&lt;/a&gt; &lt;a class="ui-datepicker-next ui-corner-all" title="Next"&gt;&lt;span class="ui-icon ui-icon-circle-triangle-e"&gt;Next&lt;/span&gt;&lt;/a&gt; &lt;div class="ui-datepicker-title"&gt; &lt;span class="ui-datepicker-month"&gt;January&lt;/span&gt;&lt;span class="ui-datepicker-year"&gt;2009&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;table class="ui-datepicker-calendar"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th class="ui-datepicker-week-end"&gt;&lt;span title="Sunday"&gt;Su&lt;/span&gt;&lt;/th&gt; ... &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt;&lt;tr&gt; &lt;td class="ui-datepicker-week-end ui-datepicker-other-month "&gt; 1 &lt;/td&gt; ... &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;div class="ui-datepicker-buttonpane ui-widget-content"&gt; &lt;button type="button" class="ui-datepicker-current ui-state-default ui-priority-secondary ui-corner-all"&gt;Today&lt;/button&gt; &lt;button type="button" class="ui-datepicker-close ui-state-default ui-priority-primary ui-corner-all"&gt;Done&lt;/button&gt; &lt;/div&gt;&lt;/div&gt;Apply new styles to those classes after you import the stylesheet from Google and you'll be good to go. For example (just as an example--I have no idea if this would look good):.ui-datepicker-div { font-size: 75%; } Master pages are you best bet here. I would guess that once you get that in there, before long you'll find lots of other great things to put in there, too.There are other solutions, but they're not as easy (e.g. subclass page and inject scripts). Guessing at your HTML:// assumes you have links within a features div$('#features a').click(function() { $('#features-slides').cycle( // call `cycle` with the rel# of clicked item parseInt( // turn the attribute value into a number $(this).attr('rel') // retrieve the attribute value for clicked item ) ); return false; // don't follow the link});parseInt() is a builtin JS function. It just turns a string into a number. Use the "P" format, which is hopefully more aware of globalization:String.Format("{0:P4}", pos); // e.g. 1,000.0000%You ought to be able to use this format string directly in your Gridview, too, as others have suggested. Since it does the 100x calc for you, though, it should actually work :). Perhaps like this:&lt;asp:BoundField DataField="Db" DataFormatString="{0:P4}" /&gt; You're locking on different objects.If other parts of your code (or internal code) sync on SyncRoot, which they should, then you're breaking things (i.e. introducing threading bugs) by syncing on Me.You should definitely sync on SyncRoot--that's why it's there. This is not possible without wrapping it yourself.Probably the safest thing to do would be...not do this. If you're a thrill seeker, just undo the parts you want decoded after the encoding is complete.Something like this might be a naive way (i.e. my way) of doing it:encodeURIComponent(uri).replace('%A3','') I'm using TempDate["Message"] to show little update banners as the user does things on my site like this:[AcceptVerbs(HttpVerbs.Post), Authorize(Roles = "Admins")]public ActionResult Delete(int id){ _Repo.DeletePage(id); // soft-delete TempData["Message"] = "Page deleted!"; return RedirectToAction("Revisions", "Page", new { id = id });}Then in my master page I have this:&lt;%-- message box (show it only if it contains a message) --%&gt;&lt;% string Message = (TempData["Message"] ?? ViewData["Message"]) as string; if(!string.IsNullOrEmpty(Message)){ %&gt; &lt;div id="message"&gt;&lt;%:Message %&gt;&lt;/div&gt; &lt;% } TempData["Message"] = null; ViewData["Message"] = null; %&gt;I hit both TempData and ViewData because I read somewhere that TempData should be used for redirects and ViewData should be used otherwise.The issue is: often the message won't show up right away. Sometimes it takes a click or two to different parts of the site for the message to show up. It's very strange. Any ideas? I was recently asked to estimate how long it would take to build an enormous system just by looking at screen shot mockups. Mgmt was asking for a gut feel in under an hour without asking any questions.I listed out all the modules (pages, reports, big queries, etc.) that I could see and started giving them relative estimates. e.g.:Task 1: 8 unitsTask 2: 16 unitsTask 3: 4 unitsThen I added a bunch of modules we had already done for this customer along with the relative number of units and actual number of hours/days. This told me what my ratio of units to hours was so I could guess (more than estimate) how long the unknown tasks should take. For example, if I found that an 8 unit task took us 16 hours in the past (2 hours/unit), I'd estimate that the above tasks might take:Task 1: 8 units * 2 hours/unit = 16 hoursTask 2: 16 units * 2 hours/unit = 32 hoursTask 3: 4 units * 2 hours/unit = 8 hoursThis approach enabled me to methodically consider the work to be done and apply some structure around guessing how long it would take to implement.Of course I delivered my +/- guess with a generous disclaimer.Then, if you want a calendar schedule from this, estimate how many hours per week you will work on the project and see what you come up with. The pound sign # is used to prefix temporary tables and procedures. A single instance (#) refers to a temporary object that lives/dies with the current session while a double instance (##) is a global object. Try this:UPDATE Temp_LTGData LTGSource SET Col1 = L2.Col1, Col2 = L2.Col2, Col3 = L2.Col3FROM LTGSource L1JOIN LTGSource L2 ON L2.CORP_REG_NO IS NOT NULL AND L1.CUSTOMER_NUMBER = L2.CUSTOMER_NUMBERWHERE L1.CORP_REG_NO IS NULL That should do it for you. You're joining the updateable table to itself so you can have access to both the old row and the new row for the update. This way, you can update multiple columns at once.  Find your rogue connection with the activity monitor and kill it. Or if it's an emergency, just recycle the SQL Server service. The routes you register in your global.asax.cs file are only initialized when the application starts up. This part of execution has nothing to do with an incoming request other than the fact that an incoming request will cause an unstarted application to be started. Subsequent requests will hit the already running application (assuming it hasn't been recycled or stopped) so it won't need to reinitialize the routes.If you want to determine what routes are being used to serve a request, this is not the place for a breakpoint (I'm not sure what it, sorry). // you don't need to test if it exists first$('div.homeBox &gt; div').remove()$('div.homeBox').append(data.loadPage);// if you want to do it in one go, this less clear option should work, too:// .end() moves back up the stack to undo the last filter operation (.children())$('div.homeBox').children('div').remove().end().append(data.loadPage);// if you want to get rid of everything within homebox, this is even easier:$('div.homeBox').empty().append(data.loadPage); All of these:if (user_name != pattern){ ...Should be more like this:if (pattern.test(user_name)){ ... In MS Access, I have a simple data entry form. At the bottom of the screen, you can step through the records and doing so updates the form with each click:&nbsp;&nbsp;&nbsp;&nbsp; access previous next bar http://a.yfrog.com/img62/2654/5ge.pngHow can I do that from a combobox on my form? That is, I want to be able to quick-pick an item from a list and have the form show that item. This is possible. If you're running into issues with that, please post specific errors or questions! You need to wrap the entire conditional statement in parans:if ( (blah) || (blah) ) ^ ^{ // as you were} Rather than add/remove the events each time with die(), I'd just create a toggle flag:var Toggle = false;$("#filterZaal").live("change", function(){ if(Toggle){ interceptZaalFilter(); } // alterantively, add this check Toggle = !Toggle; // to the func you call});// and so onThis seems to better capture what you want, and will almost certainly be more efficient. &lt;input type='submit'&gt; creates a button that submits a form to a server and triggers your server code. If you want the button hidden when the page comes back, you need to add logic to your page to do that. How you do this will depend on your server technology (php, .net, etc.).The reason the behavior with &lt;button&gt; is different is that &lt;button&gt;s don't submit the form (unless you add more code to make them do that)...so the above mentioned stuff never happens. It's not so much that a &lt;button&gt; stays hidden as much as the page never changes/reloads. If you added code to the &lt;button&gt; to make it refresh the page, it'd reappear, too. A few reasons:Generating SSL content takes some extra work so performance of a busy site could be an issueMost (all?) browsers stop sending referrer info with requests to tracking users through your site could be more challengingYou might have to be more deliberate in how you serve pages to get browsers to cache them properlyIf the page is SSL, all content loaded on the page should be SSL, too, to avoid mixed-content warnings in the browser; serving dependencies like scripts, images, etc. under SSL is not always convenientNote, however, that a lot of sites do do this. For example, several of the banks I use are always https, even for the parts that don't require it. (updated with KeithS's clarification that they aren't read until first used)They will be read the first time they are used, and then retained until the AppDomain is stopped or recycled, which is probably what you want.That is, ASP.NET apps run inside an AppDomain. This is how they are resident and available to multiple requests without having to startup for each individual request. You can configure how long they live and when they recycle, etc. Static variables live and die with the app and thus will survive as long as the app is resident in the app domain. Add this to the &lt;head&gt; section of the popup page:&lt;base target=_self&gt;This is a common ASP.NET issue, not specific to MVC. I suggest adding a parameter on the link you give to Google. i.e. instead of yoursite.com/landing, do yoursite.com/landing?campaign=12.If you are concerned that curious users will play with this parameter, the fix is simple-- redirect via a server 301 redirect when they hit that URL. That is, if I request yoursite.com/landing?campaign=12, your server--before serving a page-- should log my visit to campaign 12 and redirect me to the plain url yoursite.com/landing. This has the added advantage that reloads won't increment your campaign hit count.Yes, users could still mess with the original link if they are clever or curious enough to look at it before they click on it, but I think this is going to be far more effective than sniffing the referer. The producer/consumer pattern is pretty helpful for situations like this. I explained it a bit more over here.That said, if your situation is really that straightforward, simpler techniques may be more appropriate, like partitioning the data evenly.Also, I assume that you're not expecting to see a 100x speedup as your HW surely wouldn't support that...Of course if I've completely misunderstood and you actually want to process each string 100x (i.e. each script does something different), then please clarify. I don't think that rule alone will solve this problem for you. It probably doesn't rewrite links in pages that are sent to users. The article you linked to suggests that you do this "together with the IIS Application Request Routing module". It's the routing module that actually changes links within files sent to the client. I dug into the source for jQModal and it looks like it's just using jQuery's .load internally. Since you can append a selector to the URL to extract a piece of the page to display, you should be able to simply do this:$('#dialog').jqm({ajax: 'ajax-url #desired-box-selector',modal:true, trigger: 'a.trigger'});The downside is, of course, unless you modify jqModal, you won't be able to use the @href shortcut because it likely won't preserve the added selector. Getting around that is pretty straightforward, though. That works for me (Chrome9 on Win7). What browser are you using? Maybe post more of your code? Something like this:$('.checklist a').click(function(){ $(this).closest('li') // get current LI .removeClass('transparent') .addClass('opaque') .siblings() // get adjacent LIs .removeClass('opaque') .addClass('transparent');}); You're missing two ]s:function Populate() { $('input[name=WindowHeight]').val($(window).height()); $('input[name=WindowWidth]').val($(window).width()); $('input[name=DocumentHeight]').val($(document).height()); // --^ $('input[name=DocumentWidth]').val($(document).width()); // --^} jQuery selectors work on sets of elements. You need to refine the selector in your click event handler so it only works on the one desired element. Something (approximately) like this should work:$('.alternatepayee-checkbox').click(function() { // 'this' refers to the single checkbox div that was actually clicked // next looks for the next sibling that matches '.alternatepayee-b' $(this).next('.alternatepayee-b').slideToggle("slow");});What you use for .next will vary depending on your markup but that's the general idea.Also, if you are adding these dynamically, you can use .live('click', ...) instead to automatically bind your event handler to elements added after your page loads. Are you missing &lt;script&gt; tags, and, you know, jQuery? Also, since this is a cross-site request, make sure you're actually handling this as jsonp correctly.Without posting your actual code I think that's the best we can do. If the problem is that clicking one registration's checkbox changes all the registrations, you just need to scope your selectors better. For example, imagine that each registration looks something like this:&lt;div class='registration'&gt; ... a bunch of stuff &lt;input type='checkbox' class='blah' /&gt; &lt;/div&gt;Now you have a handler like this to capture clicks on those checkboxes:$('.registration input[type=checkbox]').live('change', function(){ // figure out which checkbox was checked and whatever // but only affect the registration that holds the checkbox: var AffectedRegistration = $(this).closest('.registration'); // do something smart with the affected registration...});Note: if you post your actual code here you might get more tailored help, but I think this will get you going. Your selectors are wrong. Instead of using this:$('ul[class=listItem_drop] li').dblclick( function () Use this:$('ul.listItem_drop li').dblclick( function () The difference here is that your first selector is looking for an element with that exact value for the class attribute, and no other classes. The far, far more common way to test for a class, the .classname selector, is what you want here. But you ask, what other classes? Well, when you work with jQueryUI, it adds classes to keep track of some internal things. This is evident in the inspector:(Updated fiddle.) Your methods should be private unless they need to be public for your application, not your test. Generally you shouldn't make things public just to support unit testing (internal might help there). And in that case, you should generally still be testing public interfaces, not private details of the class, which are much more likely to change and break your test.If you have access to a copy, Roy Osherove's "The Art Of Unit Testing" addresses this issue pretty well I'd probably just check to see if the element can reach the body element:$j.closest('body').size()&gt;0As you noted in other comments, this would fail in some exceptional cases where you are handling extra body elements. If you really want to detect those situations, I guess you could check to see if you have multiple $(body) elements but I suspect that such extreme cases will get out of control pretty quickly.This "is-probably-attached-to-page" check could be turned in to a bona-fide jQuery selector, too:$.expr[':'].isProbablyAttached = function(obj){ return $(obj).closest('body').size()&gt;0;};// Usage:$('.someClasses:isProbablyAttached').doSomething(); If you can define what the ordering should be, then I would do it like this (I chose to order by key):Dictionary&lt;string, string&gt; inputs = new Dictionary&lt;string, string&gt;(3){ { "A", "First" }, { "Z", "Third" }, { "J", "Second" }};var outputs = inputs.OrderBy(i=&gt;i.Key).Select(i=&gt;i.Value).ToArray();// output// String [] (3 items):First SecondThirdThis gives you an array with the indices that you asked for (e.g. output[0]).If you really want dictionary entries back, you can get an ienumerable of them like this (you can't just return a dictionary because they're unordered):var outputs = inputs.OrderBy(i=&gt;i.Key).Select( (entry, index) =&gt; new KeyValuePair&lt;int, string&gt;(index, entry.Value));Throw a .ToArray() on there if you need to.If you really want a dictionary back, try this:var outputs = inputs.OrderBy(i=&gt;i.Key) .Select((entry, i) =&gt; new { entry.Value, i }) .ToDictionary(pair=&gt;pair.i, pair=&gt;pair.Value).Dump();Just keep in mind that dictionaries are not inherently ordered so if you enumerate over it, you should add a .OrderBy again. If I understand you correctly, you want to have something that vaguely operates like a tabbed interface, with each tab being loaded via ajax and displayed with animation.You can certainly do something plain with plugins like jqueryui, but for something that fits the style of your site, I'd go full custom. Start with this to load the content and then do something with it:$.ajax('Skills.aspx', { dataType: 'html' success: function(data){ $('#container') // something to hold your content .slideUp(400, function(){ // hide existing content $(this).empty() // and remove it .append(data) // append new content .slideDown(); // and show it }); }});Again, that's just to get you started. If the content is lightweight, you could load it all from the server and skip the AJAX stuff altogether. If you want to do something the first time the logo is clicked, you can do this:var hjkl = $("#mainimage").height();var hjklw = $("#mainimage").width();$('#logo') .one('click', function(){ /* your one-time stuff */ $("#mainimage").css({ 'max-height':'','max-width':''}); }) .toggle( function() { $('#mainimage').animate({"width": 1600, "height": 1200}, "fast"); }, function() { $('#mainimage').animate({"width": hjklw, "height": hjkl}, "fast"); });It might be easier to apply your one-time styles with a class, and then remove them with .removeClass in the one-time section. To get all related divs, do this:var $YourDivs = $('.myDiv').filter(function(){ return $(this).height() &gt; 50; });Then you need to append something to each of them like this:// since we're passing in a set, jquery will clone '.icon-collase' for you$('.icon_collase').appendTo($YourDivs);Then add the class toggle function to all the collapse icons:$(".icon_collase").click(function() { $(this).closest('.myDiv').toggleClass('icon_collase icon_expand')}); From the docs: tabsselect This event is triggered when clicking a tab.// Supply a callback function to handle the select event as an init option.$( ".selector" ).tabs({ select: function(event, ui) { ... }});// Bind to the select event by type: tabsselect.$( ".selector" ).bind( "tabsselect", function(event, ui) { ...});Note: if you want to run a function after the tab has loaded (especially if it's a remote tab), you probably want the load/tabsload event instead. The format strings are culture/locale dependent so it may be using the settings from your server (e.g. 24 hour time). Try this:@Model.ReportDate.ToString("hh:mm tt", System.Globalization.CultureInfo.InvariantCulture)If this (or something similar) solves your problem, I suggest setting the desired culture in global.asax so your entire app uses the culture you expect. Maybe you need to change $(xml) to $(this) inside your loop?And fixup the append code (you only have one list, right? if so, remove the .eq stuff) like this:var $list = $('#set1').find('ul');$(xml).find('section1').each(function () { var myLink = $(this).find('link').text(); $list.append("&lt;li&gt;"+myLink+"&lt;/li&gt;");});If that works, you might be able to simplify it down to this:var $list = $('#set1').find('ul');$(xml).find('section1 link').each(function () { var myLink = $(this).text(); $list.append("&lt;li&gt;"+myLink+"&lt;/li&gt;");});And perhaps even further using $.map Since you want to include everything except a few particular types, try this:$('input:not([type=image],[type=button],[type=submit])') Try this more explicit version (fiddle):var list = $("&lt;ul/&gt;"); var listitem = null;// iterate over each cell (not each row)$('#tab1').find("tr &gt; td").each(function(i) { // starting with the first item, start a new listitem every three items // and append it to the ul if(i%3 == 0){ listitem = $("&lt;li/&gt;"); list.append(listitem); } // append the current item as a paragraph to the listitem var p = "&lt;p&gt;" + $(this).html() + "&lt;/p&gt;"; listitem.append(p);}); // replace the table with the ul$('#tab1').replaceWith(list);  Presumably your boxed page could check for a container. On the demo site, the container has the id TB_window. So in that example, you could do something like this:if( $('selector-for-stuff-that-might-be-boxed').closest('#TB_window').size() ){ // you're probably in a box}Note: if the point of this is to apply different styles to the boxed content, you can do that with just regular CSS by adding that ID to the CSS selector:/* applies to non-boxed content */.my-style { /*...*/ }/* applies to boxed content */#TB_window .my-style { /*...*/ } In your case you can wrap el and traverse from it, like this:$(el).find('.something-else').blah(); // ...el is not a string, it's a DOM element. Some of your confusion might stem from writing $(el).html(). If you were debugging with that, it'd look like a string because you were extracting the actual HTML held within the DOM element you had in hand.  Have you tried using an accessor?:string val = YourPanel.Attributes["Text"];// ^ that's your attribute nameThat should get the attribute's value BUT I'm pretty sure what you are doing isn't possible as attribute values are not persisted between postbacks (at least not when set via a client script). To do that you should use hidden inputs or some other form element. Try is which tests if anything in the given set matches another selector:if( $('#mydiv').is('div') ){ // it's a div}You can also get the tag this way:$('#mydiv').get(0).tagName // yields: 'DIV' This gets messy pretty quick, but here's a start:ISNULL(address,'') + ' ' + ISNULL(address2,'') + ' ' + ISNULL(city,'') + ' ' + ISNULL(state,'') + ' ' + ISNULL(zip,'')(If isnull doesn't work, you can try coalesce. If neither work, share what DMBS you're using.) Generally speaking you should use the same type throughout your layers. So if the underlying types in the database are x, you should pass around those data with identical types in c#, too.What type you choose depends on what you are storing--you shouldn't be switching around types just to get something to "work". To that end, storing numeric data in a non-numeric type (e.g. varchar) will come back to bite you very soon. It's good you've opened this question to fix that!As others have miraculously inferred, you are likely running into a localization issue. This is a great example of why storing numbers as strings is a problem. If you properly accept user input in whatever culture/localization they want (or you want), and get it into a numeric-type variable, then the rest (talking to the DB) should be easy. More so, you should not do number formatting in the database if you can help it--that stuff is much better placed at the front end, closer to the users. Structure your delete like this:DELETE UFROM U ...JOIN Q ...WHERE Foo ...Or, if you already have a spiffy query in hand, you can do this:DELETE Usertable WHERE userId IN ( SELECT UserID FROM ... /* big complex query here */) Try this:SELECT (Select count(*) FROM tbl_Events) + (Select count(*) FROM tbl_Events2)Or (tested in MSSQL), this:SELECT COUNT(*) FROM (SELECT * FROM tbl_Events UNION ALL SELECT * FROM tbl_Events2) AS AllEventsI'd guess the first will lead to better performance because it has more obvious index options. Test to be sure, though. No, this isn't possible. Imagine how crazy things would be if this was possible.If you want something specific skipped in the Child case, consider reworking your design to better represent what you need (e.g. maybe you need to override something else in the Child class, too). Or, you could provide another Foo() in the Parent class that doesn't do anything except call its base.Foo(). The comment is true. Without ref or out, the variable is passed by value. However, with objects, what you are passing by value is a reference.The only time you would want to pass an object-reference by reference is if you are assigning a new object to the parameter within the method and you want that reassignment to affect the caller's copy of the reference.You aren't ever really passing an object around. Instead you are passing around references to an object. With that in mind, this byval/byref business applies to the object-reference, not the object itself.Jon Skeet has a great post about this topic. You need to set the background color to something:#b { background-color: #fff }Updated fiddle Try this: html:&lt;div id='a'&gt; &lt;div id='b'&gt;&lt;/div&gt;&lt;/div&gt;css:#a, html, body{ height: 100%;}#a { width: 300px; background-color: #dde; border: 1px solid #99c; position:relative; overflow: hidden}#b { width: 50px; height: 50px; background-color: #99c; border: 1px solid #54a; position: absolute; bottom: -25px; left: 125px;}You'll need to actually add the bg image to b. If I have this in hand:R.drawable.fooWhich is really just a reference to a jpg file, how do I open it in Android's gallery app?I have found a bunch of references which suggest something along the lines of this:startActivity( new Intent( Intent.ACTION_VIEW, /* what goes here for the URI?? */ )); But what URI do I use?I'm doing this tutorial and want to open the images in the native Android app when tapped so I can get all that zooming, sharing, etc. for free.If I can't use a URI here (as suggested here), what should I do to load the image? I'm using this command to build and deploy my site:MSBuild myprj.sln /P:Configuration=Debug /P:DeployOnBuild=True /P:MsDeployServiceUrl=http://myserver/MsDeployAgentService /P:MSDeployPublishMethod=RemoteAgent /P:DeployTarget=MSDeployPublish /P:UserName=foo /P:Password=bar /P:DeployIisAppPath="Default Web Site\MyApp" It works great, except I think I want to exclude a certain data file, say, ~/App_Data/data.xml. I don't want data.xml in my project since it's generated by the app or setup by the user (e.g. by renaming and configuring data.xml.orig to data.xml). So what to do? Can I simply exclude it from MSDeploy or should I be handling this another way? Remove those ending &lt;br/&gt;s from your &lt;li&gt;s. They shouldn't be there.&lt;div id="prof_div"&gt;&lt;ul&gt; &lt;li&gt;&lt;a href="#prof_home"&gt;Profile&lt;/a&gt;&lt;/li&gt;&lt;br/&gt; &lt;li&gt;&lt;a href="#prof_details"&gt;Details&lt;/a&gt;&lt;/li&gt;&lt;br/&gt; &lt;li&gt;&lt;a href="#prof_settings"&gt;Settings&lt;/a&gt;&lt;/li&gt;&lt;br/&gt;&lt;/ul&gt;Here's a fiddle. As the highlighter probably helped you figure out, your first &lt;div&gt; tag isn't complete. Errors like this are easier to see in an editor that does syntax highlighting, and are often reported in Chrome's console (in the developer tools). Can you pass in the full path?@Html.Partial("~/Views/Projects/_NotesPartial.cshtml") Try thisif ( // get all the keys between 65-90 (e.keyCode &gt;= 65 &amp;&amp; e.keyCode &lt;= 90) // or 44 or 47 || e.keyCode == 44 || e.keyCode == 47){ // do stuff}If the conditional logic is tripping you up, I think you might be best served by thinking about the numbers you want to include (not exclude). Break them into ranges and put each range on its own line. Start with pseudo code:if // keys between 31-47 // or keys between 58-90then // do stuffendThen fill in the conditions:if ( // keys between 31-47 (e.keyCode &gt;= 31 &amp;&amp; e.keyCode &lt;= 47) // or keys between 58-90 || (e.keyCode &gt;= 58 &amp;&amp; e.keyCode &lt;= 90) ){ // do stuff} You are using .closest(), which wasn't added to jQuery until 1.3. See the docs for more info.If you really need to maintain support for the very old jq1.2.6, you might be able to shim in .parents() instead. Start with this:$('#your-image-selector').attr('src', 'product_color_finish_or_whatever.jpg');Or, clarify a bit what you need and you'll get more specific help.Entering guess mode. You hinted at something more conventions based. Suppose you had the following markup, possibly generated by a script:&lt;div id="pickers"&gt; &lt;select id="color"&gt; &lt;option value="blue"&gt; &lt;/select&gt; &lt;img id="color-swatch"/&gt; &lt;select id="finish"&gt; &lt;option value="blue"&gt; &lt;/select&gt; &lt;img id="finish-swatch"/&gt; &lt;select id="highlights"&gt; &lt;option value="blue"&gt; &lt;/select&gt; &lt;img id="highlights-swatch"/&gt;You could drive the img src tags with this:$('#pickers &gt; select').bind('load change', function(){ $(this).next().attr('src', 'Product_' + $(this).val() + '.jpg');});That doesn't require any specific classes or IDs on anything--just that the selects be next to the imgs and that the img filename include the value from the picker.What's that? You don't want your images adjacent to the pickers? OK then, link the two together with the id convention of picker-id whatever and related image-id of whatever--swatch. Then this code will work:$('#pickers &gt; select').bind('load change', function(){ $('#' + $(this).attr('id') + '-swatch') .attr('src', 'Product_' + $(this).val() + '.jpg');});This should use that convention to find the image and update its src.None of these code samples has been tested but they should inspire something that works. Two things:There's no selector :all and you can't use colons in IDs--take that outIDs must be unique. You can't have 2 or more elements with the same ID.You'll need to use another strategy for finding all the checkboxes. Something like this:$('input:checkbox').click( /* ... */ );Or add a class to all the checkboxes and do this:$('input.yourclass:checkbox').click( /* ... */ );If you want to click on a link and have that check all the boxes, try this:// check on all the checks$('#all-link-id').click(function(){ $('input.yourclass:checkbox').attr('checked', true);});// check off all the checks$('#none-link-id').click(function(){ $('input.yourclass:checkbox').removeAttr('checked');}); If you want to grab the HTML code of your DOM elements, you can use innerHTML. See this fiddle for an example:HTML:&lt;div id='div1'&gt; &lt;p&gt;A Paragraph!&lt;/p&gt; &lt;br/&gt; &lt;p&gt;Another p&lt;/p&gt;&lt;/div&gt;&lt;button id='go'&gt;Get HTML&lt;/button&gt;JSdocument.getElementById('go').onclick = function(){ alert(document.getElementById('div1').innerHTML);}; You can't (and shouldn't) block processing with a sleep function. However, you can use setTimeout to kick off a function after a delay:setTimeout(function(){alert("hi")}, 1000);Depending on your needs, setInterval might be useful, too. Here it is in razor:@{ // you can inline this instead var Param = Url.Encode(Url.Action("action", "controller", new{ /*params*/ }); ^^^^^ // or for the current page's URL (hat tip @Dismissile) Param = Url.Encode(Request.Url.ToString());}&lt;a class="facebook" rel="nofollow" target="_blank" href="http://www.facebook.com/sharer.php?u=@Param"&gt;some_title&lt;/a&gt; ^^^^^^If you're not using Razor, it looks like this (or at least close to this):&lt;% // you can inline this instead var Param = Url.Encode(Url.Action("action", "controller", new{ /*params*/ }); ^^^^^ // or for the current page's URL (hat tip @Dismissile) Param = Url.Encode(Request.Url.ToString());%&gt;&lt;a class="facebook" rel="nofollow" target="_blank" href="http://www.facebook.com/sharer.php?u=&lt;%=Param%&gt;"&gt;some_title&lt;/a&gt; ^^^^^^ Sorting 10000 elements isn't nearly enough to effectively evaluate an algorithm. Go bigger.Also, is the input random? Post your implementation of GetFilledListAND you need to unsort elements before doing insertion sort (or just re-initialize elements). If you flip the order in which you do the sorts, what happens? I'm guessing that you are doing all the work in mergesort, and then insertion sort is merely sorting an already sorted list, which it's actually very good at (O(n), assuming a sane implementation). Being a stateless platform, every time the page loads you need to rebind things like this. Here's the pattern I use to make it easier, though:If this is common across an area of your site, put this type of stuff into an init function in the common file. e.g. global.js:function InitSalesPageOrWhatever(){ $(function(){ foo; }); OtherStuffThatRunsOnEverySalesPageLoad();}Then in the script block on your pages, e.g. SalesPage:InitSalesPageOrWhatever();That's it--just one line in your content pages. Beyond the benefit of the content pages being nice and clean, that big clump of JS can now be cached by the user's browser, making the load on you less and their experience faster. I was seeing this same error. It drove me nuts but I finally figured it out. My issue had nothing to do with web.config, assemblies, Initialize_42 or Initialize(false) hacks or anything. Here's where I went wrong...I had enabled automatic application of migrations like this:App_Start:Database.SetInitializer( new MigrateDatabaseToLatestVersion&lt;DataContext, Migrations.Configuration&gt;());Migrations/Configuration.cs:internal sealed class Configuration : DbMigrationsConfiguration&lt;Path.To.DataContext&gt;{ public Configuration() { AutomaticMigrationsEnabled = true; }}And that was being triggered via WebActivator like this:[assembly: WebActivator.PreApplicationStartMethod( typeof(service_tracker_mvc.App_Start.DatabaseInitializer), "Start")]I accidentally found that disabling this process resulted in the profiler working. The issue, as it happens, is that this init process was happening too soon. It normally happens during Application_Start (if you're not using this fancy WebActivator stuff) so I changed it to PostStart. Now it works: [assembly: WebActivator.PostApplicationStartMethod( typeof(service_tracker_mvc.App_Start.DatabaseInitializer), "Start")] Yes, you should be using a helper for these. This will ensure that your generated links use the appropriate routes, which will make your life much easier in the future if you do anything fancy with your URLs or deploy to a non-root path (i.e. /)In your case, the easiest solution is to replace the URL with @Url.Action. I'd use that over Html.ActionLink because Html.ActionLink doesn't let you easily linkify content more complicated than simple text (e.g. your html).&lt;a href="@Url.Action("Index", "Interfaces")"&gt; &lt;div id="homeInterfaces" class="homeLinks"&gt; &lt;h1&gt;Interfaces&lt;/h1&gt; &lt;h2&gt;Create, Edit or Delete Interfaces&lt;/h2&gt; &lt;/div&gt;&lt;/a&gt;If you're not using Razor, go switch to that first. It's worth it. Or drop the @ sign and add some &lt;%= ... %&gt;.As @MichalFran notes, though, if it's working now, you can always just start following this advice in the future and revisit what you've already done when/if you need to down the road. Sterling Web Forms is a web-based messaging system for large companies to send invoices/orders/notices/etc. to vendors from their ERP systems.I have an app that would benefit from accessing the messages sent to me programmatically. Assuming there's an API for interfacing with it, where is this publicly documented?I get the sense that this exists but I'm not searching with the right Enterprise-y terminology or product names... The issue is that the 100%-sized map container is originally bounded by the window as the root element. But when you nest it inside another div, it's now bounded by that div, which is much smaller (ie 0). You need to make the outer div bigger, too:#a, #map_canvas { height: 100% ; width:100%;}^^^ It appears that Entity Framework supports your requirements. It can definitely connect to both of your providers. It looks like you can use stored procs, too, but that's a little fuzzy.I believe the only "switch" you flip is in the .config file (no rebuild).As an aside in case it's relevant, the new EF Code First + Migrations bits are pretty neat. I've been using them with SQL Server locally for development and a SQL Server cloud host for production. I've been very happy with them. You need to include the controller name in your action link:@Html.ActionLink("Dashboard","Index","DashBoard")If you leave out the controllerName, then the links will be constructed with the current controller. Since you navigated to the AccountController, the link that was supposed to point to the DashboardController broke.In shared areas (like navigation), you'll usually want to include the controller reference. Before you start animating, you should call .stop(true) to interrupt any ongoing and queued animations. Then reset your elements like you do now and start the new animation.In case it's helpful, .stop(true, true) would simply jump to the end of the animation rather than leaving elements in between their start/stop positions. This property is additive to what the font would normally use. So, 1px will increase it by a pixel. Sitepoint calls it "extra" space (with negative values allowed).The W3C docs say the same thing: "This value indicates inter-character space in addition to the default space between characters. Values may be negative..." You have a lot of the right keywords, but they aren't wired up quite right. The .attr() getter isn't chainable, for example.This gets all links that have a title and adds the click handler to them:$('a[title]').on('click', function(){ $('#myTextBox').val( $(this).attr('title') ); // ^^ this returns a string and passes it to .val()});When clicked, the textbox's value will be replaced with the link's title attribute's value.This could be a little more verbose. If you are new, I suggest writing things more like this initially as it makes things much easier to debug. Once you're more comfortable with the jQuery way of doing things, the denser, chained approach will be more natural.$('a[title]').on('click', function(){ var $link = $(this); var titleText = $link.attr('title'); var $textbox = $('#myTextBox'); $textbox.val(titleText);}); If your form-related JS is in the file signupValidation.js, you need to move the script call that includes that file to be after the jquery include.I'd probably clean up the form code a tiny bit, too:$('form#signup').on('submit', function(event){ event.preventDefault(); var $input = $(this).find('[name=username]'); console.log($input.val()); alert($input.val());})You might be interested in looking at .serialize(), too. You can't call stored procedures within an existing select statement. What you want is user defined scalar function (as opposed to a table function or built in function).Depending on what you're really trying to do, a user defined table function could apply. In that case, you'd make a function that returns a table and then you could join to it. They're a bit like views but accept parameters. You can add an attribute selector to get the form you want:$('form[name="foo"]')... I see examples all over the net of people setting up their custom model binders like this:// global.asaxprotected void Application_Start(){ ModelBinders.Binders.Add(typeof(YourModel), new YourBinder());}But when I try that, it doesn't compile (.Binders isn't found). What gives? It turns out this was just a naming conflict because I had put my custom model binder in a folder/namespace called "ModelBinders". You can fix this one of two ways:Rename the namespace/folder to something else, e.g. CustomModelBindersUse a fully qualified reference to the ModelBinders like this:System.Web.Mvc.ModelBinders.Binders.Add( /* ... */ ); I think you want something like this:RewriteRule ^TestDirectory/(\w+\.\w+)$ foo.aspx?u=$1 [R]The regex \w+\.\w+ matches a word, a dot, and another word. The $1 is replaced with the captured string from the regex. The [R] means to actually redirect the user.These rules are tough to get just right so I recommend reading through some examples. Elmah is perfect for this:  Logging of nearly all unhandled exceptions. A web page to remotely view the entire log of recoded exceptions. A web page to remotely view the full details of any one logged exception, including colored stack traces. *In many cases, you can review the original yellow screen of death that ASP.NET generated for a given exception, even with customErrors mode turned off. An e-mail notification of each error at the time it occurs.  An RSS feed of the last 15 errors from the log. Here's a config example. Shouldn't that return statement actually be a yield?yield return ValidationResult("NotActived", Resources.UserNotActivated);If you really need to return a collection, you can yield return a collection, too (like you have it), it's just not necessary since you have only one.Also, in the case that you want to stop enumerating explicitly, you can use yield break; This is definitely not going to work:Foo existingFoo = context.Foos.Where(x =&gt; x.Id == id).First();existingFoo = value;You're looking it up, and then immediately overwriting the reference with something entirely different.I think you want to attach your value to the context and then do a save. Something more like this might do it for you:context.Foos.AddObject(value);context.ObjectStateManager.ChangeObjectState(value, System.Data.EntityState.Modified);context.SaveChanges();This doesn't require that you load the object to be updated first, which is nice. If that doesn't do it, then knowing that this is called something like disconnected updating might help your future googling.If you already have the object to be updated in hand, along with the new copy, I'm not aware of anything clean that merges them for you. Another way I've done it before looks more like this, which might feel less hacky:var entity = context.Entry(value);entity.State = EntityState.Modified;context.SaveChanges();Or more concisely:context.Entry(value).State = EntityState.Modified;context.SaveChanges();I can't remember if that's a built in thing or not, though. I want to build a .net 4.5/VS2012 solution in TeamCity. My builds work on the agent that has VS2012 installed, but on the agent that doesn't have VS2012, I get warnings like this: C:\Windows\Microsoft.NET\Framework\v4.0.30319\Microsoft.Common.targets(983,5): warning MSB3644: The reference assemblies for framework ".NETFramework,Version=v4.5" were not found.  To resolve this, install the SDK or Targeting Pack for this framework version or retarget your application to a version of the framework for which you have the SDK or Targeting Pack installed. Note that assemblies will be resolved from the Global Assembly Cache (GAC) and will be used in place of reference assemblies. Therefore your assembly may not be correctly targeted for the framework you intend. Can I install the targets without installing all of Visual Studio 2012, like I could with .NET 4.0?Where's the download?(I feel ridiculous asking this...but I have searched and searched for it! Honest! This site suggests it's only available with VS2012, which seems like madness.) I'm deploying an Azure Web Site and I want to get at the raw url, before anything messes with it. I'm finding, though, that by the time my site gets involved, the URL has already been cleaned up a bit. For instance: http://url-tests.azurewebsites.net///// (I made that for this question, you can try it)From the app, I have checked all sorts of things but they don't show what I expect in Azure (where are all those other slashes?):UNENCODED_URL: /HTTP_URL: /REQUEST_URI: /X-FORWARDED-FOR: X-FOO: HTTP_X_REWRITE_URL: HTTP_X_ORIGINAL_URL: /Request.RawUrl: /Request.Url.ToString(): http://url-tests.azurewebsites.net/For reference, when I run the app locally with IIS Express, or IIS 7, I see what I expect (at least in some of the variables):UNENCODED_URL: /////HTTP_URL: /////What gives? Is Azure stripping things out? If so, how can I get back to what the browser actually requested? (I did verify with Fiddler that the browser is requesting the URL with all those extra slashes.)(Also, the slashes are just an example. I'm not really building an app that expects to see 5 slashes in a row.)Update: checked HTTP_X_ORIGINAL_URL, too (added to list above). No dice NopCommerce templates typically include just views and assets, not code. But can they?I'd like to have a custom HtmlHelper that I refer to from my views. For example, if I create this extension in my theme:namespace Nop.Theme.Foo.Helpers{ public static class NopHelpers { public static string Test(this HtmlHelper html) { return "foo"; } }}Where do I put the built dll? And how do I refer to it in my view? The following does not work:@using Nop.Theme.Foo.Helpers;...@Html.Test()The error is: error: CS0234: The type or namespace name 'Theme' does not exist in the namespace 'Nop' (are you missing an assembly reference?).So I guess my questions are:how do I add the custom helper to my theme/template?where does the build output go (so NopCommerce can load it)?how do I refer to the helper from my view? Any dlls in the theme folder will be ignored. You can still build them in your theme project, but you'll need to drop them into the Nop.Web/bin folder so they get loaded.So:how do I add the custom helper to my theme/template?Just like you have it--create an extenstion method against HtmlHelper directly in your theme project.where does the build output go (so NopCommerce can load it)?Move the theme dll to Nop.Web/bin--i.e. the bin directory at the root of your website.how do I refer to the helper from my view?Just like you have it. Add a using statement, and then use the helper:@using Nop.Theme.Foo.Helpers;...@Html.Test()Oh, and if you want to resolve an instance of something inside your static helper, you can use this:using Nop.Core.Infrastructure;// ...var whateverYouWant = EngineContext.Current.Resolve&lt;IWhateverYouWant&gt;(); I'm using ObjectContent to build an XML request like so:private HttpRequestMessage CreateRequest&lt;T&gt;(T content, HttpMethod method) where T : class{ // create http message request var request = CreateRequest(method); // set contents of the HTTP message var xmlFormatter = new XmlMediaTypeFormatter { Indent = true, UseXmlSerializer = true }; var objectContent = new ObjectContent&lt;T&gt;(content, xmlFormatter); request.Content = objectContent; // return HttpRequestMessage return request;}This works well! But, the output doesn't include the XML preamble, e.g. &lt;?xml version="1.0" encoding="UTF-8"?&gt;How can I encourage the XmlSerializer to include that line? I couldn't figure out how to do this with ObjectContent so I just serialized it first, and then passed it to the request via StreamContent:private HttpRequestMessage CreateRequest&lt;T&gt;(T content, HttpMethod method) where T : class{ var request = CreateRequest(method); var encoding = Encoding.UTF8; var xmlWriterSettings = new XmlWriterSettings { Indent = true, Encoding = encoding }; // StringWriterWithEncoding courtesy of http://stackoverflow.com/a/9459212/29 using (var stringWriter = new StringWriterWithEncoding(encoding)) using (var xmlWriter = XmlWriter.Create(stringWriter, xmlWriterSettings)) { var xmlSerializer = new XmlSerializer(typeof(T)); xmlSerializer.Serialize(xmlWriter, content); request.Content = new StringContent(stringWriter.ToString(), encoding); } return request;} I can successfully create a new Azure Web App with this command (provided the resource group and app service plan exist, of course):New-AzureWebApp ` -Name site-name ` -ResourceGroupName resource-group-name ` -Location 'North Central US' ` -AppServicePlan app-service-plan-nameBut when I try to add a slot with a similar command it fails:New-AzureWebApp ` -Name site-name ` -ResourceGroupName resource-group-name ` -Location 'North Central US' ` -AppServicePlan app-service-plan-name ` -SlotName dev # &lt;--------------------------- this line is addedwith the error:New-AzureWebApp : MismatchingResourceName: The provided resource name 'site-name' did not match the name in the Url 'site-name/dev'.At line:1 char:1+ New-AzureWebApp -SlotName "dev" -Name "site-name" -Location "North ...+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~+ CategoryInfo : CloseError: (:) [New-AzureWebApp], CloudException+ FullyQualifiedErrorId : Microsoft.Azure.Commands.WebApp.Cmdlets.NewAzureWebAppCmdletWhat's going on here? Am I not going about making slots the right way?Note: I'm using Azure Powershell in AzureResourceManager mode.This AzureServiceManagement mode command does work so I'm not entirely lost:New-AzureWebsite -Name "site-name" -Slot "dev" -Location "North Central US"But why can't I get the former command to work? If I deploy a web app (formerly known as an Azure WebSite) to an App Hosting Plan in Azure with a couple of instances (scale = 2) will the load balancer in front of the instances care if any of the instances is unhealthy?I'm troubleshooting an issue that sometimes causes my site to return an http 503 ~50% of the time. My thinking here is that one of two of my instances has failed but the load balancer hasn't noticed.If the load balancer does care, what does it look for? I can't find anyway to specify a ping url, for instance.Note: this question has nothing to do with Traffic Manager. Following the procedure in this article I disabled the ARR Affinity cookie on my Azure Web App with this header in my responses:Arr-Disable-Session-Affinity: TrueIt does remove the cookie, which is very much a good thing. But, the header itself is still coming through. This header doesn't really hurt anything, but according to that same doc it shouldn't be there: If you add the Arr-Disable-Session-Affinity header to disable the affinity cookie, ARR will not set the cookie, but it will also remove the Arr-Disable-Session-Affinity header itself, so if your process is working correctly, you will see neither.So...how do I get it to remove the header, too? Suppose I have an index for cars on a dealer's car lot. Each document resembles the following:{ color: 'red', model_year: '2015', date_added: '2015-07-20'}Suppose I have a million cars.Suppose I want to present a view of the most recently added 1000 cars, along with facets over those 1000 cars.I could just use from and size to paginate the results up to a fixed limit of 1000, but in doing so the totals and facets on model_year and color (i.e. aggregations) I get back from Elasticsearch aren't right--they're over the entire matched set.How do I limit my search to the most recently added 1000 documents for pagination and aggregation? You have to put a cert on the www address.By using https your browser is demanding a secure connection before trusting to do what the server says. Your connection isn't secure so the browser won't send cookies, follow redirects, etc. This is a good thing. But it stinks for your cert budget. If your CA lets you add www as a Subject Alternate Name you can handle both domains with one cert, which is convenient and has pretty broad support.  As other answers have well covered: this is not about performance, it's about clarity. There's wide support for both of your options:if (!acceptedValues.Any(v =&gt; v == someValue)){ // exception logic}if (acceptedValues.All(v =&gt; v != someValue)){ // exception logic}But I think this might achieve broader support:var isValueAccepted = acceptedValues.Any(v =&gt; v == someValue);if (!isValueAccepted){ // exception logic}Simply computing the boolean (and naming it) before negating anything clears this up a lot in my mind. I can use nginx to proxy data from an upstream server, but how can I use it to proxy data from a url that is passed in via a query string parameter?This works, but is incomplete:# e.g. http://localhost:8080?u=https://requestb.in/1nm8uv01 -&gt; oklocation / { proxy_pass $arg_u; resolver 8.8.8.8;}I'm not encoding that u parameter correctly. This is a problem when I start adding query string params to it. For example, this fails:# http://localhost:8080?u=https://requestb.in/1nm8uv01?a=b&amp;c=d -&gt; incomplete; c is not passed to the upstreamSo encode it, right? Encoding the url parameter also fails:# http://localhost:8080/?u=https%3A%2F%2Frequestb.in%2F1nm8uv01%3Fa%3Db%26c%3Dd -&gt; nginx error: invalid URL prefix in "https%3A%2F%2Freq...So if I encode the parameter as in this last example, how do I get nginx to decode it before doing the request? I use my app to request an oauth token from Azure AD for a user so that I can use the Azure Service Management API on behalf of the user to do things with their Azure resources. This works fine, however, now I have too much power.I want to limit the scope of the tokens I retrieve to specific abilities so that I can't accidentally (or maliciously) do bad things to the Azure resources of the person my app impersonates.The "Microsoft Graph" API has dozens of permissions I can grant:but the "Windows Azure Service Management" API only has one: everythingHow can I make this access more granular to protect my app and my users?                                                                   